<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.83.1"><link rel=canonical type=text/html href=/documentation/><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Documentation | HPCC Home</title><meta property="og:title" content="Documentation"><meta property="og:description" content="Home of UCR's HPCC"><meta property="og:type" content="website"><meta property="og:url" content="/documentation/"><meta property="og:site_name" content="HPCC Home"><meta itemprop=name content="Documentation"><meta itemprop=description content="Home of UCR's HPCC"><meta name=twitter:card content="summary"><meta name=twitter:title content="Documentation"><meta name=twitter:description content="Home of UCR's HPCC"><link rel=preload href=/scss/main.min.e8d637f30893e85918b2aeae9cd9eab6c68fcd7998810e804d7c9ab542fbfd45.css as=style><link href=/scss/main.min.e8d637f30893e85918b2aeae9cd9eab6c68fcd7998810e804d7c9ab542fbfd45.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.5.1.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://unpkg.com/lunr@2.3.8/lunr.min.js integrity=sha384-vRQ9bDyE0Wnu+lMfm57BlYLO0/XauFuKpVsZPs7KEDwYKktWi5+Kz3MP8++DFlRY crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class=navbar-logo><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 500 500" style="enable-background:new 0 0 500 500"><g><path style="fill:#fff" d="M116.8525 421.9722c-5.7041.0-10.3442-4.3127-10.3442-9.6129V88.183c0-5.3002 4.6401-9.6117 10.3442-9.6117H320.858c3.0347.0 9.3959.5498 11.7506 2.6302l.3545.3442 58.905 63.2912c2.3101 2.491 2.9202 8.4928 2.9202 11.3184v256.2039c0 5.3002-4.6407 9.6129-10.3436 9.6129H116.8525z"/><g><g><g><path style="fill:#767676" d="M384.4445 423.2066H116.852c-6.3839.0-11.5786-4.8658-11.5786-10.8474V88.1831c0-5.9804 5.1947-10.8461 11.5786-10.8461h204.0062c.377.0 9.2786.0329 12.568 2.9389l.3947.3833 58.9508 63.337c3.2135 3.4652 3.2514 11.7924 3.2514 12.1593v256.2036C396.0231 418.3408 390.8284 423.2066 384.4445 423.2066zM116.5079 411.9189c.0848.0278.1999.0531.3441.0531h267.5925c.1442.0.2581-.0253.3441-.0531V156.1556c-.0076-.9033-.3593-3.7347-.7034-5.0037l-57.6527-61.9416c-1.4651-.3176-4.4533-.6389-5.5742-.6389H116.852c-.143.0-.2594.024-.3441.0531V411.9189zm267.4533-261.149zM327.0321 89.371v.0013V89.371z"/></g></g></g><g><g><path style="fill:#5b7fc0" d="M189.0874 210.1754l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4473C177.5953 212.627 183.0601 210.1742 189.0874 210.1754zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 234.1722 197.0804 232.033z"/><path style="opacity:.3;fill:#fff" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/><g><defs><path id="SVGID_1_" d="M194.7376 237.6875c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 234.2399 196.1861 236.239 194.7376 237.6875z"/></defs><clipPath id="SVGID_2_"><use xlink:href="#SVGID_1_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_2_);fill:#fff" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/><path style="opacity:.13;clip-path:url(#SVGID_2_);fill:#020202" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/></g><g><defs><path id="SVGID_3_" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/></defs><clipPath id="SVGID_4_"><use xlink:href="#SVGID_3_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_4_);fill:#5b7fc0" d="M172.6595 215.6045c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8475-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 209.1953 176.6171 211.647 172.6595 215.6045z"/></g></g><rect x="198.8952" y="225.1043" style="fill:#5b7fc0" width="122.6266" height="13.8671"/></g><g><path style="fill:#d95140" d="M189.0874 155.7611l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.0249 2.454-11.4897 6.4116-15.4473C177.5953 158.2128 183.0601 155.7599 189.0874 155.7611zm7.993 21.8577c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.2508 181.7667 197.0816 179.758 197.0804 177.6188z"/><path style="opacity:.3;fill:#fff" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zm7.9941 21.8613c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/><g><defs><path id="SVGID_5_" d="M194.7376 183.2733c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 179.8256 196.1861 181.8248 194.7376 183.2733z"/></defs><clipPath id="SVGID_6_"><use xlink:href="#SVGID_5_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_6_);fill:#fff" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/><path style="opacity:.13;clip-path:url(#SVGID_6_);fill:#020202" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/></g><g><defs><path id="SVGID_7_" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zm7.9941 21.8613c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/></defs><clipPath id="SVGID_8_"><use xlink:href="#SVGID_7_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_8_);fill:#d95140" d="M172.6595 161.1903c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 154.7811 176.6171 157.2327 172.6595 161.1903z"/></g><rect x="198.8952" y="170.69" style="fill:#d95140" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#56a55c" d="M189.5379 264.6147l.0012-.0012c7.7751.0012 15.0294 4.1862 18.932 10.9235 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.3281-2.2733-15.458-6.4032-4.13-4.13-6.4032-9.6186-6.4056-15.4628.0012-6.0249 2.454-11.4897 6.4116-15.4472C178.0458 267.0663 183.5105 264.6135 189.5379 264.6147zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6538 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.7013 290.6202 197.5321 288.6115 197.5309 286.4723z"/><path style="opacity:.3;fill:#fff" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/><g><defs><path id="SVGID_9_" d="M195.1881 292.1268c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9941 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.5344 288.6792 196.6366 290.6783 195.1881 292.1268z"/></defs><clipPath id="SVGID_10_"><use xlink:href="#SVGID_9_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_10_);fill:#fff" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/><path style="opacity:.13;clip-path:url(#SVGID_10_);fill:#020202" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/></g><g><defs><path id="SVGID_11_" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/></defs><clipPath id="SVGID_12_"><use xlink:href="#SVGID_11_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_12_);fill:#56a55c" d="M173.11 270.0439c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7325-11.1497-10.9151-18.926-10.9151C182.5311 263.6346 177.0676 266.0863 173.11 270.0439z"/></g></g><rect x="199.3456" y="279.5436" style="fill:#56a55c" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#f1bc42" d="M189.0874 318.7208l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3305-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4472C177.5953 321.1724 183.0601 318.7196 189.0874 318.7208zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 342.7176 197.0804 340.5784z"/><path style="opacity:.3;fill:#fff" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/><g><defs><path id="SVGID_13_" d="M194.7376 346.2329c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 342.7853 196.1861 344.7844 194.7376 346.2329z"/></defs><clipPath id="SVGID_14_"><use xlink:href="#SVGID_13_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_14_);fill:#fff" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/><path style="opacity:.13;clip-path:url(#SVGID_14_);fill:#020202" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/></g><g><defs><path id="SVGID_15_" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/></defs><clipPath id="SVGID_16_"><use xlink:href="#SVGID_15_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_16_);fill:#f1bc42" d="M172.6595 324.15c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8474-1.0151-7.6327-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 317.7407 176.6171 320.1924 172.6595 324.15z"/></g></g><rect x="198.8952" y="333.6497" style="fill:#f1bc42" width="122.6266" height="13.8671"/></g></g></svg></span><span class="text-uppercase font-weight-bold">HPCC Home</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/about/about/><span>About</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/access-rates/access-rates/><span>Access & Rates</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/contacts/><span>Staff & Contacts</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/contacts/location/><span>Location</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/documentation/><span class=active>Documentation</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"><input type=search class="form-control td-search-input" placeholder="&#xf002; Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.0c28cf2b3162f967ddd5c61d829ef9fa.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"></div><div class="d-none d-xl-block col-xl-2 td-toc d-print-none"></div><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/documentation/>Return to the regular view of this page</a>.</p></div><h1 class=title>Documentation</h1><ul><li>1: <a href=#pg-72b81f4c6982c0a8089b5a40a79d8944>Overview</a></li><ul></ul><li>2: <a href=#pg-79c5e61be9a5ab97cc0dc6292992271f>HPC Cluster</a></li><ul><li>2.1: <a href=#pg-3fe3dae529768e4fb6000f0ac30578bc>Communicating</a></li><li>2.2: <a href=#pg-c9bef8be0d26b524c847b87a4fd191eb>Data Storage</a></li><li>2.3: <a href=#pg-1915e6971b765ae24edf59fb8f78b3e5>Getting Started</a></li><li>2.4: <a href=#pg-585ba955c4fd270a0445a3be8d3e54d5>Introduction</a></li><li>2.5: <a href=#pg-79fc43e3b0910006e7d7e5b6957bd2b1>Login</a></li><li>2.6: <a href=#pg-7526eb56ba93fa593a9ed0234144b199>Managing Jobs</a></li><li>2.7: <a href=#pg-2402efae435cf116cdf7d3495c902c12>Package Management</a></li><li>2.8: <a href=#pg-cb171105c20295006484cc7a3d475eb8>Parallel Evaluations in R</a></li><li>2.9: <a href=#pg-1dab12415a1ae5cd43e140ecef9dfe93>Queue Policies</a></li><li>2.10: <a href=#pg-33543218cb7f95b316141a36a8629e9f>Security</a></li><li>2.11: <a href=#pg-f084de12202027a4e8874426f773d174>Sharing Data</a></li><li>2.12: <a href=#pg-44da1bc9f9e7d2ae115c8cb435e37591>SSH Keys Apple macOS</a></li><li>2.13: <a href=#pg-d726acebcd0bd6b600f604bfdce70fa0>SSH Keys Microsoft Windows</a></li><li>2.14: <a href=#pg-008bc8a4cf5439833eb50953ea9f062b>Terminal-based Working Environments</a></li><li>2.15: <a href=#pg-1d4c62174462deb26fd1485bfa8ac42a>Visualization</a></li></ul><li>3: <a href=#pg-e88a4922f0cd5d4ed59782cdf6fc1f24>HPCC Cloud/External</a></li><ul><li>3.1: <a href=#pg-beacfdfe8793106a0dce0688e1436540>Account Creation</a></li><li>3.2: <a href=#pg-bb9a0cc487677c78eb5d0f2dfa604443>Account Egress Waiver</a></li><li>3.3: <a href=#pg-5e19d092497df8af716f50c58b7201c7>Cluster Operation</a></li><li>3.4: <a href=#pg-f8a784a057005b39f975eadeb4a739f0>Cost Control and Billing</a></li><li>3.5: <a href=#pg-4c457da514322cc737a3885a02aa14c8>HPCC cfnCluster Setup</a></li><li>3.6: <a href=#pg-389571a10573d130fd51b9bc08293672>Introduction</a></li></ul><li>4: <a href=#pg-0a7cfdbbbcf4186e92cdbbda5db3dc9d>Linux Basics</a></li><ul><li>4.1: <a href=#pg-9291f41bc052c8146c2f2d2bc1f05148>Access</a></li><li>4.2: <a href=#pg-ec9dd3a11b1821f51d2bd89f64cd57aa>Command Line Basics</a></li><li>4.3: <a href=#pg-7eb831e5c7bb1c75993d9c2d1660258a>File Systems and Transfers</a></li><li>4.4: <a href=#pg-ea36b6adbbc1635f99e1da1659fbe7ab>Finding Things</a></li><li>4.5: <a href=#pg-d64f50f5d5ae8ccbd34759787e1d5175>Permissions and Ownership</a></li><li>4.6: <a href=#pg-dbf76568729e6f45436864bb508b3ed3>Piping</a></li><li>4.7: <a href=#pg-c2544b888e150bbe542cef6b8043ac41>Process Management</a></li><li>4.8: <a href=#pg-1c4417cb6a57ee480443dcdfa3f74862>Shell Bootcamp</a></li><li>4.9: <a href=#pg-2fd30c11f419f2288892e85df4de180b>Streams</a></li><li>4.10: <a href=#pg-c8656daa5ea9b4db1c7a307969154d39>Text Editors</a></li><li>4.11: <a href=#pg-5214e2825df5a868ca3a6d2886c4ad5f>Variables</a></li></ul><li>5: <a href=#pg-6c33cd51ee4d79b09958bb3cbefd007d>Reference</a></li><ul><li>5.1: <a href=#pg-0ced68162fb683117a1934936d54c1ac>Parameter Reference</a></li></ul></ul><div class=content></div></div><div class=td-content><h1 id=pg-72b81f4c6982c0a8089b5a40a79d8944>1 - Overview</h1><div class=lead>Here&rsquo;s where your user finds out if your project is for them.</div><div class="pageinfo pageinfo-primary"><p>This is a placeholder page that shows you how to use this template site.</p></div><p>The Overview is where your users find out about your project. Depending on the size of your docset, you can have a separate overview page (like this one) or put your overview contents in the Documentation landing page (like in the Docsy User Guide).</p><p>Try answering these questions for your user in this page:</p><h2 id=what-is-it>What is it?</h2><p>Introduce your project, including what it does or lets you do, why you would use it, and its primary goal (and how it achieves it). This should be similar to your README description, though you can go into a little more detail here if you want.</p><h2 id=why-do-i-want-it>Why do I want it?</h2><p>Help your user know if your project will help them. Useful information can include:</p><ul><li><p><strong>What is it good for?</strong>: What types of problems does your project solve? What are the benefits of using it?</p></li><li><p><strong>What is it not good for?</strong>: For example, point out situations that might intuitively seem suited for your project, but aren&rsquo;t for some reason. Also mention known limitations, scaling issues, or anything else that might let your users know if the project is not for them.</p></li><li><p><strong>What is it <em>not yet</em> good for?</strong>: Highlight any useful features that are coming soon.</p></li></ul><h2 id=where-should-i-go-next>Where should I go next?</h2><p>Give your users next steps from the Overview. For example:</p><ul><li><a href=/docs/getting-started/>Getting Started</a>: Get started with $project</li><li><a href=/docs/examples/>Examples</a>: Check out some example code!</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-79c5e61be9a5ab97cc0dc6292992271f>2 - HPC Cluster</h1><div class=lead>What does your user need to know to try your project?</div><div class="pageinfo pageinfo-primary"><p>This is a placeholder page that shows you how to use this template site.</p></div><p>Information in this section helps your user try your project themselves.</p><ul><li><p>What do your users need to do to start using your project? This could include downloading/installation instructions, including any prerequisites or system requirements.</p></li><li><p>Introductory “Hello World” example, if appropriate. More complex tutorials should live in the Tutorials section.</p></li></ul><p>Consider using the headings below for your getting started page. You can delete any that are not applicable to your project.</p><h2 id=prerequisites>Prerequisites</h2><p>Are there any system requirements for using your project? What languages are supported (if any)? Do users need to already have any software or tools installed?</p><h2 id=installation>Installation</h2><p>Where can your user find your project code? How can they install it (binaries, installable package, build from source)? Are there multiple options/versions they can install and how should they choose the right one for them?</p><h2 id=setup>Setup</h2><p>Is there any initial setup users need to do after installation to try your project?</p><h2 id=try-it-out>Try it out!</h2><p>Can your users test their installation, for example by running a command or deploying a Hello World example?</p></div><div class=td-content style=page-break-before:always><h1 id=pg-3fe3dae529768e4fb6000f0ac30578bc>2.1 - Communicating</h1><h2 id=communicating-with-others>Communicating with others</h2><p>The cluster is a shared resource, and communicating with other users can help to schedule large computations.</p><p><strong>Looking-Up Specific Users</strong></p><p>A convenient overview of all users and their lab affiliations can be retrieved with the following command:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>user_details.sh
</code></pre></div><p>You can search for specific users by running:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#000>MATCH1</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#39;username1&#39;</span> <span style=color:#8f5902;font-style:italic># Searches by real name, and username, and email address and PI name</span>
<span style=color:#000>MATCH2</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#39;username2&#39;</span>
user_details.sh <span style=color:#000;font-weight:700>|</span> grep -P <span style=color:#4e9a06>&#34;</span><span style=color:#000>$MATCH1</span><span style=color:#4e9a06>|</span><span style=color:#000>$MATCH2</span><span style=color:#4e9a06>&#34;</span>
</code></pre></div><p><strong>Listing Users with Active Jobs on the Cluster</strong>
To get a list of usernames:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>squeue --format <span style=color:#4e9a06>&#39;%u&#39;</span> <span style=color:#000;font-weight:700>|</span> sort <span style=color:#000;font-weight:700>|</span> uniq
</code></pre></div><p>To get the list of real names:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>grep &lt;<span style=color:#ce5c00;font-weight:700>(</span>user_details.sh <span style=color:#000;font-weight:700>|</span> awk <span style=color:#4e9a06>&#39;{print $2,$3,$4}&#39;</span><span style=color:#ce5c00;font-weight:700>)</span> -f &lt;<span style=color:#ce5c00;font-weight:700>(</span>squeue --format <span style=color:#4e9a06>&#39;%u&#39;</span> --noheader <span style=color:#000;font-weight:700>|</span> sort <span style=color:#000;font-weight:700>|</span> uniq<span style=color:#ce5c00;font-weight:700>)</span> <span style=color:#000;font-weight:700>|</span> awk <span style=color:#4e9a06>&#39;{print $1,$2}&#39;</span>
</code></pre></div><p>To get the list of emails:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>grep &lt;<span style=color:#ce5c00;font-weight:700>(</span>user_details.sh <span style=color:#000;font-weight:700>|</span> awk <span style=color:#4e9a06>&#39;{print $4,$5}&#39;</span><span style=color:#ce5c00;font-weight:700>)</span> -f &lt;<span style=color:#ce5c00;font-weight:700>(</span>squeue --format <span style=color:#4e9a06>&#39;%u&#39;</span> --noheader <span style=color:#000;font-weight:700>|</span> sort <span style=color:#000;font-weight:700>|</span> uniq<span style=color:#ce5c00;font-weight:700>)</span> <span style=color:#000;font-weight:700>|</span> awk <span style=color:#4e9a06>&#39;{print $2}&#39;</span>
</code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-c9bef8be0d26b524c847b87a4fd191eb>2.2 - Data Storage</h1><h2 id=dashboard>Dashboard</h2><p>HPCC cluster users are able to check on their home and bigdata storage usage from the <a href=https://dashboard.hpcc.ucr.edu>Dashboard Portal</a>.</p><h2 id=home>Home</h2><p>Home directories are where you start each session on the HPC cluster and where your jobs start when running on the cluster. This is usually where you place the scripts and various things you are working on. This space is very limited. Please remember that the home storage space quota per user account is 20 GB.</p><table><thead><tr><th>Path</th><th>/rhome/<code>username</code></th></tr></thead><tbody><tr><td>User Availability</td><td>All Users</td></tr><tr><td>Node Availability</td><td>All Nodes</td></tr><tr><td>Quota Responsibility</td><td>User</td></tr></tbody></table><h2 id=bigdata>Bigdata</h2><p>Bigdata is an area where large amounts of storage can be made available to users. A lab purchases bigdata space separately from access to the cluster. This space is then made available to the lab via a shared directory and individual directories for each user.</p><p><strong>Lab Shared Space</strong>
This directory can be accessed by the lab as a whole.</p><table><thead><tr><th>Path</th><th>/bigdata/<code>labname</code>/shared</th></tr></thead><tbody><tr><td>User Availability</td><td>Labs that have purchased space.</td></tr><tr><td>Node Availability</td><td>All Nodes</td></tr><tr><td>Quota Responsibility</td><td>Lab</td></tr></tbody></table><p><strong>Individual User Space</strong>
This directory can be accessed by specific lab members.</p><table><thead><tr><th>Path</th><th>/bigdata/<code>labname</code>/<code>username</code></th></tr></thead><tbody><tr><td>User Availability</td><td>Labs that have purchased space.</td></tr><tr><td>Node Availability</td><td>All Nodes</td></tr><tr><td>Quota Responsibility</td><td>Lab</td></tr></tbody></table><h2 id=non-persistent-space>Non-Persistent Space</h2><p>Frequently, there is a need to do things like, output a significant amount of intermediate data during a job, access a dataset from a faster medium than bigdata or the home directories or write out lock files. These types of things are well suited to the use of non-persistent spaces. Below are the filesystems available on the HPC cluster.</p><p><strong>Temporary Space</strong>
This is a standard space available on all Linux systems. Please be aware that it is limited to the amount of free disk space on the node you are running on.</p><table><thead><tr><th>Path</th><th>/tmp</th></tr></thead><tbody><tr><td>User Availability</td><td>All Users</td></tr><tr><td>Node Availability</td><td>All Nodes</td></tr><tr><td>Quota Responsibility</td><td>N/A</td></tr></tbody></table><p><strong>SSD Backed Space</strong>
This space is much faster than the persistwnt space (/rhome,/bigdata), but slower than using RAM based storage.</p><table><thead><tr><th>Path</th><th>/scratch</th></tr></thead><tbody><tr><td>User Availability</td><td>All Users</td></tr><tr><td>Node Availability</td><td>All Nodes</td></tr><tr><td>Quota Responsibility</td><td>N/A</td></tr></tbody></table><p><strong>RAM Space</strong>
This type of space takes away from physical memory but allows extremely fast access to the files located on it. When submitting a job you will need to factor in the space your job is using in RAM as well. For example, if you have a dataset that is 1G in size and use this space, it will take at least 1G of RAM.</p><table><thead><tr><th>Path</th><th>/dev/shm</th></tr></thead><tbody><tr><td>User Availability</td><td>All Users</td></tr><tr><td>Node Availability</td><td>All Nodes</td></tr><tr><td>Quota Responsibility</td><td>N/A</td></tr></tbody></table><h2 id=usage-and-quotas>Usage and Quotas</h2><p>To quickly check your usage and quota limits:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>check_quota home
check_quota bigdata
</code></pre></div><p>To get the usage of your current directory, run the following command:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>du -sh .
</code></pre></div><p>To calculate the sizes of each separate sub directory, run:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>du -shc *
</code></pre></div><p>This may take some time to complete, please be patient.</p><p>For more information on your home directory, please see the <a href=manuals_linux-basics_cmdline-basics.html#orientation>Linux Basics Orientation</a>.</p><h2 id=automatic-backups>Automatic Backups</h2><p>The cluster does create backups however it is still advantageous for users to periodically make copies of their critical data to a separate storage device.
The cluster is a production system for research computations with a very expensive high-performance storage infrastructure. It is not a data archiving system.</p><p>Home backups are created daily and kept for one week.
Bigdata backups are created weekly and kept for one month.</p><p>Home and bigdata backups are located under the following respective directories:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>/rhome/.snapshots/
/bigdata/.snapshots/
</code></pre></div><p>The individual snapshot directories have names with numerical values in epoch time format.
The higher the value the more recent the snapshot.</p><p>To view the exact time of when each snapshot was taken execute the following commands:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>mmlssnapshot home
mmlssnapshot bigdata
</code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-1915e6971b765ae24edf59fb8f78b3e5>2.3 - Getting Started</h1><h2 id=login-from-mac-linux-mobaxterm>Login from Mac, Linux, MobaXTerm</h2><p>The initial login brings users into the cluster head node (i.e. pigeon, penguin, owl). From there, users can submit jobs via qsub to the compute nodes or log into owl to perform intensive tests.
Since all machines are mounting a centralized file system, users will always see the same home directory on all systems. Therefore, there is no need to copy files from one machine to another.</p><p>Open the terminal and type</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ssh -X username@cluster.hpcc.ucr.edu
</code></pre></div><h2 id=login-from-windows>Login from Windows</h2><p>Please refer to the login instructions of our <a href=manuals_linux-basics_intro#windows>Linux Basics manual</a>.</p><h2 id=change-password>Change Password</h2><ol><li>Login via SSH using the Terminal on Mac/Linux or MobaXTerm on Windows</li></ol><ul><li>Once you have logged in type the following command:</li></ul><pre><code>passwd
</code></pre><ul><li>Enter the old password (the random characters that you were given as your initial password)</li><li>Enter your new password</li></ul><p>The password minimum requirements are:</p><ul><li>Total length at least 8 characters long</li><li>Must have at least 3 of the following:<ul><li>Lowercase character</li><li>Uppercase character</li><li>Number</li><li>Punctuation character</li></ul></li></ul><h2 id=modules>Modules</h2><p>All software used on the HPC cluster is managed through a simple module system.
You must explicitly load and unload each package as needed.
More advanced users may want to load modules within their bashrc, bash_profile, or profile files.</p><h3 id=available-modules>Available Modules</h3><p>To list all available software modules, execute the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>module avail
</code></pre></div><p>This should output something like:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>------------------------- /usr/local/Modules/versions --------------------------
3.2.9
--------------------- /usr/local/Modules/3.2.9/modulefiles ---------------------
BEDTools/2.15.0<span style=color:#ce5c00;font-weight:700>(</span>default<span style=color:#ce5c00;font-weight:700>)</span> modules
PeakSeq/1.1<span style=color:#ce5c00;font-weight:700>(</span>default<span style=color:#ce5c00;font-weight:700>)</span> python/3.2.2
SOAP2/2.21<span style=color:#ce5c00;font-weight:700>(</span>default<span style=color:#ce5c00;font-weight:700>)</span> samtools/0.1.18<span style=color:#ce5c00;font-weight:700>(</span>default<span style=color:#ce5c00;font-weight:700>)</span>
bowtie2/2.0.0-beta5<span style=color:#ce5c00;font-weight:700>(</span>default<span style=color:#ce5c00;font-weight:700>)</span> stajichlab
cufflinks/1.3.0<span style=color:#ce5c00;font-weight:700>(</span>default<span style=color:#ce5c00;font-weight:700>)</span> subread/1.1.3<span style=color:#ce5c00;font-weight:700>(</span>default<span style=color:#ce5c00;font-weight:700>)</span>
matrix2png/1.2.1<span style=color:#ce5c00;font-weight:700>(</span>default<span style=color:#ce5c00;font-weight:700>)</span> tophat/1.4.1<span style=color:#ce5c00;font-weight:700>(</span>default<span style=color:#ce5c00;font-weight:700>)</span>
module-info
</code></pre></div><h3 id=using-modules>Using Modules</h3><p>To load a module, run:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>module load &lt;software name&gt;<span style=color:#ce5c00;font-weight:700>[</span>/&lt;version&gt;<span style=color:#ce5c00;font-weight:700>]</span>
</code></pre></div><p>To load the default version of the tophat module, run:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>module load tophat
</code></pre></div><h3 id=show-loaded-modules>Show Loaded Modules</h3><p>To show what modules you have loaded at any time, you can run:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>module list
</code></pre></div><p>Depending on what modules you have loaded, it will produce something like this:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>Currently Loaded Modulefiles:
  1<span style=color:#ce5c00;font-weight:700>)</span> vim/7.4.1952                  3<span style=color:#ce5c00;font-weight:700>)</span> slurm/16.05.4                 5<span style=color:#ce5c00;font-weight:700>)</span> R/3.3.0                       7<span style=color:#ce5c00;font-weight:700>)</span> less-highlight/1.0            9<span style=color:#ce5c00;font-weight:700>)</span> python/3.6.0
  2<span style=color:#ce5c00;font-weight:700>)</span> tmux/2.2                      4<span style=color:#ce5c00;font-weight:700>)</span> openmpi/2.0.1-slurm-16.05.4   6<span style=color:#ce5c00;font-weight:700>)</span> perl/5.20.2                   8<span style=color:#ce5c00;font-weight:700>)</span> iigb_utilities/1
</code></pre></div><h3 id=unloading-software>Unloading Software</h3><p>Sometimes you want to no longer have a piece of software in path. To do this you unload the module by running:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>module unload &lt;software name&gt;
</code></pre></div><h2 id=databases>Databases</h2><h3 id=loading-databases>Loading Databases</h3><p><a href=http://www.ncbi.nlm.nih.gov/>NCBI</a>, <a href=http://en.wikipedia.org/wiki/Pfam#External_links>PFAM</a>, and <a href=http://www.uniprot.org/>Uniprot</a>, do not need to be downloaded by users. They are installed as modules on the cluster.</p><pre><code>module load db-ncbi
module load db-pfam
module load db-uniprot
</code></pre><p>Specific database release numbers can be identified by the version label on the module:</p><pre><code>module avail db-ncbi

----------------- /usr/local/Modules/3.2.9/modulefiles -----------------
db-ncbi/20140623(default)
</code></pre><h3 id=using-databases>Using Databases</h3><p>In order to use the loaded database users can simply provide the corresponding environment variable (NCBI_DB, UNIPROT_DB, PFAM_DB, etc&mldr;) for the proper path in their executables.</p><p>This is the old deprecated BLAST and it may not work in the near future, however if you require it:</p><pre><code>blastall -p blastp -i proteins.fasta -d $NCBI_DB/nr -o blastp.out
</code></pre><p>You can can also use this method if you require the old version of BLAST (old BLAST with legacy support):</p><pre><code>BLASTBIN=`which legacy_blast.pl | xargs dirname`
legacy_blast.pl blastall -p blastp -i proteins.fasta -d $NCBI_DB/nr -o blast.out --path $BLASTBIN
</code></pre><p>This is the preferred/recommended method (BLAST+):</p><pre><code>blastp -query proteins.fasta -db $NCBI_DB/nr -out proteins_blastp.txt
</code></pre><p>Usually, we store the most recent release and 2-3 previous releases of each database. This way time consuming projects can use the same database version throughout their lifetime without always updating to the latest releases.</p><h3 id=additional-features>Additional Features</h3><p>There are additional features and operations that can be done with the module command. Please run the following to get more information:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>module <span style=color:#204a87>help</span>
</code></pre></div><h2 id=quotas>Quotas</h2><h3 id=cpu>CPU</h3><p>Currently, the maximum number of CPU cores a user can use simultaneously on the cluster is 256 CPU cores when the load on the cluster is &lt;30% and 128 CPU cores when the load is above 30%. If a user submits jobs for more than 256/128 CPU cores then the additional requests will be queued until resources within the user&rsquo;s CPU quota become available. Upon request a user&rsquo;s upper CPU quota can be extended temporarily, but only if sufficient CPU resources are available. To avoid monopolisation of the cluster by a small number of users, the high load CPU quota of 128 cores is dynamically readjusted by an algorithm that considers the number of CPU hours accumulated by each user over a period of 2 weeks along with the current overall CPU usage on the cluster. If the CPU hour average over the 2 week window exceeds an allowable amount then the default CPU quota will be reduced for such a heavy user to 64 CPU cores, and if it exceeds the allowable amount by two-fold it will be reduced to 32 CPU cores. Once the average usage of a heavy user drops again below those limits, the upper CPU limit will be raised accordingly. Note: when the overall CPU load on the cluster is below 70% then the dynamically readjusted CPU quotas are not applied. At those low load times every user has the same CPU quota: 256 CPU cores at &lt;30% load and 128 CPU cores at 30-70% load.</p><h3 id=data-storage>Data Storage</h3><p>A standard user account has a storage quota of 20GB. Much more storage space, in the range of many TBs, can be made available in a user account&rsquo;s bigdata directory. The amount of storage space available in bigdata depends on a user group&rsquo;s annual subscription. The pricing for extending the storage space in the bigdata directory is available <a href=/home>here</a>.</p><h3 id=memory>Memory</h3><p>From the cluster head node users can submit jobs to the batch queue or the highmem queue. The nodes associated with the batch queue are mainly for CPU intensive tasks, while the nodes of the highmem queue are dedicated to memory intensive tasks. The batch nodes allow a 1GB RAM minimum limit on jobs and and the highmem nodes allow 100GB-1024GB RAM jobs.</p><h2 id=whats-next>What&rsquo;s Next?</h2><p>You should now know the following:</p><ol><li>Basic orginization of the cluster</li></ol><ul><li>How to login to the cluster</li><li>How to use the Module system to gain access to the cluster software</li><li>CPU, storage, and memory limitations (quotas and hardware limits)</li></ul><p>Now you can start using the cluster.
The recommended way to run your jobs (scripts, pipelines, experiments, etc&mldr;) is to submit them to the queuing system by using sbatch.
The HPCC cluster uses the Slurm queuing system.
Please do not run ANY computationally intensive tasks on any head node that starts with the letter &ldquo;P&rdquo; (i.e. penguin, pigeon, parrot). If this policy is violated, your jobs will be killed to limit the negative impact on others.
The head nodes are a shared resource and should be accessible by all users. Negatively impacting performance would affect all users on the system and will not be tolerated.</p><p>However you may run memory intensive jobs on Owl.
Login to Owl like so:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ssh -X owl.ucr.edu
</code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-585ba955c4fd270a0445a3be8d3e54d5>2.4 - Introduction</h1><h2 id=introduction>Introduction</h2><p>This manual provides an introduction to the usage of the HPCC cluster.
All servers and compute resources of the HPCC cluster are available to researchers from all departments and colleges at UC Riverside for a minimal recharge fee <a href=/#rates>(see rates)</a>.
To request an account, please email <a href=mailto:support@hpcc.ucr.edu>support@hpcc.ucr.edu</a>.
The latest hardware/facility description for grant applications is available <a href=https://goo.gl/43eOwQ>here</a>.</p><h2 id=overview>Overview</h2><h3 id=storage>Storage</h3><ul><li>Four enterprise class HPC storage systems</li><li>Approximately 2 PB (2048 TB) of network storage</li><li>GPFS (NFS and SAMBA via GPFS)</li><li>Automatic snapshots and archival backups</li></ul><h3 id=network>Network</h3><ul><li>Ethernet<ul><li>1 Gb/s switch x 5</li><li>1 Gb/s switch 10 Gig uplink</li><li>10 Gb/s switch for Campus wide Science DMZ</li><li>redundant, load balanced, robust mesh topology</li></ul></li><li>Interconnect<ul><li>56 Gb/s InfiniBand (FDR)</li></ul></li></ul><h3 id=head-nodes>Head Nodes</h3><p>All users should access the cluster via ssh through cluster.hpcc.ucr.edu, this address will automatically balance traffic to one of the available head nodes.</p><ul><li>Penguin<ul><li>Resources: 8 cores, 64 GB memory</li><li>Primary function: submitting jobs to the queuing system</li><li>Secondary function: development; code editing and running small (under 50 % CPU and under 1 GB RAM) sample jobs</li></ul></li><li>Pigeon<ul><li>Resources: 16 cores, 128 GB memory</li><li>Primary function: submitting jobs to the queuing system</li><li>Secondary function: development; code editing and running small (under 50 % CPU and under 1 GB RAM) sample jobs</li></ul></li><li>Pelican<ul><li>Resources: 32 cores, 64 GB memory</li><li>Primary function: submitting jobs to the queuing system</li><li>Secondary function: development; code editing and running small (under 50 % CPU and under 1 GB RAM) sample jobs</li></ul></li><li>Owl<ul><li>Resources: 16 cores, 64 GB memory</li><li>Primary function: testing; running test sets of jobs</li><li>Secondary function: submitting jobs to the queuing system</li></ul></li><li>Globus<ul><li>Resources: 32 cores, 32 GB memory</li><li>Primary function: submitting jobs to the queuing system</li><li>Secondary function: development; code editing and running small (under 50 % CPU and under 1 GB RAM) sample jobs</li></ul></li></ul><h3 id=worker-nodes>Worker Nodes</h3><ul><li>Batch<ul><li>c01-c48: each with 64 AMD cores and 512 GB memory</li></ul></li><li>Highmem<ul><li>h01-h06: each with 32 Intel cores and 1024 GB memory</li></ul></li><li>GPU<ul><li>gpu01-gpu02: each with 32 (HT) cores Intel Haswell CPUs and 2 x NVIDIA Tesla K80 GPUs (~10000 CUDA cores each) and 128 GB memory</li><li>gpu03-gpu04: each with 32 (HT) cores Intel Haswell CPUs and 4 x NVIDIA Tesla K80 GPUs (~10000 CUDA cores each) and 128 GB memory</li></ul></li><li>Intel<ul><li>i01-i40: each with 32 Intel Broadwell cores and 512 GB memory</li></ul></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-79fc43e3b0910006e7d7e5b6957bd2b1>2.5 - Login</h1><h2 id=login>Login</h2><p>We are moving all accounts to a more secure method of authentication for logging into the cluster.
Passwords alone will no longer be allowed, but rather <a href=#passwordduo>Password+DUO</a> or <a href=#ssh-keys>SSH Keys</a>.</p><p>Roll-Out Plan:</p><ol><li>Old (password) and new (secure) authentication methods are provided through <code>cluster.hpcc.ucr.edu</code> and <code>secure.hpcc.ucr.edu</code> respectively.</li><li>Users configure new authentication method.</li><li>Users log into the cluster using host <code>secure.hpcc.ucr.edu</code>.</li><li>After the authentication switch over deadline (TBD), host <code>cluster.hpcc.ucr.edu</code> switches over to new (secure) authentication methods. The old (password) authentication method is completely deprecated.</li></ol><h2 id=secure-authentication>Secure Authentication</h2><p>There are two methods of authentication that the cluster supports:</p><ol><li><a href=#passwordduo>Password+DUO</a></li><li><a href=#ssh-keys>SSH Keys</a></li></ol><h3 id=passwordduo>Password+Duo</h3><p>The <code>Password+DUO</code> combination method will only work if your UCR NetID matches your cluster username.
If these two match then first check if you already have DUO installed and configured on a mobile device.
If you already have used DUO with other UCR campus multi-factor enabled sites or utilites, great!
Otherwise, if you have not yet installed, nor configured DUO on a mobile device, then you will need to do so by enrolling:
<a href=https://cnc.ucr.edu/mfa/enrollment.html>https://cnc.ucr.edu/mfa/enrollment.html</a></p><p>Once you have DUO installed and configured on your mobile device, then retrieve your password for the cluster.
If you have a new account then your password was emailed to you when your account was created.</p><p>In order to test this try to log into the cluster through the <code>secure</code> server:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ssh username@secure.hpcc.ucr.edu
</code></pre></div><p>Remember to replace <code>username</code> with your real cluster username, which should also match your UCR NetID.</p><p>Assuming that you have already installed and configured DUO on a mobile device, then when attempting to login you will be first asked to provide your password, and then you will need to choose your DUO authentication option to validate your login attempt.
Depending on how you chose to configure/enrolling your mobile device, you may see multiple options.</p><p>DUO uses either an option for DUO authentication via <code>Push</code> which uses the mobile app, or via <code>SMS</code> which sends a code as a text message to your phone.
Choose whichever option works best for you.</p><p>After logging in successfully, you are expected to update your password with the <code>passwd</code> command.</p><p>For more general information regarding Multi-Factor Authentication and DUO, please visit the following:
<a href=https://cnc.ucr.edu/mfa/how.html>https://cnc.ucr.edu/mfa/how.html</a></p><h3 id=ssh-keys>SSH Keys</h3><p>SSH keys can only be setup if you already have access to the cluster.
This is becuase in order to get this working a file needs to be placed in your home directory on the cluster.</p><p>When using SSH key authentication, you will need to create a public and a pritate key.
This is analogous to how a key and a lock are used in the real world, one uniquely fits to the other.
Only when your private key &ldquo;fits&rdquo; the public key, can you be granted access.</p><p>To create the key pair run the following command on your computer (<a href=manuals_linux-basics_intro#mac>Terminal</a>/<a href=manuals_linux-basics_intro#windows>MobaXterm</a>):</p><pre><code># Create SSH directory
mkdir -p ~/.ssh

# Create key pair (Private and Public)
ssh-keygen -t rsa -f ~/.ssh/id_rsa
</code></pre><p>Once the command has completed, you will find two files in your <code>~/.ssh</code> directory.</p><pre><code># List files in SSH directory
ls ~/.ssh/
  id_rsa
  id_rsa.pub
</code></pre><p>The <code>id_rsa</code> file is your private key and the <code>id_rsa.pub</code> is your public key.
You will need to copy your public key to the cluster, creating the <code>authorized_keys</code> file.</p><p>From your computer (<a href=manuals_linux-basics_intro#mac>Terminal</a>/<a href=manuals_linux-basics_intro#windows>MobaXterm</a>) run the following:</p><pre><code>scp .ssh/id_rsa.pub username@cluster.hpcc.ucr.edu:.ssh/authorized_keys
</code></pre><p>If the <code>authorized_keys</code> file already exists, you can just append your new public key, like so:</p><pre><code>scp .ssh/id_rsa.pub username@cluster.hpcc.ucr.edu:tmpkey &amp;&amp; ssh username@cluster.hpcc.ucr.edu &quot;cat tmpkey &gt;&gt; ~/.ssh/authorized_keys &amp;&amp; rm tmpkey&quot;
</code></pre><p>In order to test this try to log into the cluster through the <code>secure</code> server:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ssh username@secure.hpcc.ucr.edu
</code></pre></div><p>Remember to replace <code>username</code> with your real cluster username, which should also match your UCR NetID.</p><blockquote><p>Note: MS Windows (MobaXterm) can also use the graphical SSH keys manager &ldquo;MobaKeyGen&rdquo; (from the &ldquo;Tools&rdquo; menu).</p></blockquote><h2 id=file-transfers>File Transfers</h2><p>We support <code>FileZilla</code> as the recommended graphical file transfer application. If you are comfortable with the command line that is typically easier to use.
However, there may be times when selecting multiple files from a graphical application is prefered.</p><p>When using <code>FileZilla</code> you must create a new site, just click <code>File -> Site Manager</code>.
From the new window click <code>New Site</code>.</p><p>On the right pane fill in the information as follows:</p><pre><code>Protocol    SFTP - SSH File Transfer Protocol
Host        secure.hpcc.ucr.edu
Port        22
</code></pre><p>The <code>Logon Type</code> can be either <code>Interactive</code> or <code>Key File</code>, this depends on if you have setup <a href=#passwordduo>Password+DUO</a> or <a href=#ssh-keys>SSH Keys</a> respectively.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-7526eb56ba93fa593a9ed0234144b199>2.6 - Managing Jobs</h1><h2 id=what-is-a-job>What is a Job?</h2><p>Submitting and managing jobs is at the heart of using the cluster. A &lsquo;job&rsquo; refers to the script, pipeline or experiment that you run on the nodes in the cluster.</p><h2 id=partitions>Partitions</h2><p>In the past we used queues under the old Torque system, we now refer to these logically grouped nodes as partitions. There are several different partitions available for cluster users to send jobs to:</p><ul><li>intel<ul><li>Default partition</li><li>Nodes: i01-02,i17-i40</li><li>Cores: Intel, 256 per user</li><li>RAM: 1 GB default</li><li>Time (walltime): 168 hours (7 days) default</li></ul></li><li>batch<ul><li>Nodes: c01-c48</li><li>Cores: AMD, 256 per user</li><li>RAM: 1 GB default</li><li>Time (walltime): 168 hours (7 days) default</li></ul></li><li>highmem<ul><li>Nodes: h01-h06</li><li>Cores: Intel, 32 per user</li><li>RAM: 100 GB min and 1000 GB max</li><li>Time (walltime): 48 hours (2 days) default</li></ul></li><li>gpu<ul><li>Nodes: gpu01-gpu05</li><li>GPUs: 8 per group</li><li>RAM: 1 GB default</li><li>Time (walltime): 48 hours (2 days) default</li></ul></li><li>short<ul><li>Nodes: Mixed set of nodes from batch, intel, and group partitions</li><li>Cores: AMD/Intel, 256 per user</li><li>RAM: 1 GB default</li><li>Time (walltime): 2 hours Maximum</li></ul></li><li>Group Partition<ul><li>This partition is unique to the group, if your lab has purchased nodes then you will have a priority partition with the same name as your group (ie. girkelab).
In order to submit a job to different partitions add the optional &lsquo;-p&rsquo; parameter with the name of the partition you want to use:</li></ul></li></ul><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sbatch -p batch SBATCH_SCRIPT.sh
sbatch -p highmem SBATCH_SCRIPT.sh
sbatch -p gpu SBATCH_SCRIPT.sh
sbatch -p intel SBATCH_SCRIPT.sh
sbatch -p mygroup SBATCH_SCRIPT.sh
</code></pre></div><h2 id=slurm>Slurm</h2><p>Slurm is now our default queuing system across all head nodes. <a href=#getting-started>SSH directly into the cluster</a> and your connection will be automatically load balanced to a head node:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ssh -XY cluster.hpcc.ucr.edu
</code></pre></div><h3 id=resources-and-limits>Resources and Limits</h3><p>To see your limits you can do the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>slurm_limits
</code></pre></div><p>Check total number of cores used by your group in the all partitions:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>group_cpus
</code></pre></div><p>However this does not tell you when your job will start, since it depends on the duration of each job.
The best way to do this is with the &ldquo;&ndash;start&rdquo; flag on the squeue command:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>squeue --start -u <span style=color:#000>$USER</span>
</code></pre></div><h3 id=submitting-jobs>Submitting Jobs</h3><p>There are 2 basic ways to submit jobs; non-interactive, interactive. Slurm will automatically start within the directory where you submitted the job from, so keep that in mind when you use relative file paths.
Non-interactive submission of a SBATCH script:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sbatch SBATCH_SCRIPT.sh
</code></pre></div><p>Here is an example of an SBATCH script:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#8f5902;font-style:italic>#!/bin/bash -l
</span><span style=color:#8f5902;font-style:italic></span>
<span style=color:#8f5902;font-style:italic>#SBATCH --nodes=1</span>
<span style=color:#8f5902;font-style:italic>#SBATCH --ntasks=1</span>
<span style=color:#8f5902;font-style:italic>#SBATCH --cpus-per-task=10</span>
<span style=color:#8f5902;font-style:italic>#SBATCH --mem=10G</span>
<span style=color:#8f5902;font-style:italic>#SBATCH --time=1-00:15:00     # 1 day and 15 minutes</span>
<span style=color:#8f5902;font-style:italic>#SBATCH --mail-user=useremail@address.com</span>
<span style=color:#8f5902;font-style:italic>#SBATCH --mail-type=ALL</span>
<span style=color:#8f5902;font-style:italic>#SBATCH --job-name=&#34;just_a_test&#34;</span>
<span style=color:#8f5902;font-style:italic>#SBATCH -p intel # This is the default partition, you can use any of the following; intel, batch, highmem, gpu</span>

<span style=color:#8f5902;font-style:italic># Print current date</span>
date

<span style=color:#8f5902;font-style:italic># Load samtools</span>
module load samtools

<span style=color:#8f5902;font-style:italic># Concatenate BAMs</span>
samtools cat -h header.sam -o out.bam in1.bam in2.bam

<span style=color:#8f5902;font-style:italic># Print name of node</span>
hostname
</code></pre></div><p>The above job will request 1 node, 10 cores (parallel threads), 10GB of memory, for 1 day and 15 minutes. An email will be sent to the user when the status of the job changes (Start, Failed, Completed).
For more information regarding parallel/multi core jobs refer to <a href=#parallelization>Parallelization</a>.</p><p>Interactive submission:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>srun --pty bash -l
</code></pre></div><p>If you do not specify a partition then the intel partition is used by default.</p><p>Here is a more complete example:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>srun --x11 --mem<span style=color:#ce5c00;font-weight:700>=</span>1gb --cpus-per-task <span style=color:#0000cf;font-weight:700>1</span> --ntasks <span style=color:#0000cf;font-weight:700>1</span> --time 10:00:00 --pty bash -l
</code></pre></div><p>The above example enables X11 forwarding and requests, 1GB of memory, 1 cores, for 10 hours within an interactive session.</p><h3 id=monitoring-jobs>Monitoring Jobs</h3><p>To check on your jobs states, run the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>squeue -u <span style=color:#000>$USER</span> --start
</code></pre></div><p>To list all the details of a specific job, run the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>scontrol show job JOBID
</code></pre></div><p>To view past jobs and their details, run the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sacct -u <span style=color:#000>$USER</span> -l
</code></pre></div><p>You can also adjust the start <code>-S</code> time and/or end <code>-E</code> time to view, using the YYYY-MM-DD format.
For example, the following command uses start and end times:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sacct -u <span style=color:#000>$USER</span> -S 2018-01-01 -E 2018-08-30 -l <span style=color:#000;font-weight:700>|</span> less -S <span style=color:#8f5902;font-style:italic># Type &#39;q&#39; to quit</span>
</code></pre></div><h3 id=canceling-jobs>Canceling Jobs</h3><p>In cancel/stop your job run the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>scancel &lt;JOBID&gt;
</code></pre></div><p>You can also cancel multiple jobs:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>scancel &lt;JOBID1&gt; &lt;JOBID2&gt; &lt;JOBID3&gt;
</code></pre></div><p>If you want to cancel/stop/kill ALL your jobs it is possible with the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#8f5902;font-style:italic># Be very careful when running this, it will kill all your jobs.</span>
squeue --user <span style=color:#000>$USER</span> --noheader --format <span style=color:#4e9a06>&#39;%i&#39;</span> <span style=color:#000;font-weight:700>|</span> xargs scancel
</code></pre></div><p>For more information please refer to <a href=https://slurm.schedmd.com/scancel.html title="Slurm scancel doc">Slurm scancel documentation</a>.</p><h3 id=advanced-jobs>Advanced Jobs</h3><p>There is a third way of submitting jobs by using steps.
Single Step submission:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>srun &lt;command&gt;
</code></pre></div><p>Under a single step job your command will hang until appropriate resources are found and when the step command is finished the results will be sent back on STDOUT. This may take some time depending on the job load of the cluster.
Multi Step submission:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>salloc -N <span style=color:#0000cf;font-weight:700>4</span> bash -l
srun &lt;command&gt;
...
srun &lt;command&gt;
<span style=color:#204a87>exit</span>
</code></pre></div><p>Under a multi step job the salloc command will request resources and then your parent shell will be running on the head node. This means that all commands will be executed on the head node unless preceeded by the srun command. You will also need to exit this shell in order to terminate your job.</p><h3 id=highmem-jobs>Highmem Jobs</h3><p>The highmem partition does not have a default amount of memory set, however it does has a minimum limit of 100GB per job. This means that you need to explicity request at least 100GB or more of memory.</p><p>Non-Interactive:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sbatch -p highmem --mem<span style=color:#ce5c00;font-weight:700>=</span>100g --time<span style=color:#ce5c00;font-weight:700>=</span>24:00:00 SBATCH_SCRIPT.sh
</code></pre></div><p>Interactive</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>srun -p highmem --mem<span style=color:#ce5c00;font-weight:700>=</span>100g --time<span style=color:#ce5c00;font-weight:700>=</span>24:00:00 --pty bash -l
</code></pre></div><p>Of course you should adjust the time argument according to your job requirements.</p><h3 id=gpu-jobs>GPU Jobs</h3><p>GPU nodes have multiple GPUs, and very in type (K80 or P100). This means you need to request how many GPUs and of what type that you would like to use.</p><p>To request a gpu of any type, only indicate how many GPUs you would like to use.</p><p>Non-Interactive:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sbatch -p gpu --gres<span style=color:#ce5c00;font-weight:700>=</span>gpu:1 --mem<span style=color:#ce5c00;font-weight:700>=</span>100g --time<span style=color:#ce5c00;font-weight:700>=</span>1:00:00 SBATCH_SCRIPT.sh
</code></pre></div><p>Interactive</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>srun -p gpu --gres<span style=color:#ce5c00;font-weight:700>=</span>gpu:4 --mem<span style=color:#ce5c00;font-weight:700>=</span>100g --time<span style=color:#ce5c00;font-weight:700>=</span>1:00:00 --pty bash -l
</code></pre></div><p>Since the HPCC Cluster has two types of GPUs installed (K80s and P100s), GPUs can be requested explicitly by type.</p><p>Non-Interactive:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sbatch -p gpu --gres<span style=color:#ce5c00;font-weight:700>=</span>gpu:k80:1 --mem<span style=color:#ce5c00;font-weight:700>=</span>100g --time<span style=color:#ce5c00;font-weight:700>=</span>1:00:00 SBATCH_SCRIPT.sh
sbatch -p gpu --gres<span style=color:#ce5c00;font-weight:700>=</span>gpu:p100:1 --mem<span style=color:#ce5c00;font-weight:700>=</span>100g --time<span style=color:#ce5c00;font-weight:700>=</span>1:00:00 SBATCH_SCRIPT.sh
</code></pre></div><p>Interactive</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>srun -p gpu --gres<span style=color:#ce5c00;font-weight:700>=</span>gpu:k80:1 --mem<span style=color:#ce5c00;font-weight:700>=</span>100g --time<span style=color:#ce5c00;font-weight:700>=</span>1:00:00 --pty bash -l
srun -p gpu --gres<span style=color:#ce5c00;font-weight:700>=</span>gpu:p100:1 --mem<span style=color:#ce5c00;font-weight:700>=</span>100g --time<span style=color:#ce5c00;font-weight:700>=</span>1:00:00 --pty bash -l
</code></pre></div><p>Of course you should adjust the time argument according to your job requirements.</p><p>Once your job starts your code must reference the environment variable &ldquo;CUDA_VISIBLE_DEVICES&rdquo; which will indicate which GPUs have been assigned to your job. Most CUDA enabled software, like MegaHIT, will check this environment variable and automatically limit accordingly.</p><p>For example, when reserving 4 GPUs for a NAMD2 job:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#204a87>echo</span> <span style=color:#000>$CUDA_VISIBLE_DEVICES</span>
0,1,2,3
namd2 +idlepoll +devices <span style=color:#000>$CUDA_VISIBLE_DEVICES</span> MD1.namd
</code></pre></div><p>Each group is limited to a maximum of 8 GPUs on the gpu partition. Please be respectful of others and keep in mind that the GPU nodes are a limited shared resource.
Since the CUDA libraries will only run with GPU hardward, development and compiling of code must be done within a job session on a GPU node.</p><p>Here are a few more examples of jobs that utilize more complex features (ie. array, dependency, MPI etc):
<a href=https://github.com/ucr-hpcc/hpcc_slurm_examples>Slurm Examples</a></p><h3 id=web-browser-access>Web Browser Access</h3><h4 id=ports>Ports</h4><p>Some jobs require web browser access in order to utilize the software effectively.
These kinds of jobs typically use (bind) ports in order to provide a graphical user interface (GUI) through a web browser.
Users are able to run jobs that use (bind) ports on a compute node.
Any port can be used on any compute node, as long as the port number is greater than 1000 and it is not already in use (bound).</p><h4 id=tunneling>Tunneling</h4><p>Once a job is running on a compute node and bound to a port, you may access this compute node via a web browser.
This is accomplished by using 2 chained SSH tunnels to route traffic through our firewall.
This acts much like 2 runners in a relay race, handing the baton to the next runer, to get past a security checkpoint.</p><p>We will create a tunnel that goes though a headnode and connect to a compute node on a particular port:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ssh -NL 8888:NodeName:8888 username@cluster.hpcc.ucr.edu
</code></pre></div><p>Port 8888 (first) is the local port you will be using on your laptop.
NodeName is the compute node where where job is running, which can be found by using the <code>squeue -u $USER</code> command.
Port 8888 (second) is the remote port on the compute node.
Again, the NodeName and ports will be different depending on where your job runs and what port your job uses.</p><p>At this point you may need to provide a password to make the SSH tunnel.
Once this has succeeded, the command will hang (this is normal).
Leave this session connected, if you close it your tunnel will be closed.</p><p>Then open a browser on your local computer (PC/laptop) and point it to:</p><pre><code>http://localhost:8888
</code></pre><p>If your job uses TSL/SSL, so you may need to try https if the above does not work:</p><pre><code>https://localhost:8888
</code></pre><h4 id=examples>Examples</h4><p>A perfect example of this method is used for Jupyter Lab/Notebook.
For more details please refer to the following <a href=https://github.com/ucr-hpcc/hpcc_slurm_examples/tree/master/jupyter>Jupyter Example</a>.</p><h3 id=desktop-environments>Desktop Environments</h3><h4 id=vnc-server-cluster>VNC Server (cluster)</h4><p><strong>Start VNC Server</strong></p><p>Log into the cluster:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ssh username@cluster.hpcc.ucr.edu
</code></pre></div><p>The first time you run the vncserver it will need to be configured:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>vncserver -fg
</code></pre></div><p>You should set a password for yourself, and the read-only password is optional.</p><p>Then configure X Startup with the following command:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#204a87>echo</span> <span style=color:#4e9a06>&#39;/usr/bin/ssh-agent /usr/bin/dbus-launch --exit-with-session /usr/bin/gnome-session --session=gnome-classic&#39;</span> &gt; /rhome/<span style=color:#000>$USER</span>/.vnc/xstartup
</code></pre></div><p>After your vncserver is configured, submit a vncserver job to get it started:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sbatch -p short,batch --cpus-per-task<span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>4</span> --mem<span style=color:#ce5c00;font-weight:700>=</span>10g --time<span style=color:#ce5c00;font-weight:700>=</span>2:00:00 --wrap<span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#39;vncserver -fg&#39;</span> --output<span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#39;vncserver-%j.out&#39;</span>
</code></pre></div><blockquote><p>Note: Appropriate job resources should be requested based on the processes you will be running from within the VNC session.</p></blockquote><p>Check the contents of your job log to determine the <code>NodeName</code> and <code>Port</code> you were assigned:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>cat vncserver-*.out
</code></pre></div><p>The contents of your slurm job log should be similar to the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>vncserver

New <span style=color:#4e9a06>&#39;i54:1&#39;</span> desktop is i54:1

Creating default startup script /rhome/username/.vnc/xstartup
Starting applications specified in /rhome/username/.vnc/xstartup
Log file is /rhome/username/.vnc/i54:1.log
</code></pre></div><p>The VNC <code>Port</code> used should be 5900+N, N being the display number mentioned above in the format <code>NodeName</code>:<code>DisplayNumber</code> (ie. <code>i54:1</code>).
In this example (default), the port is <code>5901</code>, if this <code>Port</code> were already in use then the vncserver will automatically increment the DisplayNumber and you might find something like <code>i54:2</code> or <code>i54:3</code> and so on.</p><p><strong>Stop VNC Server</strong></p><p>To stop the vncserver, you can click on the logout option from the upper right hand menu from within your VNC desktop environment.
If you want to kill your vncserver manually, then you will need to do the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ssh NodeName <span style=color:#4e9a06>&#39;vncserver -kill :DisplayNumber&#39;</span>
</code></pre></div><p>You will need to replace <code>NodeName</code> with the node name of your where your job is running, and the <code>DisplayNumber</code> with the DisplayNumber from your slurm job log.</p><h4 id=vnc-client-desktoplaptop>VNC Client (Desktop/Laptop)</h4><p>After you know the <code>NodeName</code> and VNC <code>Port</code> you should be able to create an SSH tunnel to your vncserver, like so:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ssh -N -L Port:NodeName:Port cluster.hpcc.ucr.edu
</code></pre></div><p>Now let us create an SSH tunnel on your local machine (desktop/laptop) using the <code>NodeName</code> and VNC <code>Port</code> from above:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ssh -L 5901:i54:5901 cluster.hpcc.ucr.edu
</code></pre></div><p>After you have logged into the cluster with this shell, log into the node where your VNC server is running:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ssh NodeName
</code></pre></div><p>After you have logged into the correct <code>NodeName</code>, just let this terminal sit here, do not close it.</p><p>Then launch vncviewer on your local system (laptop/workstation), like so:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>vncviewer localhost:5901
</code></pre></div><p>After launching the vncviewer, and providing your VNC password (not your cluster password), you should be able to see a Linux desktop environment.</p><p>For more information regarding tunnels and VNC in MS Windows, please refer <a href=https://docs.ycrc.yale.edu/clusters-at-yale/access/vnc/>More VNC Info</a>.</p><h3 id=licenses>Licenses</h3><p>The cluster currently supports <a href=software_commercial>Commercial Software</a>. Since most of the licenses are campus wide there is no need to track individual jobs. One exception is the Intel Parallel Suite, which contains the Intel compilers.</p><p>The <code>--licenses</code> flag is used to request a license for Intel compilers, for example:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>srun --license<span style=color:#ce5c00;font-weight:700>=</span>intel:1 -p short --mem<span style=color:#ce5c00;font-weight:700>=</span>10g --cpus-per-task<span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>10</span> --time<span style=color:#ce5c00;font-weight:700>=</span>2:00:00 --pty bash -l
module load intel
icc -help
</code></pre></div><p>The above interactive submission will request 1 Intel license, 10GB of RAM, 10 CPU cores for 2 hours on the short partition.
The short parititon can only be used for a maximum of 2 hours, however for compilation this could be sufficient.
It is recommended that you separate your compilation job from your computation/analysis job.
This way you will only have the license checked out for the duration of compilation, and not the during the execution of the analysis.</p><h2 id=parallelization>Parallelization</h2><p>There are 3 major ways to parallelize work on the cluster:</p><ol><li>Batch</li><li>Thread</li><li>MPI</li></ol><h3 id=parallel-methods>Parallel Methods</h3><p>For <strong>batch</strong> jobs, all that is required is that you have a way to split up the data and submit multiple jobs running with the different chunks.
Some data sets, for example a FASTA file is very easy to split up (ie. fasta-splitter). This can also be more easily achieved by submitting an array job. For more details please refer to <a href=#advanced-jobs>Advanced Jobs</a>.</p><p>For <strong>threaded</strong> jobs, your software must have an option referring to &ldquo;number of threads&rdquo; or &ldquo;number of processors&rdquo;. Once the thread/processor option is identified in the software, (ie. blastn flag <code>-num_threads 4</code>) you can use that as long as you also request the same number of CPU cores (ie. slurm flag <code>--cpus-per-task=4</code>).</p><p>For <strong>MPI</strong> jobs, your software must be MPI enabled. This generally means that it was compiled with MPI libraries. Please refer to the user manual of the software you wish to use as well as our documentation regarding <a href=#mpi>MPI</a>. It is important that the number of cores used is equal to the number requested.</p><p>In Slurm you will need 2 different flags to request cores, which may seem similar, however they have different purposes:</p><ul><li>The <code>--cpus-per-task=N</code> will provide N number of virtual cores with locality as a factor.
Closer virtual cores can be faster, assuming there is a need for rapid communication between threads.
Generally, this is good for threading, however not so good for independent subprocesses nor for MPI.</li><li>The <code>--ntasks=N</code> flag will provide N number of physical cores on a single or even multiple nodes.
These cores can be further away, since the need for physical CPUs and dedicated memory is more important.
Generally this is good for independent subprocesses, and MPI, however not so good for threading.</li></ul><p>Here is a table to better explain when to use these Slurm options:</p><p>| | Single Threaded | Multi Threaded (OpenMP) | MPI only | MPI + Multi Threaded (hybrid) |</p><table><thead><tr><th>Slurm Flag</th><th style=text-align:center></th><th style=text-align:center></th><th style=text-align:center></th><th style=text-align:center></th></tr></thead><tbody><tr><td><code>--cpus-per-task</code></td><td style=text-align:center></td><td style=text-align:center>X</td><td style=text-align:center></td><td style=text-align:center>X</td></tr><tr><td><code>--ntasks</code></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center>X</td><td style=text-align:center>X</td></tr></tbody></table><p>As you can see:</p><ol><li>A single threaded job would use neither Slurm option, since Slurm already assumes at least a single core.</li><li>A multi threaded OpenMP job would use <code>--cpus-per-task</code>.</li><li>A MPI job would use <code>--ntasks</code>.</li><li>A Hybrid job would use both.</li></ol><p>For more details on how these Slurm options work please review <a href=https://slurm.schedmd.com/mc_support.html>Slurm Multi-core/Multi-thread Support</a>.</p><h4 id=mpi>MPI</h4><p>MPI stands for the Message Passing Interface. MPI is a standardized API typically used for parallel and/or distributed computing.
The HPCC cluster has a custom compiled versions of MPI that allows users to run MPI jobs across multiple nodes.
These types of jobs have the ability to take advantage of hundreds of CPU cores symultaniously, thus improving compute time.</p><p>Many implementations of MPI exists, however we only support the following:</p><ul><li><a href=http://www.open-mpi.org/>Open MPI</a></li><li><a href=http://www.mpich.org/>MPICH</a></li><li><a href=https://software.intel.com/en-us/mpi-developer-guide-linux>IMPI</a></li></ul><p>For general information on MPI under Slurm look <a href=https://slurm.schedmd.com/mpi_guide.html>here</a>.
If you need to compile an MPI application then please email <a href=mailto:support@hpcc.ucr.edu>support@hpcc.ucr.edu</a> for assistance.</p><p>When submitting MPI jobs it is best to ensure that the nodes are identical, since MPI is sensitive to differences in CPU and/or memory speeds.
The <code>batch</code> and <code>intel</code> partitions are designed to be homogeneous, however, the <code>short</code> partition is a mixed set of nodes.
When using the <code>short</code> partition for MPI append the constraint flag for Slurm.</p><p><strong>Short Example</strong></p><p>Here is an example that shows how to ensure that your job will only run on <code>intel</code> nodes from the <code>short</code> partition:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sbatch -p short --constraint<span style=color:#ce5c00;font-weight:700>=</span>intel myJobScript.sh
</code></pre></div><p><strong>NAMD Example</strong></p><p>To run a NAMD2 process as an OpenMPI job on the cluster:</p><ol><li><p>Log-in to the cluster</p></li><li><p>Create SBATCH script</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#8f5902;font-style:italic>#!/bin/bash -l
</span><span style=color:#8f5902;font-style:italic></span>
<span style=color:#8f5902;font-style:italic>#SBATCH -J c3d_cr2_md</span>
<span style=color:#8f5902;font-style:italic>#SBATCH -p batch</span>
<span style=color:#8f5902;font-style:italic>#SBATCH --ntasks=32</span>
<span style=color:#8f5902;font-style:italic>#SBATCH --mem=16gb</span>
<span style=color:#8f5902;font-style:italic>#SBATCH --time=01:00:00</span>

<span style=color:#8f5902;font-style:italic># Load needed modules</span>
<span style=color:#8f5902;font-style:italic># You could also load frequently used modules from within your ~/.bashrc</span>
module load slurm <span style=color:#8f5902;font-style:italic># Should already be loaded</span>
module load openmpi <span style=color:#8f5902;font-style:italic># Should already be loaded</span>
module load namd

<span style=color:#8f5902;font-style:italic># Run job utilizing all requested processors</span>
<span style=color:#8f5902;font-style:italic># Please visit the namd site for usage details: http://www.ks.uiuc.edu/Research/namd/</span>
mpirun --mca btl ^tcp namd2 run.conf <span style=color:#000;font-weight:700>&amp;</span>&gt; run_namd.log
</code></pre></div></li><li><p>Submit SBATCH script to Slurm queuing system</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sbatch run_namd.sh
</code></pre></div></li></ol><p><strong>Maker Example</strong></p><p>OpenMPI does not function properly with Maker, you must use MPICH.
Our version of MPICH does not use the mpirun/mpiexec wrappers, instead use srun:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#8f5902;font-style:italic>#!/bin/bash -l
</span><span style=color:#8f5902;font-style:italic></span>
<span style=color:#8f5902;font-style:italic>#SBATCH -p intel</span>
<span style=color:#8f5902;font-style:italic>#SBATCH --ntasks=32</span>
<span style=color:#8f5902;font-style:italic>#SBATCH --mem=16gb</span>
<span style=color:#8f5902;font-style:italic>#SBATCH --time=01:00:00</span>

<span style=color:#8f5902;font-style:italic># Load maker</span>
module load maker/2.31.11

mpirun maker <span style=color:#8f5902;font-style:italic># Provide appropriate maker options here</span>

</code></pre></div><h2 id=more-examples>More examples</h2><p>The range of differing jobs and how to submit them is endless:</p><pre><code>1. Singularity containers
2. Database services
3. Graphical user interfaces
4. Etc ...
</code></pre><p>For a growing list of examples please visit <a href=https://github.com/ucr-hpcc/hpcc_slurm_examples>HPCC Slurm Examples</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-2402efae435cf116cdf7d3495c902c12>2.7 - Package Management</h1><h2 id=python>Python</h2><p>The scope of this manual is a brief introduction on how to manage Python packages.</p><h3 id=python-versions>Python Versions</h3><p>Different Python versions do not play nice with each other. It is best to only load one Python module at any given time.
The miniconda2 module for Python is the default version. This will enable users to leverage the conda installer, but with as few Python packages pre-installed as possible. This is to avoid conflicts with future needs of individuals.</p><h4 id=conda>Conda</h4><p>We have several Conda software modules:</p><ol><li>miniconda2 - Basic Python 2 install (default)</li><li>miniconda3 - Basic Python 3 install</li><li>anaconda2 - Full Python 2 install</li><li>anaconda3 - Full Python 3 install
For more information regarding our module system please refer to <a href=manuals_linux-cluster_start.html#modules>Environment Modules</a>.</li></ol><p>The miniconda modules are very basic installs, however users can choose to unload this basic install for a fuller one (anaconda), like so:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>module load miniconda2 <span style=color:#8f5902;font-style:italic>#This is the default</span>
</code></pre></div><p>After loading anaconda, you will see that there are many more Python packages installed (ie. numpy, scipy, pandas, jupyter, etc&mldr;).
For a list of installed Python packages try the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>pip list
</code></pre></div><h4 id=virtual-environments>Virtual Environments</h4><p>Sometimes it is best to create your own environment in which you have full control over package installs.
Conda allows you to do this through virtual environments.</p><h5 id=initialize>Initialize</h5><p>Conda will now auto initialize when you load the corresponding module. No need to run the <code>conda init</code> or make any modifications to your <code>~/.bashrc</code> file.</p><h5 id=configure>Configure</h5><p>Installing many packages can consume a large (ie. >20GB) amount of disk space, thus it is recommended to store conda environments under your bigdata space.
If you have bigdata, create the <code>.condarc</code> file (otherwise conda environments will be created under your home directory).</p><p>Create the file <code>.condarc</code> in your home, with the following content:</p><pre><code>channels:
  - defaults
pkgs_dirs:
  - ~/bigdata/.conda/pkgs
envs_dirs:
  - ~/bigdata/.conda/envs
auto_activate_base: false
</code></pre><p>Then create your Python 2 conda environment, like so:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>conda create -n NameForNewEnv <span style=color:#000>python</span><span style=color:#ce5c00;font-weight:700>=</span>2.7.14 <span style=color:#8f5902;font-style:italic># Many Python versions are available</span>
</code></pre></div><p>For Python 3, please use the miniconda3, like so:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>module unload miniconda2
module load miniconda3
conda create -n NameForNewEnv <span style=color:#000>python</span><span style=color:#ce5c00;font-weight:700>=</span>3.6.4 <span style=color:#8f5902;font-style:italic># Many Python versions are available</span>
</code></pre></div><h5 id=activating>Activating</h5><p>Once your virtual environment has been created, you need to activate it before you can use it:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>conda activate NameForNewEnv
</code></pre></div><h5 id=deactivating>Deactivating</h5><p>In order to exit from your virtual environment, do the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>conda deactivate
</code></pre></div><h5 id=installing-packages>Installing packages</h5><p>Here is a simple example for installing packages under your Python virtual environment via conda:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>conda install -n NameForNewEnv PackageName
</code></pre></div><p>You may need to enable an additional channel to install the package (refer to your package&rsquo;s documentation):</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>conda install -n NameForNewEnv -c ChannelName PackageName
</code></pre></div><h5 id=cloning>Cloning</h5><p>It is possible for you to copy an existing environment into a new environment:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>conda create --name AnotherNameForNewEnv --clone NameForNewEnv
</code></pre></div><h5 id=listing-environments>Listing Environments</h5><p>Run the following to get a list of currently installed conda evironments:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>conda env list
</code></pre></div><h5 id=removing>Removing</h5><p>If you wish to remove a conda environment run the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>conda env remove --name myenv
</code></pre></div><h4 id=more-info>More Info</h4><p>For more information regarding conda please visit <a href=https://conda.io/docs/user-guide/>Conda Docs</a>.</p><h3 id=jupyter>Jupyter</h3><p>You can run jupyter as an interactive job using <a href=manuals_linux-cluster_jobs.html#web-browser-access>tunneling</a>, or you can use the web portal <a href=https://jupyter.hpcc.ucr.edu>Jupyter-Hub</a>.</p><h4 id=virtual-environment>Virtual Environment</h4><p>In order to enable your conda virtual environemnt within the Jupyter web portal you will need to do the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#8f5902;font-style:italic># Create a virtual environment, if you don&#39;t already have one</span>
conda create -n ipykernel_py2 <span style=color:#000>python</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>2</span> ipykernel

<span style=color:#8f5902;font-style:italic># Load the new environment</span>
conda activate ipykernel_py2

<span style=color:#8f5902;font-style:italic># Install kernel</span>
python -m ipykernel install --user --name myenv --display-name <span style=color:#4e9a06>&#34;JupyterPy2&#34;</span>
</code></pre></div><p>Now when you visit <a href=https://jupyter.hpcc.ucr.edu>Jupyter-Hub</a> you should see the option &ldquo;JupyterPy2&rdquo; when you click the &ldquo;New&rdquo; dropdown menu in the upper left corner of the home page.</p><h4 id=r>R</h4><p>For instructions on how to configure your R environment please visit <a href=https://github.com/IRkernel/IRkernel>IRkernel</a>.
Since we should already have IRkernel install in the latest version of R, you would only need to do the following within R:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-R data-lang=R><span style=color:#000>IRkernel</span><span style=color:#ce5c00;font-weight:700>::</span><span style=color:#000>installspec</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>name</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#4e9a06>&#39;ir44&#39;</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>displayname</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#4e9a06>&#39;R 4.0.1&#39;</span><span style=color:#000;font-weight:700>)</span>
</code></pre></div><h2 id=r-1>R</h2><p>This section is regarding how to manage R packages.</p><h3 id=current-r-version>Current R Version</h3><p>Currently the default version of R is 4.0.1 and is loaded automatically for you.
This can be seen by running:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>module list
</code></pre></div><h3 id=older-r-versions>Older R Versions</h3><p>You can load older versions of R with the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>module unload R
module load R/3.4.2
</code></pre></div><h3 id=installing-r-packages>Installing R Packages</h3><p>The default version of R has many of the most popular R packages available already installed.
It is also possible for you to install additional R packages in your local environments.</p><h4 id=bioconductor-packages>Bioconductor Packages</h4><p>To install from Bioconductor you can use the following method:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-R data-lang=R><span style=color:#000>BiocManager</span><span style=color:#ce5c00;font-weight:700>::</span><span style=color:#000>install</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>c</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#34;package-to-install&#34;</span><span style=color:#000;font-weight:700>,</span> <span style=color:#4e9a06>&#34;another-packages-to-install&#34;</span><span style=color:#000;font-weight:700>))</span>
<span style=color:#000>Update</span> <span style=color:#000>all</span><span style=color:#ce5c00;font-weight:700>/</span><span style=color:#000>some</span><span style=color:#ce5c00;font-weight:700>/</span><span style=color:#000>none</span><span style=color:#ce5c00;font-weight:700>?</span> <span style=color:#000>[a</span><span style=color:#ce5c00;font-weight:700>/</span><span style=color:#000>s</span><span style=color:#ce5c00;font-weight:700>/</span><span style=color:#000>n]</span><span style=color:#ce5c00;font-weight:700>:</span> <span style=color:#000>n</span>
</code></pre></div><p>For more information please visit <a href=https://www.bioconductor.org/install/>Bioconductor Install Page</a>.</p><h4 id=github-packages>GitHub Packages</h4><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-R data-lang=R><span style=color:#000>library</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>devtools</span><span style=color:#000;font-weight:700>)</span>
<span style=color:#000>install_github</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#34;duncantl/RGoogleDocs&#34;</span><span style=color:#000;font-weight:700>)</span> <span style=color:#8f5902;font-style:italic># replace name with the GitHub account/repo</span>
</code></pre></div><h4 id=local-packages>Local Packages</h4><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-R data-lang=R><span style=color:#000>install.packages</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#34;http://hartleys.github.io/QoRTs/QoRTs_LATEST.tar.gz&#34;</span><span style=color:#000;font-weight:700>,</span><span style=color:#000>repos</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#204a87;font-weight:700>NULL</span><span style=color:#000;font-weight:700>,</span><span style=color:#000>type</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;source&#34;</span><span style=color:#000;font-weight:700>)</span> <span style=color:#8f5902;font-style:italic># replace URL with your URL or local path to your .tar.gz file</span>
</code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-cb171105c20295006484cc7a3d475eb8>2.8 - Parallel Evaluations in R</h1><h1 id=overview>Overview</h1><p>R provides a variety of packages for parallel computations. One of the most
comprehensive parallel computing environments for R is <a href=https://mllg.github.io/batchtools/articles/batchtools.html><code>batchtools</code></a>
(formerly <code>BatchJobs</code>). It supports both multi-core and multi-node computations with and
without schedulers. By making use of cluster template files, most schedulers
and queueing systems are also supported (e.g. Torque, Sun Grid Engine, Slurm).</p><h2 id=r-code-of-this-section>R code of this section</h2><p>To simplify the evaluation of the R code of this page, the corresponding text version
is available for download from <a href=https://raw.githubusercontent.com/ucr-hpcc/ucr-hpcc.github.io/master/_support_docs/tutorials/batchtools_test.R>here</a>.</p><h2 id=parallelization-with-batchtools>Parallelization with batchtools</h2><p>The following introduces the usage of <code>batchtools</code> for a computer cluster using SLURM as scheduler (workload manager).</p><h2 id=set-up-working-directory-for-slurm>Set up working directory for SLURM</h2><p>First login to your cluster account, open R and execute the following lines. This will
create a test directory (here <code>mytestdir</code>), redirect R into this directory and then download
the required files:</p><ul><li><a href=https://github.com/ucr-hpcc/ucr-hpcc.github.io/blob/master/_support_docs/tutorials/slurm.tmpl><code>slurm.tmpl</code></a></li><li><a href=https://github.com/ucr-hpcc/ucr-hpcc.github.io/blob/master/_support_docs/tutorials/.batchtools.conf.R><code>.batchtools.conf.R</code></a></li></ul><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-r data-lang=r><span style=color:#000>dir.create</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#34;mytestdir&#34;</span><span style=color:#000;font-weight:700>)</span>
<span style=color:#000>setwd</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#34;mytestdir&#34;</span><span style=color:#000;font-weight:700>)</span>
<span style=color:#000>download.file</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#34;https://goo.gl/tLMddb&#34;</span><span style=color:#000;font-weight:700>,</span> <span style=color:#4e9a06>&#34;slurm.tmpl&#34;</span><span style=color:#000;font-weight:700>)</span>
<span style=color:#000>download.file</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#34;https://goo.gl/5HrYkE&#34;</span><span style=color:#000;font-weight:700>,</span> <span style=color:#4e9a06>&#34;.batchtools.conf.R&#34;</span><span style=color:#000;font-weight:700>)</span>
</code></pre></div><h2 id=load-package-and-define-some-custom-function>Load package and define some custom function</h2><p>This is the test function (here toy example) that will be run on the cluster for demonstration
purposes. It subsets the <code>iris</code> data frame by rows, and appends the host name and R version of each
node where the function was executed. The R version to be used on each node can be
specified in the <code>slurm.tmpl</code> file (under <code>module load</code>).</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-r data-lang=r><span style=color:#000>library</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#39;RenvModule&#39;</span><span style=color:#000;font-weight:700>)</span>
<span style=color:#000>module</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#39;load&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#4e9a06>&#39;slurm&#39;</span><span style=color:#000;font-weight:700>)</span> <span style=color:#8f5902;font-style:italic># Loads slurm among other modules</span>

<span style=color:#000>library</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>batchtools</span><span style=color:#000;font-weight:700>)</span>
<span style=color:#000>myFct</span> <span style=color:#ce5c00;font-weight:700>&lt;-</span> <span style=color:#000>function</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>x</span><span style=color:#000;font-weight:700>)</span> <span style=color:#000;font-weight:700>{</span>
	<span style=color:#000>result</span> <span style=color:#ce5c00;font-weight:700>&lt;-</span> <span style=color:#000>cbind</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>iris[x</span><span style=color:#000;font-weight:700>,</span> <span style=color:#0000cf;font-weight:700>1</span><span style=color:#ce5c00;font-weight:700>:</span><span style=color:#0000cf;font-weight:700>4</span><span style=color:#000;font-weight:700>,</span><span style=color:#000>]</span><span style=color:#000;font-weight:700>,</span>
	<span style=color:#000>Node</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#000>system</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#34;hostname&#34;</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>intern</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#204a87;font-weight:700>TRUE</span><span style=color:#000;font-weight:700>),</span>
	<span style=color:#000>Rversion</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#000>paste</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>R.Version</span><span style=color:#000;font-weight:700>()</span><span style=color:#000>[6</span><span style=color:#ce5c00;font-weight:700>:</span><span style=color:#0000cf;font-weight:700>7</span><span style=color:#000>]</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>collapse</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;.&#34;</span><span style=color:#000;font-weight:700>))</span>
<span style=color:#000;font-weight:700>}</span>
</code></pre></div><h2 id=submit-jobs-from-r-to-cluster>Submit jobs from R to cluster</h2><p>The following creates a <code>batchtools</code> registry, defines the number of jobs and resource requests, and then submits the jobs to the cluster
via SLURM.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-r data-lang=r><span style=color:#000>reg</span> <span style=color:#ce5c00;font-weight:700>&lt;-</span> <span style=color:#000>makeRegistry</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>file.dir</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;myregdir&#34;</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>conf.file</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;.batchtools.conf.R&#34;</span><span style=color:#000;font-weight:700>)</span>
<span style=color:#000>Njobs</span> <span style=color:#ce5c00;font-weight:700>&lt;-</span> <span style=color:#0000cf;font-weight:700>1</span><span style=color:#ce5c00;font-weight:700>:</span><span style=color:#0000cf;font-weight:700>4</span> <span style=color:#8f5902;font-style:italic># Define number of jobs (here 4)</span>
<span style=color:#000>ids</span> <span style=color:#ce5c00;font-weight:700>&lt;-</span> <span style=color:#000>batchMap</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>fun</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#000>myFct</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>x</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#000>Njobs</span><span style=color:#000;font-weight:700>)</span> 
<span style=color:#000>done</span> <span style=color:#ce5c00;font-weight:700>&lt;-</span> <span style=color:#000>submitJobs</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>ids</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>reg</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#000>reg</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>resources</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#000>list</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>partition</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;short&#34;</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>walltime</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>60</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>ntasks</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>1</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>ncpus</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>1</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>memory</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>1024</span><span style=color:#000;font-weight:700>))</span>
<span style=color:#000>waitForJobs</span><span style=color:#000;font-weight:700>()</span> <span style=color:#8f5902;font-style:italic># Wait until jobs are completed</span>
</code></pre></div><h2 id=summarize-job-status>Summarize job status</h2><p>After the jobs are completed one instect their status as follows.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-r data-lang=r><span style=color:#000>getStatus</span><span style=color:#000;font-weight:700>()</span> <span style=color:#8f5902;font-style:italic># Summarize job status</span>
<span style=color:#000>showLog</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>Njobs[1]</span><span style=color:#000;font-weight:700>)</span>
<span style=color:#8f5902;font-style:italic># killJobs(Njobs) # # Possible from within R or outside with scancel</span>
</code></pre></div><h2 id=accessassemble-results>Access/assemble results</h2><p>The results are stored as <code>.rds</code> files in the registry directory (here <code>myregdir</code>). One
can access them manually via <code>readRDS</code> or use various convenience utilities provided
by the <code>batchtools</code> package.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-r data-lang=r><span style=color:#000>readRDS</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#34;myregdir/results/1.rds&#34;</span><span style=color:#000;font-weight:700>)</span> <span style=color:#8f5902;font-style:italic># reads from rds file first result chunk</span>
<span style=color:#000>loadResult</span><span style=color:#000;font-weight:700>(</span><span style=color:#0000cf;font-weight:700>1</span><span style=color:#000;font-weight:700>)</span> 
<span style=color:#000>lapply</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>Njobs</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>loadResult</span><span style=color:#000;font-weight:700>)</span>
<span style=color:#000>reduceResults</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>rbind</span><span style=color:#000;font-weight:700>)</span> <span style=color:#8f5902;font-style:italic># Assemble result chunks in single data.frame</span>
<span style=color:#000>do.call</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#34;rbind&#34;</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>lapply</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>Njobs</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>loadResult</span><span style=color:#000;font-weight:700>))</span>
</code></pre></div><h2 id=remove-registry-directory-from-file-system>Remove registry directory from file system</h2><p>By default existing registries will not be overwritten. If required one can exlicitly
clean and delete them with the following functions.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-r data-lang=r><span style=color:#000>clearRegistry</span><span style=color:#000;font-weight:700>()</span> <span style=color:#8f5902;font-style:italic># Clear registry in R session</span>
<span style=color:#000>removeRegistry</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>wait</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>0</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>reg</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#000>reg</span><span style=color:#000;font-weight:700>)</span> <span style=color:#8f5902;font-style:italic># Delete registry directory</span>
<span style=color:#8f5902;font-style:italic># unlink(&#34;myregdir&#34;, recursive=TRUE) # Same as previous line</span>
</code></pre></div><h2 id=load-registry-into-r>Load registry into R</h2><p>Loading a registry can be useful when accessing the results at a later state or
after moving them to a local system.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-r data-lang=r><span style=color:#000>from_file</span> <span style=color:#ce5c00;font-weight:700>&lt;-</span> <span style=color:#000>loadRegistry</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#34;myregdir&#34;</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>conf.file</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;.batchtools.conf.R&#34;</span><span style=color:#000;font-weight:700>)</span>
<span style=color:#000>reduceResults</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>rbind</span><span style=color:#000;font-weight:700>)</span>
</code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-1dab12415a1ae5cd43e140ecef9dfe93>2.9 - Queue Policies</h1><h2 id=start-times>Start Times</h2><p>Start times are a great way to track your jobs:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>squeue -u <span style=color:#000>$USER</span> --start
</code></pre></div><p>Start times are rough estimates based on the current state of the queue.</p><h2 id=fair-share>Fair-Share</h2><p>Users that have not submitted any jobs in a long time usually have a higher priority over others that have ran jobs recently.
Thus the estimated start times can be extended to allow everyone their fair share of the system.
This prevents a few large groups from dominating the queuing system for long periods of time.</p><p>You can see with the <code>sqmore</code> command what priority your job has (list is sorted from lowest to highest priority).
You can also check to see how your group&rsquo;s priority is compared to other groups on the cluster with the &ldquo;sshare&rdquo; command.</p><p>For example:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sshare
</code></pre></div><p>It may also be useful to see your entire group&rsquo;s fairshare score and who has used the most shares:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sshare -A <span style=color:#000>$GROUP</span> --all
</code></pre></div><p>Lastley, if you only want to see your own fairshare score:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sshare -A <span style=color:#000>$GROUP</span> -u <span style=color:#000>$USER</span>
</code></pre></div><p>The fairshare score is a number between 0 and 1. The best score being 1, and the worst being 0.
The fairshare score approches zero the more resource you (or your group) consume.
Your individual consumption of resources (usage) does affect your entire group&rsquo;s fiarshare score.
The affects of your running/completed jobs on your fairshare score are halved each day (half-life).
Thus, after waiting several days without running any jobs, you should see an improvment in your fairshare score.</p><p>Here is a very good <a href=https://www.rc.fas.harvard.edu/fairshare/>explaination of fairshare</a>.</p><h2 id=priority>Priority</h2><p>The fairshare score and jobs queue wait time is used to calculate your job&rsquo;s priority.
You can use the <code>sprio</code> command to check the priority of your jobs:</p><pre><code>sprio -u $USER
</code></pre><p>Even if your group has a lower fairshare score, your job may still have a very high priority.
This would be likely due to the job&rsquo;s queue wait time, and it should start as soon as possible regardless of fairshare score.
You can use the <code>sqmore</code> command to see a list of all jobs sorted by priority.</p><h2 id=backfill>Backfill</h2><p>Some small jobs may start before yours, only if they can complete before yours starts and thus not negatively affecting your start time.</p><h2 id=priority-partition>Priority Partition</h2><p>Some groups on our system have purchased additional hardware. These nodes will not be affected by the fairshare score.
This is because jobs submitted to the group&rsquo;s partition will be evaluated first before any other jobs that have been submitted to those nodes from a different partition.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-33543218cb7f95b316141a36a8629e9f>2.10 - Security</h1><h2 id=protection-levels-and-classification>Protection Levels and Classification</h2><p>UCR protection levels, and data classifications are outlined by UCOP as a UC wide policy: <a href=https://security.ucop.edu/policies/institutional-information-and-it-resource-classification.html>UCOP Institutional Information and IT Resource Classification</a>
According to the above documentation, there are 4 levels of protection for 4 classifications of data:</p><p>| Protection Level | Policy | Examples |
|&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;|
| P1 - Minimal | IS-1 | Internet facing websites, press releases, anything intended for public use |
| P2 - Low | IS-2 | Unpublished research work, intellectual property NOT classified as P3 or P4 |
| P3 - Moderate | IS-3 | Research information classified by an Institutional Review Board as P3 (ie. dbGaP from NIH) |
| P4 - High | IS-4 | Protected Health Information (PHI/HIPAA), patient records, sensitive identifiable human subject research data, Social Security Numbers |</p><p>The HPC cluster could be compliant with with other security polices (ie. NIH), however the policy must be reviewed by our security team.</p><p>At this time the HPC cluster is not a IS-4 (P4) compliant cluster. If you have needs for very sensitive data, it may be best to work with UCSD and their <a href=https://sherlock.sdsc.edu/>Sherlock service</a>.
Our cluster is IS-3 compliant, however there are several responsibilities that users will need to adhere to.</p><h2 id=general-guidelines>General Guidelines</h2><p><span style=color:red>First, please contact us (<a href=mailto:support@hpcc.ucr.edu>support@hpcc.ucr.edu</a>) before transferring any data to the cluster.
After we have reviewed your needs, data classification and appropriate protection level, then it may be possible to proceed to use the HPCC.</span></p><p>Here are a few basic rules to keep in mind:</p><ul><li>Always be aware of access control methods (Unix permissions and ACLs), do not allow others to view the data (ie. chmod 400 filename)</li><li>Do not make unnecessary copies of the data</li><li>Do not transfer the data to insecure locations</li><li>Encrypt data when/where possible</li><li>Delete all data when it is no longer needed</li></ul><h2 id=access-controls>Access Controls</h2><p>When sharing files with others, it is imperative that proper permission are used.
However, basic Unix permissions (user,group,other) may not be adequate.
It is better to use ACLs in order to allow fine grained access to sensitive files.</p><h3 id=gpfs-acls>GPFS ACLs</h3><p>GPFS is used for most of our filesystems (/rhome and /bigdata) and it uses nfsv4 style ACLs.
Users are able to explicitly allow many individuals, or groups, access to specific files or directories.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#8f5902;font-style:italic># Get current permissions and store in acls file</span>
mmgetacl /path/to/file &gt; ~/acls.txt

<span style=color:#8f5902;font-style:italic># Edit acls file containing permissions</span>
vim ~/acls.txt

<span style=color:#8f5902;font-style:italic># Apply new permissions to file</span>
mmputacl -i ~/acls.txt /path/to/file

<span style=color:#8f5902;font-style:italic># Delete acls file</span>
rm ~/acls.txt
</code></pre></div><p>For more information regarding GPFS ACLs refer to the following: <a href=https://www.ibm.com/support/knowledgecenter/en/STXKQY_4.2.3/com.ibm.spectrum.scale.v4r23.doc/bl1adm_nfsv4syn.htm>GPFS ACLs</a></p><h3 id=xfs-acls>XFS ACLs</h3><p>The XFS filesystem is used for the CentOS operating system and typical unix locations (/,/var,/tmp,etc), as well as /secure.
For more information on how to use ACLs under XFS, please refer to the following: <a href=https://vishmule.com/2015/06/11/access-control-list-acl-permissions-in-rhel7centos7/>CentOS 7 XFS</a></p><blockquote><p>Note: ACLs are not applicable to gocryptfs, which is a FUSE filesystem, not GPFS nor XFS.</p></blockquote><h2 id=encryption>Encryption</h2><p>Under the IS-3 policy, P3 data encryption is mandatory.
It is best if you get into the habit of doing encryption in transit, as well as encryption at rest.
This means, when you move the data (transit) or when the data is not in use (rest), it should be encrypted.</p><h3 id=in-transit>In Transit</h3><p>When transferring files make sure that files are encrypted in flight with one of the following transfer protocols:</p><ul><li>SCP</li><li>SFTP</li><li>RSYNC (via SSH)</li></ul><p>The destination for sensitive data on the cluster must also be encrypted at rest under one of the follow secure locations:</p><ul><li>/dev/shm/ - This location is in RAM, so it does not exist at rest (ensure proper ACLs)</li><li>/secure - This location is encrypted at rest with AES 256 key length (ensure proper ACLs)</li><li>/run/user/$EUID/unencrypted - This location is manually managed, and should be created for access to unencrypted files.</li></ul><p>It is also possible to encrypt your files with GPG (<a href=https://kb.iu.edu/d/awio>GPG Example</a>), before they are transferred.
Thus, during transfer they will be GPG encrypted. However, decryption must occur in one of the secure locations mentioned above.</p><blockquote><p>Note: Never store passphrases/passwords/masterkeys in an unsecure location (ie. a plain text script under /rhome).</p></blockquote><h3 id=at-rest>At Rest</h3><p>There are 3 methods available on the cluster for encryption at rest:</p><ol><li>GPG encryption of files via the command line <a href=https://kb.iu.edu/d/awio>GPG Example</a>, however you must ensure proper ACLs and decryption must occur in a secure location.</li><li>The location &ldquo;/secure&rdquo; is encrypted and is mounted on the head nodes, however you must ensure proper ACLs.</li><li>Create your own location with <a href=https://nuetzlich.net/gocryptfs/forward_mode_crypto/>gocryptfs</a>.</li></ol><h4 id=gocryptfsmgr>GocryptfsMgr</h4><p>You can use <code>gocryptfs</code> directly or use the <code>gocryptfsmgr</code>, which automates a few steps in order to simplify things.</p><p>Here are the basics when using <code>gocryptfsmgr</code>:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#8f5902;font-style:italic># Create new encrypted data directory</span>
gocryptfsmgr create bigdata privatedata1

<span style=color:#8f5902;font-style:italic># List all encrypted and unencrypted (access point) directories</span>
gocryptfsmgr list

<span style=color:#8f5902;font-style:italic># Unencrypted privatedata1 (create access point)</span>
gocryptfsmgr open bigdata privatedata1 rw

<span style=color:#8f5902;font-style:italic># Transfer files (ie. SCP,SFTP,RSYNC)</span>
scp user@remote-server:sensitive_file.txt <span style=color:#000>$UNENCRYPTED</span>/privatedata1/sensitive_file.txt

<span style=color:#8f5902;font-style:italic># Remove access point (re-encrypt) privatedata1</span>
gocryptfsmgr close privatedata1

<span style=color:#8f5902;font-style:italic># Remove all access points (re-encrypt all)</span>
gocryptfsmgr quit
</code></pre></div><p>For subsequent access to the encrypted space, (ie. computation or analysis) the follow procedure is recommended:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#8f5902;font-style:italic># Request a 2hr interactive job on an exclusive node, resources can be adjusted as needed</span>
srun -p short --exclusive<span style=color:#ce5c00;font-weight:700>=</span>user --pty bash -l

<span style=color:#8f5902;font-style:italic># Unencrypted privatedata1 in read-only mode (create access point)</span>
gocryptfsmgr open bigdata privatedata1 ro

<span style=color:#8f5902;font-style:italic># Read file contents from privatedata1 (simulating work or analysis)</span>
cat <span style=color:#000>$UNENCRYPTED</span>/privatedata1/sensitive_file.txt

<span style=color:#8f5902;font-style:italic># List all encrypted and unencrypted (access points) directories</span>
gocryptfsmgr list

<span style=color:#8f5902;font-style:italic># Make sure we re-encrypt (close access point) for privatedata1</span>
gocryptfsmgr close privatedata1

<span style=color:#8f5902;font-style:italic># Exit from interactive job</span>
<span style=color:#204a87>exit</span>
</code></pre></div><p>With the above methods you can create multiple encrypted directories and access points and move between them.</p><h4 id=gocryptfs>Gocryptfs</h4><p>When using the <code>gocryptfs</code> directly, you will need to know a bit more details on how it works.
The <code>gocryptfs</code> module on the HPCC cluster uses these predefined variables:</p><ol><li><code>HOME_ENCRYPTED</code> = <code>/rhome/$USER/encrypted</code> - Very small encrypted space, not recommended to use</li><li><code>BIGDATA_ENCRYPTED</code> = <code>/rhome/$USER/bigdata/encrypted</code> - Best encrypted space for private data sets</li><li><code>SHARED_ENCRYPTED</code> = <code>/rhome/$USER/shared/encrypted</code> - Encrypted space when intending to share data sets with group</li><li><code>UNENCRYPTED</code> = <code>/run/user/$UID/unencrypted</code> - Access directory where encrypted data will be viewed as unencrypted</li></ol><p>Here is an example how to create an encrypted directory under the <code>BIGDATA_ENCRYPTED</code> location using <code>gocryptfs</code>:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#8f5902;font-style:italic># Load gocyptfs software</span>
module load gocryptfs

<span style=color:#8f5902;font-style:italic># Create empty data directory</span>
mkdir -p <span style=color:#000>$BIGDATA_ENCRYPTED</span>/privatedata1

<span style=color:#8f5902;font-style:italic># Then intialize empty directory and encrypt it</span>
gocryptfs -aessiv -init <span style=color:#000>$BIGDATA_ENCRYPTED</span>/privatedata1

<span style=color:#8f5902;font-style:italic># Create access point directory where encrypted files will be viewed as unencrypted</span>
mkdir -p <span style=color:#000>$UNENCRYPTED</span>/privatedata1

<span style=color:#8f5902;font-style:italic># After that mount the encrypted directory on the access point and open a new shell within it</span>
gocryptfssh <span style=color:#000>$BIGDATA_ENCRYPTED</span>/privatedata1

<span style=color:#8f5902;font-style:italic># Transfer files (ie. SCP,SFTP,RSYNC)</span>
scp user@remote-server:sensitive_file.txt <span style=color:#000>$UNENCRYPTED</span>/sensitive_file.txt

<span style=color:#8f5902;font-style:italic># Exiting this shell will automatically unmount the unencrypted directory</span>
<span style=color:#204a87>exit</span>
</code></pre></div><p>For subsequent access to the encrypted space, (ie. computation or analysis) the follow procedure is recommended:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#8f5902;font-style:italic># Request a 2hr interactive job on an exclusive node, resources can be adjusted as needed</span>
srun -p short --exclusive<span style=color:#ce5c00;font-weight:700>=</span>user --pty bash -l

<span style=color:#8f5902;font-style:italic># Load cyptfs software</span>
module load gocryptfs

<span style=color:#8f5902;font-style:italic># Create unencrypted directory</span>
mkdir -p <span style=color:#000>$UNENCRYPTED</span>/privatedata1

<span style=color:#8f5902;font-style:italic># Mount encrypted filesystem as read-only and unmount idling for 1 hour</span>
gocryptfs -ro -i 1h -sharedstorage <span style=color:#000>$BIGDATA_ENCRYPTED</span>/privatedata1 <span style=color:#000>$UNENCRYPTED</span>/privatedata1

<span style=color:#8f5902;font-style:italic># Read file contents (simulating work or analysis)</span>
cat <span style=color:#000>$UNENCRYPTED</span>/privatedata1/sensitive_file.txt

<span style=color:#8f5902;font-style:italic># Manually close access point when analysis has completed</span>
fusermount -u <span style=color:#000>$UNENCRYPTED</span>/privatedata1

<span style=color:#8f5902;font-style:italic># Delete old empty access point</span>
rmdir <span style=color:#000>$UNENCRYPTED</span>/privatedata1
</code></pre></div><blockquote><p>WARNING: Avoid writing to the same file at the same time from different nodes. The encrypted file system cannot handle simultaneous writes and will corrupt the file. If simultaneous jobs are necessary then using write mode from a head node and read-only mode from compute nodes may be the best solution here.
Also, be mindful of reamaining job time and make sure that you have unmounted the unencrypted directories before your job ends.</p></blockquote><p>For another example on how to use gocrypfs on an HPC cluster: <a href=https://hpc.uni.lu/blog/2018/sensitive-data-encryption-using-gocryptfs/>Luxembourg HPC gocryptfs Example</a></p><h2 id=deletion>Deletion</h2><p>To ensure the complete removal of data, it is best to <code>shred</code> files instead of removing them with <code>rm</code>. The <code>shred</code> program will overwrite the contents of a file with randomized data such that recovery of this file will be very difficult, if not impossible.</p><p>Instead of using the common <code>rm</code> command to delete something, please use the <code>shred</code> command, like so:</p><pre><code>shred -u somefile
</code></pre><p>The above command will overwrite the file with random data, and then remove (unlink) it.</p><p>If we want to be even more secure, we can pass over the file seven times to ensure that reconstruction is nearly impossible, then remove it:</p><pre><code>shred -v -n 6 -z -u somefile
</code></pre></div><div class=td-content style=page-break-before:always><h1 id=pg-f084de12202027a4e8874426f773d174>2.11 - Sharing Data</h1><h2 id=permissions>Permissions</h2><p>It is useful to share data and results with other users on the cluster, and we encourage collaboration The easiest way to share a file is to place it in a location that both users can access. Then the second user can simply copy it to a location of their choice. However, this requires that the file permissions permit the second user to read the file.
Basic file permissions on Linux and other Unix like systems are composed of three groups: owner, group, and other. Each one of these represents the permissions for different groups of people: the user who owns the file, all the group members of the group owner, and everyone else, respectively Each group has 3 permissions: read, write, and execute, represented as r,w, and x. For example the following file is owned by the user <code>username</code> (with read, write, and execute), owned by the group <code>groupname</code> (with read and execute), and everyone else cannot access it.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>username@pigeon:~$ ls -l myFile
-rwxr-x---   <span style=color:#0000cf;font-weight:700>1</span> username groupname 1.6K Nov <span style=color:#0000cf;font-weight:700>19</span> 12:32 myFile
</code></pre></div><p>If you wanted to share this file with someone outside the <code>groupname</code> group, read permissions must be added to the file for &lsquo;other&rsquo;:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>username@pigeon:~$ chmod o+r myFile
</code></pre></div><p>To learn more about ownership, permissions, and groups please visit <a href=manuals_linux-basics_permissions>Linux Basics Permissions</a>.</p><h2 id=set-default-permissions>Set Default Permissions</h2><p>In Linux, it is possible to set the default file permission for new files. This is useful if you are collaborating on a project, or frequently share files and you do not want to be constantly adjusting permissions The command responsible for this is called &lsquo;umask&rsquo;. You should first check what your default permissions currently are by running &lsquo;umask -S&rsquo;.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>username@pigeon:~$ <span style=color:#204a87>umask</span> -S
<span style=color:#000>u</span><span style=color:#ce5c00;font-weight:700>=</span>rwx,g<span style=color:#ce5c00;font-weight:700>=</span>rx,o<span style=color:#ce5c00;font-weight:700>=</span>rx
</code></pre></div><p>To set your default permissions, simply run umask with the correct options. Please note, that this does not change permissions on any existing files, only new files created after you update the default permissions. For instance, if you wanted to set your default permissions to you having full control, your group being able to read and execute your files, and no one else to have access, you would run:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>username@pigeon:~$ <span style=color:#204a87>umask</span> <span style=color:#000>u</span><span style=color:#ce5c00;font-weight:700>=</span>rwx,g<span style=color:#ce5c00;font-weight:700>=</span>rx,o<span style=color:#ce5c00;font-weight:700>=</span>
</code></pre></div><p>It is also important to note that these settings only affect your current session.
If you log out and log back in, these settings will be reset.
To make your changes permanent you need to add them to your <code>.bashrc</code> file, which is a hidden file in your home directory (if you do not have a <code>.bashrc</code> file, you will need to create an empty file called <code>.bashrc</code> in your home directory).
Adding umask to your <code>.bashrc</code> file is as simple as adding your umask command (such as <code>umask u=rwx,g=rx,o=r</code>) to the end of the file.
Then simply log out and back in for the changes to take affect. You can double check that the settings have taken affect by running <code>umask -S</code>.</p><p>To learn more about umask please visit <a href=http://www.cyberciti.biz/tips/understanding-linux-unix-umask-value-usage.html>What is Umask and How To Setup Default umask Under Linux?</a>.</p><h2 id=copying-bigdata>Copying bigdata</h2><p>Rsync can:</p><ul><li>Copy (transfer) directories between different locations</li><li>Perform transfers over the network via SSH</li><li>Compare large data sets (<code>-n, --dry-run</code> option)</li><li>Resume interrupted transfers</li></ul><p>Rsync Notes:</p><ul><li>Rsync can be used on Windows, but you must install <a href=https://cygwin.com>Cygwin</a>. Most Mac and Linux systems already have rsync install by default.</li><li>Always put the / after both folder names, e.g: <code>FOLDER_A/</code> Failing to do so will result in the nesting folders every time you try to resume. If you don&rsquo;t put / you will get a second folder_B inside folder_B <code>FOLDER_A/FOLDER_A/</code></li><li>Rsync only copies by default.</li><li>Once the rsync command is done, run it again. The second run will be shorter and can be used as a double check. If there was no output from the second run then nothing changed.</li><li>To learn more try <code>man rsync</code></li></ul><p>If you are transfering to, or from, your laptop/workstation it is required that you run the rsync command locally from your laptop/workstation.</p><p>To transfer to the cluster:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>rsync -av --progress FOLDER_A/ cluster.hpcc.ucr.edu:FOLDER_A/
</code></pre></div><p>To transfer from the cluster:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>rsync -av --progress cluster.hpcc.ucr.edu:FOLDER_A/ FOLDER_A/
</code></pre></div><p>Rsync will use SSH and will ask you for your cluster password, the same way SSH or SCP does.</p><p>If your rsync transer was interrupted, rsync can continue where it left off. Simply run the same command again to resume.</p><h2 id=copying-large-folders-on-the-cluster-between-directories>Copying large folders on the cluster between Directories</h2><p>If you want to syncronize the contents from one directory to another, then use the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>rsync -av --progress PATH_A/FOLDER_A/ PATH_B/FOLDER_A/
</code></pre></div><p>Rsync does not move but only copies. Thus you would need to delete the original once you confirm that everything has been transfered.</p><h2 id=copying-large-folders-between-the-cluster-and-other-servers>Copying large folders between the cluster and other servers</h2><p>If you want to copy data from the cluster to your own server, or another remote system, use the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>rsync -ai FOLDER_A/ sever2.xyz.edu:FOLDER_A/
</code></pre></div><p>The sever2.xyz.edu machine must be a server that accepts Rsync connections via SSH.</p><h2 id=sharing-files-on-the-web>Sharing Files on the Web</h2><p>Simply create a symbolic link or move the files into your html directory when you want to share them.
For exmaple, log into the HPC cluster and run the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#8f5902;font-style:italic># Make sure you have an html directory</span>
mkdir ~/.html

<span style=color:#8f5902;font-style:italic>#Make sure permissions are set correctly</span>
chmod a+x ~/
chmod a+rx ~/.html

<span style=color:#8f5902;font-style:italic># Make a new web project directory</span>
mkdir www-project
chmod a+rx www-project

<span style=color:#8f5902;font-style:italic># Create a default test file</span>
<span style=color:#204a87>echo</span> <span style=color:#4e9a06>&#39;&lt;h1&gt;Hello!&lt;/h1&gt;&#39;</span> &gt; ~/www-project/index.html

<span style=color:#8f5902;font-style:italic># Create shortcut/link for new web project in html directory </span>
ln -s ~/www-project ~/.html/
</code></pre></div><p>Now, test it out by pointing your web-browser to <a href=https://cluster.hpcc.ucr.edu/~username/www-project/>https://cluster.hpcc.ucr.edu/~username/www-project/</a>
Be sure to replace <code>username</code> with your actual user name.</p><h2 id=password-protect-web-pages>Password Protect Web Pages</h2><p>Files in web directories can be password protected.
First create a password file and then create a new user:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>touch ~/.html/.htpasswd
htpasswd ~/.html/.htpasswd newwebuser
</code></pre></div><p>This will prompt you to enter a password for the new user &lsquo;newwebuser&rsquo;.
Create a new directory, or go to an existing directory, that you want to password protect:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>mkdir ~/.html/locked_dir
<span style=color:#204a87>cd</span> ~/.html/locked_dir
</code></pre></div><p>For the above commands you can choose any directory name you want.</p><p>Then place the following content within a file called <code>.htaccess</code>:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-apache data-lang=apache><span style=color:#204a87>AuthName</span> &#39;Please login&#39;
<span style=color:#204a87>AuthType</span> Basic
<span style=color:#204a87>AuthUserFile</span> <span style=color:#4e9a06>/rhome/username/.html/.htpasswd</span>
<span style=color:#204a87>require</span> <span style=color:#204a87;font-weight:700>user</span> newwebuser
</code></pre></div><p>Now, test it out by pointing your web-browser to <a href=http://cluster.hpcc.ucr.edu/~username/locked_dir>http://cluster.hpcc.ucr.edu/~username/locked_dir</a>
Be sure to replace <code>username</code> with your actual user name for the above code and URL.</p><h2 id=google-drive>Google Drive</h2><p>There are several tools used to transfer files from Google Drive to the cluster, however RClone may be the easiest to setup.</p><ol><li><p>Create an <code>SSH</code> tunnel to the cluster, (MS Windows users should use <code>MobaXterm</code>):</p><pre><code>ssh -L 53682:localhost:53682 username@cluster.hpcc.ucr.edu
</code></pre></li><li><p>Once you have logged into the cluster with the above command, then load <code>rclone</code> via the module system and run it, like so:</p><pre><code>module load rclone
rclone config
</code></pre></li><li><p>After that, follow this <a href=https://rclone.org/drive/>RClone Walkthrough</a> to complete your setup.</p></li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-44da1bc9f9e7d2ae115c8cb435e37591>2.12 - SSH Keys Apple macOS</h1><h2 id=ssh-keys-on-macos>SSH Keys on macOS</h2><h3 id=what-are-ssh-keys>What are SSH Keys?</h3><p>SSH (Secure Shell) keys are an access credential that is used in the SSH protocol.</p><p>The private key remains on the system being used to access the HPCC cluster and is used to decrypt information that is exchanged in the transfer between the HPCC cluster and your system.</p><p>A public key file is used to encrypt information, and is stored on your own system.
The public key file is stored on the HPCC cluster and contains a list of authorized public keys.</p><h3 id=why-do-you-need-ssh-keys>Why do you need SSH Keys?</h3><p>HPCC supports two authentication methods; <code>Password+DUO</code> and <code>SSH Keys</code>.
The <code>Password+DUO</code> method requires a UCR NetID, if you do not have this then you will need to use <code>SSH keys</code> in order to access the HPCC cluster.</p><h3 id=what-you-need>What you need</h3><h4 id=filezilla>Filezilla</h4><p>You will need to install <code>Filezilla</code> in order to transfer the public SSH key to the HPCC cluster.</p><ol><li>Download the <code>Filezilla Client</code> for Mac OS X <a href=https://filezilla-project.org>here</a>.<ul><li>Make sure your Mac OS X system is updated to the latest version.</li></ul></li><li>Follow the install wizard to complete the install of <code>Filezilla</code>.</li></ol><h4 id=sourcetree>Sourcetree</h4><p>You will need to install <code>Sourcetree</code> in order to generate your <code>SSH keys</code> (or use the command line method mentioned here: <a href=some_other_page>Manage SSH Keys via Command Line</a>.</p><ol><li>Download <code>Sourcetree</code> from <a href=https://www.sourcetreeapp.com>here</a>.</li><li>Click on <code>Download for Mac OS X</code>.</li><li>Install <code>Sourcetree</code>.</li></ol><h3 id=create-ssh-keys-sourcetree>Create SSH Keys (<code>Sourcetree</code>)</h3><ol><li><p>Open the <code>Sourcetree</code> application and under the top <code>Sourcetree</code> menu click on the <code>Preferences...</code> sub-menu item.</p><p><img src=/img/41.png alt=fig0></p></li><li><p>Navigate to <code>Accounts</code> category and click on <code>Add...</code>.</p><p><img src=/img/42.png alt=fig0></p></li><li><p>Click on <code>Auth Type:</code> and change the drop down menu from <code>OAuth</code> to <code>Basic</code>. Make sure <code>Protocol:</code> is set to <code>SSH</code> in the drop down menu.</p><p><img src=/img/43.png alt=fig0></p></li><li><p>Enter <code>id_rsa</code> in the <code>Username</code> field.</p><p><img src=/img/44.png alt=fig0></p></li><li><p>Click the <code>Generate Key</code> button.</p><p><img src=/img/50.png alt=fig1></p></li><li><p>Press <code>Cancel</code> to exit out of the window.</p></li></ol><h3 id=ssh-keys-location>SSH Keys Location</h3><p>By default, your key files are created in the path: <code>/Users/macOSUsername/.ssh/</code>.</p><p>To verify that the keys were created, do the following:</p><ol><li><p>Open a new finder window. Click on your home directory on the left side pane.</p><p><img src=/img/23.png alt=fig1></p></li><li><p>Press the 3-button combo <code>Command</code>+<code>Shift</code>+<code>.</code> together (visualized below) to see hidden folders:</p><p><img src=/img/47b.png alt=fig1></p></li><li><p>You will now be able to see your <code>.ssh</code> folder, open it by double-clicking.</p><p><img src=/img/48.png alt=fig1></p></li><li><p>You should see your newly generated pair of <code>SSH key</code> files in the folder.</p><p><img src=/img/51.png alt=fig1></p></li><li><p>Sourcetree adds the <code>-Bitbucket</code> to the end of the <code>SSH key</code> file names. Remove this by clicking on the file you want to rename and press the <code>Enter</code> key which allows us to rename the file before the extension.</p><p><img src=/img/52.png alt=fig1></p></li><li><p>After you have removed the <code>-Bitbucket</code> suffix from each of the <code>SSH key</code> file names, your new <code>SSH key</code> file names should be <code>id_rsa</code> and <code>id_rsa.pub</code>.</p><p><img src=/img/53.png alt=fig1></p></li></ol><h3 id=configure-ssh-keys>Configure SSH Keys</h3><h4 id=public-ssh-key>Public SSH Key</h4><p>Now that you have created your <code>SSH keys</code>, and renamed them, you will need to placed the public key (<code>id_rsa.pub</code>) on the cluster using the <code>cluster.hpcc.ucr.edu</code> server.</p><ol><li><p>Start the <code>Filezilla</code> application.</p></li><li><p>Fill in the <code>Quickconnect</code> fields at the top of the application window:</p><ul><li>Enter your HPCC username in the <code>Username</code> field.</li><li>Enter the HPCC servername <code>cluster.hpcc.ucr.edu</code> for the <code>Host</code> field.</li><li>Enter your password in the <code>Password</code> field.</li><li>Enter <code>22</code> in the <code>Port</code> field.</li></ul><p><img src=/img/1e.png alt=fig4></p></li><li><p>Click on <code>Quickconnect</code></p><p><img src=/img/8e.png alt=fig7></p></li><li><p>If a pop up prompts you to save your password, select the <code>Save passwords</code> option, then click the <code>OK</code> button.</p></li><li><p>If the next pop up prompts you, then check the box that states <code>Always trust this host, add this key to the cache</code>, then click the <code>OK</code> button.</p><p><img src=/img/6be.png alt=fig8></p></li><li><p>Now that you are connected to Filezilla transfer your public SSH key from your macOS system by dragging the file <code>/Users/macOSUsername/.ssh/id_rsa.pub</code> and dropping it into the HPCC cluster direcotry <code>/rhome/username/.ssh/</code>.</p><p><img src=/img/4e.png alt=fig10></p></li></ol><h4 id=private-ssh-key>Private SSH Key</h4><p>Once your public key is in place, now you can configure <code>Filezilla</code> to use your private <code>SSH key</code> and connect to the cluster through the <code>secure.hpcc.ucr.edu</code> server.</p><ol><li><p>Open Filezilla <code>Site Manager</code> button in the top bar of icons.</p><p><img src=/img/60.png alt=fig3></p></li><li><p>Click on <code>New Site</code>, rename it (optional) and press enter.</p><p><img src=/img/54.png alt=fig3></p></li><li><p>Make sure the following fields are correctly filled before adding your <code>SSH key</code> file:</p><ul><li><code>Protocol</code>: should be set to <code>SFTP - SSH File Transfer Protocol</code></li><li><code>Host</code>: type in <code>secure.hpcc.ucr.edu</code></li><li><code>Port</code>: type <code>22</code></li><li><code>Logon Type</code>: set to <code>Key file</code></li><li><code>User</code>: type in your HPCC username</li></ul><p>After these fields are finalized, click the <code>Browse..</code> button.</p><p><img src=/img/56.png alt=fig4></p></li><li><p>Navigate to the folder you saved your key file in (default location is <code>/Users/macOSUsername/.ssh</code>) and open the private key file <code>id_rsa</code>.</p><p><img src=/img/57.png alt=fig4></p></li><li><p>You should see the added keyfile in the <code>Key file:</code> box, then click <code>Connect</code>.</p><p><img src=/img/59.png alt=fig5></p><p>Subsequnt connections can be done from the <code>Quickconnect</code> history by clicking on the down arrow to the right side of the <code>Quickconnect</code> button.</p><p><img src=/img/61.png alt=fig5></p></li><li><p>Remember to select the <code>secure.hpcc.ucr.edu</code> address.</p><p><img src=/img/62.png alt=fig5></p></li><li><p>Transfer files by double clicking or drag-n-drop. For more details regarding file transfers vist <a href=some_other_page>Filezilla Usage</a>.</p></li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-d726acebcd0bd6b600f604bfdce70fa0>2.13 - SSH Keys Microsoft Windows</h1><h2 id=ssh-keys-on-ms-windows>SSH Keys on MS Windows</h2><h3 id=what-are-ssh-keys>What are SSH keys?</h3><p>SSH (Secure Shell) keys are an access credential that is used in the SSH protocol.</p><p>The private key remains on the system being used to access the HPCC cluster and is used to decrypt information that is exchanged in the transfer between the HPCC cluster and your system.</p><p>A public key file is used to encrypt information, and is stored on your own system.
The public key file is stored on the HPCC cluster and contains a list of authorized public keys.</p><h3 id=why-do-you-need-ssh-keys>Why do you need SSH keys?</h3><p>HPCC supports two authentication methods; <code>Password+DUO</code> and <code>SSH Keys</code>.
The <code>Password+DUO</code> method requires a UCR NetID, if you do not have this then you will need to use <code>SSH keys</code> in order to access the HPCC cluster.</p><h3 id=what-you-need>What you need</h3><h4 id=filezilla>Filezilla</h4><p>You will need to install <code>Filezilla</code> in order to transfer the public SSH key to the HPCC cluster.</p><ol><li>Download the <code>Filezilla Client</code> for Windows <a href="https://filezilla-project.org/download.php?show_all=1">here</a>.
* Make sure your Windows system is updated to the latest version.</li><li>Follow the install wizard to complete the install of <code>Filezilla</code>.</li></ol><h4 id=mobaxterm>MobaXterm</h4><p>You will need to install <code>MobaXterm</code> in order to generate your <code>SSH keys</code> and also to transfer the keys to the cluster.</p><ol><li>Download <code>MobaXterm</code> from <a href=https://mobaxterm.mobatek.net/download-home-edition.html><code>here</code></a>.</li><li>Unzip</li><li>Double click portable version of exe and run the <code>MobaXterm</code> application.</li></ol><h3 id=create-ssh-keys-mobaxterm>Create SSH Keys (<code>MobaXterm</code>)</h3><ol><li><p>Begin by clicking on the tools drop down on the upper menu bar</p><p><img src=/img/ssh1moba.png alt=mobasshkey1></p></li><li><p>Find and click on the MobaKeyGen (SSH key generator) option</p><p><img src=/img/ssh2moba.png alt=mobasshkey2></p></li><li><p>A window should appear to create a new SSH key. Click on generate to create a new SSH key pair. Follow the on menu instructions.</p><p><img src=/img/revisedkeygen.png alt=revisedkeygen></p></li><li><p>Once your key has been created, enter a password in the key passphrase field to password protect your key. Click on <code>conversions</code> in the tool bar and click on <code>Export OpenSSH Key</code>. Save this key as <code>id_rsa</code> and put the file in an easy to access location.
Click on <code>Save private key</code> to save the private key with an extension of <code>.ppk</code> to use with MobaXterm or FileZilla. Save the key as <code>mobaxterm_privkey</code> and put the file in an easy to access location.</p><p><img src=/img/revisedkeygen2.png alt=revisedkeygen2></p></li><li><p>Highlight EVERYTHING in the box labeled &ldquo;Public key for pasting into OpenSSH authorized_keys file&rdquo; then right-click on it and choose Copy. Open <code>Notepad</code> and paste the copied text. Save the file as <code>id_rsa.pub</code> and put the file in an easy to access location.</p><p><img src=/img/revisedkeygen3.png alt=revisedkeygen3></p></li></ol><h3 id=keys-location>Keys Location</h3><p>SSH keys should be saved under the location <code>C:\Users\username\.ssh</code>.</p><p><img src=/img/sshkeyloc.png alt=sshkeyloc></p><h3 id=configure-ssh-keys>Configure SSH Keys</h3><h4 id=public-ssh-key>Public SSH Key</h4><p>Now that you have created your <code>SSH keys</code>, and renamed them, you will need to placed the public key (<code>id_rsa.pub</code>) on the cluster using the <code>cluster.hpcc.ucr.edu</code></p><ol><li><p>Start the <code>Filezilla</code> application.</p></li><li><p>Fill in the <code>Quickconnect</code> fields at the top of the application window:</p><ul><li>Enter your HPCC username in the <code>Username</code> field.</li><li>Enter the HPCC servername <code>cluster.hpcc.ucr.edu</code> for the <code>Host</code> field.</li><li>Enter your password in the <code>Password</code> field.</li><li>Enter <code>22</code> in the <code>Port</code> field.</li></ul><p><img src=/img/filezilla1.png alt=filezilla1></p></li><li><p>Click on <code>Quickconnect</code></p><p><img src=/img/filezilla2.png alt=filezilla2></p></li><li><p>If the next pop up prompts you, then check the box that states <code>Always trust this host, add this key to the cache</code>, then click the <code>OK</code> button.</p><p><img src=/img/filezilla3.png alt=filezilla3></p></li><li><p>You will need to create a <code>.ssh</code> directory to hold your SSH keys. On the right hand side, right click and click on the <code>Create directory option</code> under your home folder location.
<img src=/img/createsshdir.png alt=createsshdir></p></li><li><p>A window will appear to name the new directory. Name should be the following format: <code>/rhome/username/.ssh</code>. After naming the new directory click on <code>OK</code>.
<img src=/img/createsshdir2.png alt=createsshdir></p></li><li><p>Right click on the new <code>.ssh</code> directory that has been created. Find and click on <code>File permissions</code>.
<img src=/img/createsshdir3.png alt=createsshdir></p></li><li><p>A window with the directory permissions will appear. The <code>.ssh</code> directory needs exact permissions in order for it to function properly. Follow the image below to apply the permissions.
<img src=/img/createsshdir4.png alt=createsshdir></p></li><li><p>Now that you are connected to Filezilla transfer your public SSH key from your system by dragging the file <code>id_rsa.pub</code> and dropping it into the HPCC cluster direcotry <code>/rhome/username/.ssh/</code>.</p><p><img src=/img/filezilla4.png alt=filezilla4></p></li></ol><h4 id=private-ssh-key>Private SSH Key</h4><p>Once your public key is in place, now you can configure <code>Filezilla</code> to use your private <code>SSH key</code> and connect to the cluster through the <code>secure.hpcc.ucr.edu</code> server.</p><ol><li><p>Open Filezilla <code>Site Manager</code> button in the top bar of icons.</p><p><img src=/img/filezilla5.png alt=filezilla5></p></li><li><p>Click on <code>New Site</code>, rename it (optional) and press enter.</p><p><img src=/img/filezilla6.png alt=filezilla6></p></li><li><p>Make sure the following fields are correctly filled before adding your <code>SSH key</code> file:</p><ul><li><code>Protocol</code>: should be set to <code>SFTP - SSH File Transfer Protocol</code></li><li><code>Host</code>: type in <code>secure.hpcc.ucr.edu</code></li><li><code>Port</code>: type <code>22</code></li><li><code>Logon Type</code>: set to <code>Key file</code></li><li><code>User</code>: type in your HPCC username</li></ul><p>After these fields are finalized, click the <code>Browse..</code> button.</p><p><img src=/img/filezilla7.png alt=filezilla7></p></li><li><p>Navigate to the folder you saved your private key file in and open the private key file <code>mobaxterm_privkey.ppk</code>. You should see the added keyfile in the <code>Key file:</code> box, then click <code>Connect</code>.</p><p><img src=/img/filezilla9.png alt=filezilla9></p></li><li><p>Subsequnt connections can be done from the <code>Quickconnect</code> history by clicking on the down arrow to the right side of the <code>Quickconnect</code> button. Remember to select the <code>secure.hpcc.ucr.edu</code> address.</p><p><img src=/img/filezilla11.png alt=filezilla11></p></li><li><p>Transfer files by double clicking or drag-n-drop. For more details regarding file transfers vist <a href=some_other_page>Filezilla Usage</a>.</p></li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-008bc8a4cf5439833eb50953ea9f062b>2.14 - Terminal-based Working Environments</h1><h1 id=terminal-ides>Terminal IDEs</h1><p>This page introduces several terminal-based working environments available on UCR&rsquo;s
HPC cluster that are useful for a variety of computer languages.</p><h2 id=vimnvim-basics>Vim/Nvim Basics</h2><p>To work efficiently on remote systems like a computer cluster, it is essential
to learn how to work in a pure command-line interface. GUI environments like
RStudio and similar coding environments are not suitable for this. In addition,
there is a lot of value of knowing how to work in an environment that is not
restricted to a specific programming language. Therefore, for working on remote
systems like HPCC Cluster, this site focuses on Nvim and Tmux. Both are useful
for many programming languages. Combinded with the <code>nvim-r</code> plugin they also
provide a powerful command-line working environment for R. Users of Emacs may
want to consider using <a href=https://ess.r-project.org/>ESS</a> instead. The following
provides a brief introduction to the Nvim-R-Tmux environment.</p><h3 id=vim-overview>Vim overview</h3><p>The following opens a file (here <code>myfile</code>) with nvim (or vim)</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>nvim myfile.txt <span style=color:#8f5902;font-style:italic># for neovim (or &#39;vim myfile.txt&#39; for vim)</span>
</code></pre></div><p>Once you are in Nvim, there are three main modes: normal, insert and command mode. The most important commands for switching between the three modes are:</p><ul><li><code>i</code>: The <code>i</code> key brings you from the normal mode to the insert mode. The latter is used for typing.</li><li><code>Esc</code>: The <code>Esc</code> key brings you from the insert mode back to the normal mode.</li><li><code>:</code>: The <code>:</code> key starts the command mode at the bottom of the screen.</li></ul><p>Use the arrow keys to move your cursor in the text. Using <code>Fn Up/Down key</code> allows to page through
the text quicker. In the following command overview, all commands starting with <code>:</code> need to be typed in the command mode.
All other commands are typed in the normal mode after pushing the <code>Esc</code> key.</p><p>Important modifier keys to control vim/nvim</p><ul><li><code>:w</code>: save changes to file. If you are in editing mode you have to hit <code>Esc</code> first.</li><li><code>:q</code>: quit file that has not been changed</li><li><code>:wq</code>: save and quit file</li><li><code>:!q</code>: quit file without saving any changes</li></ul><h3 id=useful-resources-for-learning-vimnvim>Useful resources for learning vim/nvim</h3><ul><li><a href=http://www.openvim.com>Interactive Vim Tutorial</a></li><li><a href=http://vimdoc.sourceforge.net/>Official Vim Documentation</a></li><li><a href=http://hpcc.ucr.edu/manuals_linux-basics_vim.html>HPCC Linux Manual</a></li></ul><h2 id=for-r-nvim-r>For R: nvim-R</h2><h3 id=basics>Basics</h3><p>Tmux is a terminal multiplexer that allows to split terminal windows and to detach/reattach to
existing terminal sessions. Combinded with the <code>nvim-r</code> plugin it provides a powerful command-line working
environment for R where users can send code from a script to the R console or command-line.
Both tmux and the <code>nvim-r</code> plugin need to be installed on a system. On HPCC Cluster both are configured
in each user account. If this is not the case then follow the quick configuration instructions given in the following subsection.</p><center><img title=Nvim-R src=https://raw.githubusercontent.com/jalvesaq/Nvim-R/master/Nvim-R.gif></center>
<center>Nvim-R IDE for R</center><h3 id=quick-configuration-in-user-accounts>Quick configuration in user accounts</h3><p>Skip these steps if Nvim-R-Tmux is already configured in your account. Or follow the <a href=https://gist.github.com/tgirke/7a7c197b443243937f68c422e5471899>detailed
instructions</a> to install Nvim-R-Tmux from scratch on your own system.</p><ol><li>Log in to your user account on HPCC and execute <code>install_nvimRtmux</code>. Alternatively, follow these step-by-step <a href=https://cluster.hpcc.ucr.edu/~tgirke/Documents/R_BioCond/My_R_Scripts/vim-r-plugin/README_nvimRtmux>install commands</a>.</li><li>To enable the nvim-R-tmux environment, log out and in again.</li><li>Follow usage instructions of next section.</li></ol><h3 id=basic-usage-of-nvim-r-tmux>Basic usage of Nvim-R-Tmux</h3><p>The official and much more detailed user manual for <code>Nvim-R</code> is available <a href=https://github.com/jalvesaq/Nvim-R/blob/master/doc/Nvim-R.txt>here</a>.
The following gives a short introduction into the basic usage of Nvim-R-Tmux:</p><p><strong>1. Start tmux session</strong> (optional)</p><p>Note, running Nvim from within a tmux session is optional. Skip this step if tmux functionality is not required (<em>e.g.</em> reattaching to sessions on remote systems).</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>tmux <span style=color:#8f5902;font-style:italic># starts a new tmux session </span>
tmux a <span style=color:#8f5902;font-style:italic># attaches to an existing session </span>
</code></pre></div><p><strong>2. Open nvim-connected R session</strong></p><p>Open a <code>*.R</code> or <code>*.Rmd</code> file with <code>nvim</code> and intialize a connected R session with <code>\rf</code>. This command can be remapped to other key combinations, e.g. uncommenting lines 10-12 in <code>.config/nvim/init.vim</code> will remap it to the <code>F2</code> key. Note, the resulting split window among Nvim and R behaves like a split viewport in <code>nvim</code> or <code>vim</code> meaning the usage of <code>Ctrl-w w</code> followed by <code>i</code> and <code>Esc</code> is important for navigation.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>nvim myscript.R <span style=color:#8f5902;font-style:italic># or *.Rmd file</span>
</code></pre></div><p><strong>3. Send R code from nvim to the R pane</strong></p><p>Single lines of code can be sent from nvim to the R console by pressing the space bar. To send
several lines at once, one can select them in nvim&rsquo;s visual mode and then hit the space bar.
Please note, the default command for sending code lines in the nvim-r-plugin is <code>\l</code>. This key
binding has been remapped in the provided <code>.config/nvim/init.vim</code> file to the space bar. Most other key bindings (shortcuts) still start with the <code>\</code> as LocalLeader, <em>e.g.</em> <code>\rh</code> opens the help for a function/object where the curser is located in nvim. More details on this are given below.</p><h3 id=important-keybindings-for-nvim>Important keybindings for nvim</h3><p>The main advantages of Neovim compared to Vim are its better performance and its built-in terminal emulator facilitating the communication among Neovim and interactive programming environments such as R. Since the Vim and Neovim environments are managed independently, one can run them in parallel on the same system without interfering with each other. The usage of Neovim is almost identical to Vim.</p><p><strong>Nvim commands</strong></p><ul><li><code>\rf</code>: opens vim-connected R session. If you do this the first time in your user account, you might be asked to create an <code>R</code> directory under <code>~/</code>. If so approve this action by pressing <code>y</code>.</li><li><code>spacebar</code>: sends code from vim to R; here remapped in <code>init.vim</code> from default <code>\l</code></li><li><code>:split</code> or <code>:vsplit</code>: splits viewport (similar to pane split in tmux)</li><li><code>gz</code>: maximizes size of viewport in normal mode (similar to Tmux&rsquo;s <code>Ctrl-a z</code> zoom utility)</li><li><code>Ctrl-w w</code>: jumps cursor to R viewport and back; toggle between insert (<code>i</code>) and command (<code>Esc</code>) mode is required for navigation and controlling the environment.</li><li><code>Ctrl-w r</code>: swaps viewports</li><li><code>Ctrl-w =</code>: resizes splits to equal size</li><li><code>:resize &lt;+5 or -5></code>: resizes height by specified value</li><li><code>:vertical resize &lt;+5 or -5></code>: resizes width by specified value</li><li><code>Ctrl-w H</code> or <code>Ctrl-w K</code>: toggles between horizontal/vertical splits</li><li><code>Ctrl-spacebar</code>: omni completion for R objects/functions when nvim is in insert mode. Note, this has been remapped in <code>init.vim</code> from difficult to type default <code>Ctrl-x Ctrl-o</code>.</li><li><code>:h nvim-R</code>: opens nvim-R&rsquo;s user manual; navigation works the same as for any Vim/Nvim help document</li><li><code>:Rhelp fct_name</code>: opens help for a function from nvim&rsquo;s command mode with text completion support</li><li><code>Ctrl-s and Ctrl-x</code>: freezes/unfreezes vim (some systems)</li></ul><h3 id=important-keybindings-for-tmux>Important keybindings for tmux</h3><p><strong>Pane-level commands</strong></p><ul><li><code>Ctrl-a %</code>: splits pane vertically</li><li><code>Ctrl-a "</code>: splits pane horizontally</li><li><code>Ctrl-a o</code>: jumps cursor to next pane</li><li><code>Ctrl-a Ctrl-o</code>: swaps panes</li><li><code>Ctrl-a &lt;space bar></code>: rotates pane arrangement</li><li><code>Ctrl-a Alt &lt;left or right></code>: resizes to left or right</li><li><code>Ctrl-a Esc &lt;up or down></code>: resizes to left or right</li></ul><p><strong>Window-level comands</strong></p><ul><li><code>Ctrl-a n</code>: switches to next tmux window</li><li><code>Ctrl-a Ctrl-a</code>: switches to previous tmux window</li><li><code>Ctrl-a c</code>: creates a new tmux window</li><li><code>Ctrl-a 1</code>: switches to specific tmux window selected by number</li></ul><p><strong>Session-level comands</strong></p><ul><li><code>Ctrl-a d</code>: detaches from current session</li><li><code>Ctrl-a s</code>: switch between available tmux sesssions</li><li><code>$ tmux new -s &lt;name></code>: starts new session with a specific name</li><li><code>$ tmux ls</code>: lists available tmux session(s)</li><li><code>$ tmux attach -t &lt;id></code>: attaches to specific tmux session</li><li><code>$ tmux attach</code>: reattaches to session</li><li><code>$ tmux kill-session -t &lt;id></code>: kills a specific tmux session</li><li><code>Ctrl-a : kill-session</code>: kills a session from tmux command mode that can be initiated with <code>Ctrl-a :</code></li></ul><h2 id=for-bash-python-and-other-languages>For Bash, Python and other languages</h2><h3 id=basics-1>Basics</h3><p>For languages other than R one can use the
<a href=https://github.com/jalvesaq/vimcmdline>vimcmdline</a> plugin for nvim (or vim).
Supported languages include Bash, Python, Golang, Haskell, JavaScript, Julia,
Jupyter, Lisp, Macaulay2, Matlab, Prolog, Ruby, and Sage. The nvim terminal
also colorizes the output, as in the screenshot below, where different colors
are used for general output, positive and negative numbers, and the prompt
line.</p><center><img title=vimcmdline src=https://cloud.githubusercontent.com/assets/891655/7090493/5fba2426-df71-11e4-8eb8-f17668d9361a.png></center>
<center>vimcmdline</center><h3 id=install>Install</h3><p>To install it, one needs to copy from the <code>vimcmdline</code> resository the directories
<code>ftplugin</code>, <code>plugin</code> and <code>syntax</code> and their files to <code>~/.config/nvim/</code>. For
user accounts of UCR’s HPCC, the above install script <code>install_nvimRtmux</code> includes the
install of <code>vimcmdline</code> (since 09-Jun-18).</p><h3 id=usage>Usage</h3><p>The usage of <code>vimcmdline</code> is very similar to <code>nvim-R</code>. To start a connected terminal session, one
opens with nvim a code file with the extension of a given language (<em>e.g.</em> <code>*.sh</code> for Bash or <code>*.py</code> for Python),
while the corresponding interactive interpreter session is initiated
by pressing the key sequence <code>\s</code> (corresponds to <code>\rf</code> under <code>nvim-R</code>). Subsequently, code lines can be sent
with the space bar. More details are available <a href=https://github.com/jalvesaq/vimcmdline>here</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-1d4c62174462deb26fd1485bfa8ac42a>2.15 - Visualization</h1><h2 id=gpu-workstation>GPU Workstation</h2><p>The High-Performance Computing Center at UCR has a GPU workstation specifically designed for rendering high resolution 3D graphics.</p><h3 id=hardware>Hardware</h3><ul><li>Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz</li><li>DDR4 256GB @ 2400 MHz</li><li>NVIDIA Corporation GM204GL [Quadro M5000]</li><li>1TB RAID 1 HDD</li></ul><h3 id=software>Software</h3><p>The GPU workstation is uniquely configured to be an extension of the HPCC cluster. Thus, all software available to the cluster is also available on the GPU workstation through <a href=manuals_linux-cluster_start.html#modules>Environment Modules</a>.</p><h3 id=access>Access</h3><p>The GPU workstation is currently located in the Genomics building room 1208. Please check ahead of time to make sure the machine is available <a href=mailto:support@hpcc.ucr.edu>support@hpcc.ucr.edu</a>.
Once you have access to the GPU workstation, login with your cluster credentials. If your username does not appear in the list, you may need to click <code>Not listed?</code> at the bottom of the screen so that you are able to type in your username.</p><h4 id=usage>Usage</h4><p>There are 2 ways to use the GPU workstation:</p><ol><li>Local - Run processes directly on the GPU workstation hardware</li><li>Remote - Run processes remotely on the GPU cluster hardware</li></ol><p><strong>Local</strong></p><p>Local usage is very simple. Open a terminal and use the <a href=manuals_linux-cluster_start.html#modules>Environment Modules</a> to load the desired software, then run your software from the terminal.
For example:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>module load amira
Amira
</code></pre></div><p><strong>Remotely</strong></p><p>Open a terminal and submit a job. This is to reserve the time on the remote GPU node. Then once your job has started connect to the remote GPU node via ssh and forward the graphics back to the GPU workstation.
For example:</p><ol><li><p>Submit a job for March 28th, 2018 at 9:30am for a duration of 24 hours, 4 cpus, 100GB memory:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sbatch --begin<span style=color:#ce5c00;font-weight:700>=</span>2018-03-28T09:30:00 --time<span style=color:#ce5c00;font-weight:700>=</span>24:00:00 -p gpu --gres<span style=color:#ce5c00;font-weight:700>=</span>gpu:1 --mem<span style=color:#ce5c00;font-weight:700>=</span>100g --cpus-per-task<span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>4</span> --wrap<span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#39;echo ${CUDA_VISIBLE_DEVICES} &gt; ~/.CUDA_VISIBLE_DEVICES; sleep infinity&#39;</span>
</code></pre></div><p>Read about <a href=manuals_linux-cluster_jobs.html#gpu-jobs>GPU jobs</a> for more information regarding the above.</p></li><li><p>Run the VirtualGL client in order to receive 3D graphics from the remove GPU node:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>vglclient <span style=color:#000;font-weight:700>&amp;</span>
</code></pre></div></li><li><p>Wait for the job to start, and then check where your job is running:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#000>GPU_NODE</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#204a87;font-weight:700>$(</span>squeue -h -p gpu -u <span style=color:#000>$USER</span> -o <span style=color:#4e9a06>&#39;%N&#39;</span><span style=color:#204a87;font-weight:700>)</span><span style=color:#000;font-weight:700>;</span> <span style=color:#204a87>echo</span> <span style=color:#000>$GPU_NODE</span>
</code></pre></div></li><li><p>The above command should result in a GPU node name, which you then need to SSH directly into with the following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ssh -XY <span style=color:#000>$GPU_NODE</span>
</code></pre></div></li><li><p>Once you have SSH&rsquo;ed into the remote GPU node, run setup the environment and run your software:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#204a87>export</span> <span style=color:#000>NO_AT_BRIDGE</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>1</span>
module load amira
vglrun -display :<span style=color:#204a87;font-weight:700>$(</span>head -1 ~/.CUDA_VISIBLE_DEVICES<span style=color:#204a87;font-weight:700>)</span> Amira
</code></pre></div></li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-e88a4922f0cd5d4ed59782cdf6fc1f24>3 - HPCC Cloud/External</h1><div class=lead>What does your user need to know to try your project?</div><div class="pageinfo pageinfo-primary"><p>This is a placeholder page that shows you how to use this template site.</p></div><p>Information in this section helps your user try your project themselves.</p><ul><li><p>What do your users need to do to start using your project? This could include downloading/installation instructions, including any prerequisites or system requirements.</p></li><li><p>Introductory “Hello World” example, if appropriate. More complex tutorials should live in the Tutorials section.</p></li></ul><p>Consider using the headings below for your getting started page. You can delete any that are not applicable to your project.</p><h2 id=prerequisites>Prerequisites</h2><p>Are there any system requirements for using your project? What languages are supported (if any)? Do users need to already have any software or tools installed?</p><h2 id=installation>Installation</h2><p>Where can your user find your project code? How can they install it (binaries, installable package, build from source)? Are there multiple options/versions they can install and how should they choose the right one for them?</p><h2 id=setup>Setup</h2><p>Is there any initial setup users need to do after installation to try your project?</p><h2 id=try-it-out>Try it out!</h2><p>Can your users test their installation, for example by running a command or deploying a Hello World example?</p></div><div class=td-content style=page-break-before:always><h1 id=pg-beacfdfe8793106a0dce0688e1436540>3.1 - Account Creation</h1><h2 id=introduction>Introduction</h2><p>The scope of this manual section is am an introduction on how to get started using the Amazon cloud AWS to quickly create an on-demand cluster private to you.</p><h2 id=login-to-your-mainmaster-aws-account>Login to your Main/Master AWS account</h2><ul><li>Click this <a href=https://console.aws.amazon.com/console/home target=_blank>Link</a></li></ul><img style="box-shadow:5px 5px 5px 5px grey" src=/img/cloud-aws-login-1.png title="Master Account Login" alt="Master Account Login"><ul><li>Click Sign In</li></ul><h2 id=enter-your-two-factor-authentication-code>Enter your two-factor authentication code</h2><ul><li>Enter Auth code
<img style="box-shadow:5px 5px 5px 5px grey" src=/img/cloud-aws-2fauth.png title="Two Factor Auth" alt="Two Factor Auth"></li><li>Click Sign In</li></ul><h2 id=identity-and-access-managemenet-iam>Identity and Access Managemenet (IAM)</h2><ul><li>Naviagte to the <a href="https://console.aws.amazon.com/iam/home?region=us-west-1#/home" target=_blank>IAM Page</a>
<img style="box-shadow:5px 5px 5px 5px grey" src=/img/cloud-aws-iam-page.png title="IAM page" alt="IAM page"></li><li>Click on Users</li></ul><h2 id=add-user>Add User</h2><ul><li>This is the user managment page
<img style="box-shadow:5px 5px 5px 5px grey" src=/img/cloud-aws-users-page.png title="User Page" alt="User Page"></li><li>Click Add user</li></ul><h2 id=account-creation-wizard>Account creation wizard</h2><ul><li>Create a new account for creating clusters
<img style="box-shadow:5px 5px 5px 5px grey" src=/img/cloud-aws-add-user-account.png title="User Account" alt="User Account"></li><li>Fill out the user name and the access type (Programmatic access should be all that&rsquo;s needed for users of a lab).</li><li>Click Next: Permissions.</li></ul><h2 id=assign-permissions-to-the-new-account>Assign Permissions to the new account</h2><ul><li>Permissions are assigned to groups and users are organized into those groups.
<img style="box-shadow:5px 5px 5px 5px grey" src=/img/cloud-aws-add-user-permissions.png title="User Permissions" alt="User Permissions"></li><li>If you do not have any existing groups create an admin group</li><li>Choose what group you would like the new user to below too.</li><li>You can create a new group here also.</li><li>Click Next: Review</li></ul><h2 id=account-creation-review>Account creation review</h2><ul><li>Review account choices before creation
<img style="box-shadow:5px 5px 5px 5px grey" src=/img/cloud-aws-add-user-review.png title="User Review" alt="User Review"></li><li>Click Create user.</li></ul><h2 id=account-creation-complete>Account creation complete.</h2><ul><li>The account has been created and here are the credentials
<img style="box-shadow:5px 5px 5px 5px grey" src=/img/cloud-aws-add-user-complete.png title="User Complete" alt="User Complete"></li><li>Ensure you click on Download.csv! (this contains the Access key ID and Secret key for this account and is needed later)</li><li>Save this file.</li><li>Click on Close.</li></ul><h2 id=naviagte-to-the-aws-ec2-console>Naviagte to the AWS EC2 Console</h2><ul><li>Click this <a href="https://us-west-1.console.aws.amazon.com/ec2/v2/home?region=us-west-1#Home" target=_blank>Link</a>
<img style="box-shadow:5px 5px 5px 5px grey" src=/img/cloud-aws-console.png title="AWS Console" alt="AWS Console"></li><li>Click Key Pairs</li></ul><h2 id=key-pair-management-page>Key Pair management page</h2><img style="box-shadow:5px 5px 5px 5px grey" src=/img/cloud-aws-key-pair-page.png title="Key Pair Page" alt="Key Pair Page"><ul><li>Click Create Key Pair</li></ul><h2 id=name-new-key-pair>Name new Key Pair</h2><img style="box-shadow:5px 5px 5px 5px grey" src=/img/cloud-aws-key-pair-name.png title="Key Pair Name" alt="Key Pair Page"><ul><li>Give it a name representing the new user.</li><li>Click Create</li><li>You will be prompted to save the new key file. Note where you save this file.</li></ul><h2 id=send-credentials-and-key-file-to-the-new-user>Send credentials and key file to the new user</h2><ul><li>Send an email to the new user with the credentials file and the key file attached.</li><li>Any other private form of file transfer can also be used to distribute the files to the new user.</li></ul><p>You now have all the information needed for a user to create their own cluster.</p><p>Next step:
Setup and create a new cluster.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-bb9a0cc487677c78eb5d0f2dfa604443>3.2 - Account Egress Waiver</h1><h2 id=learn-how-to-establish-an-amazon-web-services-aws-account-under-the-uc-agreement>Learn how to establish an Amazon Web Services (AWS) account under the UC Agreement.</h2><p>A UC-wide agreement for Amazon Web Services (AWS) has been established. The agreement provides <strong>Data Egress Fee waiver for up to 15% of total monthly AWS fees</strong>.</p><p>Please follow the instructions below to ensure that an AWS account for UCR business is covered under this agreement and in compliance with UC policy and the law.</p><h2 id=understand-appropriate-use>Understand Appropriate Use</h2><p>Review the following to understand the applicable terms and conditions, and allowable data use for AWS:</p><ul><li>University of California AWS Enterprise Customer Agreement<ul><li>Applies to all AWS accounts UC-wide, except those used for:<ul><li>Commercial Web Hosting</li><li>Media Streaming</li><li>Massive Open Online Courses (MOOCs)</li></ul></li><li>80%+ of data egress must be via an approved National Research and Education Network (NREN). This includes CENIC and Internet2, so normal UC usage meets this requirement.</li></ul></li><li>Determine whether the data you are working with should be hosted in the cloud.</li><li>HIPAA Business Associate Agreement (BAA)<ul><li>In order to cover your locations AWS accounts under the terms of the UC AWS Enterprise Agreement (EA) and HIPAA Business Associate Agreement (BAA), follow the instructions <a href=http://www.ucop.edu/cloud-services-contracts/_files/UC-BAA-final-draft_v2.0-final.pdf%22>found on the UCOP Website</a> (PDF).</li></ul></li></ul><h2 id=connect-aws-account-to-uc-agreement-and-po>Connect AWS Account to UC Agreement and PO</h2><p>Send an email to UCs AWS account representative, Devinder Narula <a href=mailto:dsnarula@amazon.com>dsnarula@amazon.com</a> to:</p><ul><li>Activate your new AWS account (if pertinent)</li><li>Include your AWS account under the terms of the UC-wide AWS agreement</li><li>Connect your AWS account to your Purchase Order number</li></ul><p>To accomplish this, the email needs to include the following information:</p><ul><li>AWS 12-Digit Account Number</li><li>Company Name = University of California, Riverside (UCR)</li><li>Your Name</li></ul><h2 id=aws-account-activation>AWS Account Activation</h2><p>You will receive an email response from AWS confirming that your AWS account is now set up for invoicing under the UC AWS agreement, and providing final instructions to activate your account. Follow the instructions in the AWS activation email and your account will be active and ready for use.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-5e19d092497df8af716f50c58b7201c7>3.3 - Cluster Operation</h1><h2 id=login-to-hpcc>Login to HPCC</h2><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ssh username@cluster.hpcc.ucr.edu
</code></pre></div><h2 id=create-a-cluster>Create a Cluster</h2><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>hpcc_cloud create &lt;NameForYourCluster&gt;
</code></pre></div><h2 id=show-status-of-a-cluster>Show status of a Cluster</h2><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>hpcc_cloud status &lt;NameForYourCluster&gt;
</code></pre></div><p>Output:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>Status: cfncluster-new-cluster - CREATE_COMPLETE                                
Output:<span style=color:#4e9a06>&#34;MasterPublicIP&#34;</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;52.52.227.148&#34;</span>
Output:<span style=color:#4e9a06>&#34;MasterPrivateIP&#34;</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;172.31.24.51&#34;</span>
Output:<span style=color:#4e9a06>&#34;GangliaPublicURL&#34;</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;http://52.52.227.148/ganglia/&#34;</span>
Output:<span style=color:#4e9a06>&#34;GangliaPrivateURL&#34;</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;http://172.31.24.51/ganglia/&#34;</span>
</code></pre></div><p>Note the &ldquo;MasterPublicIP&rdquo; Address from the output.
Use this IP Address when connecting to the cluster via &ldquo;ssh&rdquo; or uploading and downloading via &ldquo;scp&rdquo;.</p><h2 id=show-running-clusters>Show running Clusters</h2><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>hcpp_cloud list
</code></pre></div><h2 id=delete-cluster>Delete cluster</h2><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>hpcc_cloud delete &lt;NameForYourCluster&gt;
</code></pre></div><h2 id=connecting-to-your-cluster>Connecting to your cluster</h2><p>Note - /path/to/your/key-file.pem = where you saved your AWS account key file</p><p>MasterPublicIP = Master Public IP address from the cluster status</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ssh -i /path/to/your/key-file.pem centos@&lt;MasterPublicIP&gt;
</code></pre></div><h2 id=uploading-data-to-your-cluster>Uploading data to your cluster</h2><p>This will transfer the local files to your home directory on the cluster.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>scp -i /path/to/your/key-file.pem &lt;local-files-to-copy&gt; centos@&lt;MasterPublicIP&gt;:.
</code></pre></div><h2 id=downloading-dataresults>Downloading data/results</h2><p>This would be called from the HPCC cluster and it will download the specified remote files to your current directory.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>scp -i /path/to/your/key-file.pem centos@&lt;MasterPublicIP&gt;:./&lt;files-to-download&gt; .
</code></pre></div><h2 id=running-a-job-on-your-cluster>Running a job on your cluster</h2><p>This will show all the steps needed to create a cluster and run a simple batch job</p><h3 id=1-start-a-new-cluster>1. Start a new cluster</h3><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>hpcc_cloud create new-cluster
</code></pre></div><h3 id=2-get-the-ip-address-of-the-new-cluster>2. Get the IP address of the new cluster</h3><p>Once the cluster build is complete you will be presented with the status informatiom.
Note the &ldquo;MasterPublicIP&rdquo; Address from the output.
Use this IP Address when connecting to the cluster via &ldquo;ssh&rdquo; or uploading and downloading via &ldquo;scp&rdquo;.</p><p>Output:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>hpcc_cloud create new-cluster
Beginning cluster creation <span style=color:#204a87;font-weight:700>for</span> cluster: new-cluster
Creating stack named: cfncluster-new-cluster
Status: cfncluster-new-cluster - CREATE_COMPLETE                                
Output:<span style=color:#4e9a06>&#34;MasterPublicIP&#34;</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;52.52.227.148&#34;</span>
Output:<span style=color:#4e9a06>&#34;MasterPrivateIP&#34;</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;172.31.24.51&#34;</span>
Output:<span style=color:#4e9a06>&#34;GangliaPublicURL&#34;</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;http://52.52.227.148/ganglia/&#34;</span>
Output:<span style=color:#4e9a06>&#34;GangliaPrivateURL&#34;</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;http://172.31.24.51/ganglia/&#34;</span>
</code></pre></div><p>Find the &ldquo;MasterPublicIP&rdquo;</p><h3 id=3-upload-your-input-files-and-slurm-submission-script>3. Upload your input files and slurm submission script</h3><p>This will transfer the local files to your home directory on the cluster.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>scp -i /path/to/your/key-file.pem &lt;local-files-to-copy&gt; centos@&lt;MasterPublicIP&gt;:.
</code></pre></div><h3 id=4-ssh-to-your-new-cluster>4. SSH to your new cluster</h3><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ssh -i /path/to/your/key-file.pem centos@&lt;MasterPublicIP&gt;
</code></pre></div><h3 id=5-submit-your-job-to-the-cluster>5. Submit your job to the cluster</h3><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sbatch slurm-submission-script.sh
</code></pre></div><h3 id=6-monitor-your-job>6. Monitor your job</h3><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>squeue
</code></pre></div><h3 id=7-download-results>7. Download results</h3><p>This command would be called from the HPCC cluster and it will download the specified remote files to your current directory.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>scp -i /path/to/your/key-file.pem centos@&lt;MasterPublicIP&gt;:./&lt;results-to-download&gt; .
</code></pre></div><h3 id=8-delete-cluster>8. Delete cluster</h3><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>hpcc_cloud delete new-cluster 
</code></pre></div><h2 id=start-sample-cluster-walk-through-sped-up>Start sample cluster walk through (sped up)</h2><script id=asciicast-lKXf3g9tVdJZiJVqoaDMVIvMY src=https://asciinema.org/a/lKXf3g9tVdJZiJVqoaDMVIvMY.js async data-autoplay=false data-size=small data-speed=5></script></div><div class=td-content style=page-break-before:always><h1 id=pg-f8a784a057005b39f975eadeb4a739f0>3.4 - Cost Control and Billing</h1><h2 id=introduction>Introduction</h2><p>This page will talk about AWS costs and billing along with setting some controls for them.</p><h2 id=costs>Costs</h2><p>AWS Costs come from each and every type of resources you consume on AWS.</p><p>Some Examples:</p><ul><li>Node Utilization (How many computers and of what type you use for how long)</li><li>Storage</li><li>Backend services such as network traffic, security groups, and API transactions. (These costs are relatively very small)</li></ul><p>Node Utilization and Storage are the two biggest contributors to cost. So when controlling costs focus here.
This can be done by only uploading and downloading the data you need, and deleting your cluster when your not using it.
There are also some saving to be realized by choosing the best type of compute node for the type of work you plan on doing.
It is easy to change the compute type and HPCC can help you to make the best decision for your work.
You can also simply use HPCCs default configuration.</p><p>As a practical example: (~$0.43 cents per hour to run in default configuration)</p><ul><li>Using the most common cluster configuration - One headnode and one 8 core compute node with 16G Ram.</li><li>Without using spot pricing.</li><li>Assuming 25GB of input and/or output data.</li></ul><p>HPCC can help with cost projection if you need it.</p><h3 id=aws-costs-calculator>AWS Costs Calculator</h3><p>Here is a link to the <a href=https://calculator.s3.amazonaws.com/index.html target=_blank>AWS Costs Calculator </a>.</p><p>This calculator is very comprehensive and can be difficult to navigate at first. (If you have questions you can ask HPCC)</p><h2 id=billing>Billing</h2><p>Billing is done my Amazon on a monthly basis and is calculated from the previous months usage. This billing is done via PO associated with a FAU.</p><p><a href=https://console.aws.amazon.com/billing/home#/ target=_blank>AWS Billing & Cost Management Dashboard</a> is a important webpage to have bookmarked.
It will be your main interface for the billing aspects AWS.</p><p>Billing access is allowed for the main AWS account only. If you have sub accounts for lab members all their activity is accumulated and reported back through the main aws account.</p><h2 id=budgets-controlsalerts>Budgets Controls/Alerts</h2><p>It is possable to configure budget alerts. This allows you to get notified if you are spending or are projected to spend more that you would like.</p><p>There are many different options to customize.</p><h2 id=basic-and-practical-control-example>Basic and practical control example:</h2><p>This will alert you if you are projected to spend more than $50 in a givien month so you can take action on it.</p><h3 id=billing-dashboard>Billing Dashboard</h3><ul><li>Navigate to the <a href=https://console.aws.amazon.com/billing/home#/ target=_blank>AWS Billing & Cost Management Dashboard</a></li><li>All aspects of billing are controlled from here
<img style="box-shadow:5px 5px 5px 5px grey" src=/img/cloud-aws-billing-dashboard.png title=Dashboard alt=Dashboard></li><li>Click Budget from the left</li></ul><h3 id=budgets>Budgets</h3><ul><li>This is the budget control page
<img style="box-shadow:5px 5px 5px 5px grey" src=/img/cloud-aws-billing-budget1.png title=Budget alt=Budget></li><li>Click Create Budget</li></ul><h3 id=define-budget-and-alerts>Define budget and alerts</h3><ul><li>This is the budget definition page
<img style="box-shadow:5px 5px 5px 5px grey" src=/img/cloud-aws-billing-budget2.png title="Budget Config 1" alt="Budget Config 1">
<img style="box-shadow:5px 5px 5px 5px grey" src=/img/cloud-aws-billing-budget3.png title="Budget Config 2" alt="Budget Config 2"></li><li>Fill out the Name field (what ever you would like to call it)</li><li>Fill out the Period (Monthly is preffered)</li><li>Fill out the Budgeted Amount (Limit we are interested in, in this example its $50)</li><li>The &ldquo;Refine your Budget&rdquo; section can be left as is</li><li>Fill out the &ldquo;Notify me when&rdquo; fields as shown</li><li>Fill out your main email address in the &ldquo;Email contacts&rdquo; section.</li><li>Click Create</li></ul><h3 id=budget-created>Budget created</h3><ul><li>We are back to the budget page
<img style="box-shadow:5px 5px 5px 5px grey" src=/img/cloud-aws-billing-budget-done.png title="Budget Done" alt="Budget Done"></li><li>Notice the new budget defined</li><li>You will now be notified it your speding is projected to exceed your budget</li><li>Complete</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4c457da514322cc737a3885a02aa14c8>3.5 - HPCC cfnCluster Setup</h1><h2 id=hpcc-cfncluster-setup>HPCC cfnCluster Setup.</h2><p>This will show how to use your HPCC account to configure cfnCluster; allowing you to create and control your own clusters.</p><h2 id=1-login-to-the-hpcc-cluster>1. Login to the HPCC Cluster</h2><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ssh -X username@cluster.hpcc.ucr.edu
</code></pre></div><h3 id=from-windows>From Windows</h3><p>Please refer to the login instructions of our <a href=manuals_linux-basics_intro.html#windows>Linux Basics manual</a>.</p><h2 id=2-run-hpcc_cloud-configure>2. Run hpcc_cloud configure</h2><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>hpcc_cloud configure
</code></pre></div><ul><li>Cluster Template<ul><li>Just hit enter to choose the default template</li></ul></li><li>AWS Access Key ID<ul><li>YOUR-aws_access_key_id (found in your credentials file)</li></ul></li><li>AWS Secret Access Key ID<ul><li>YOUR-aws_secret_access_key (found in your credentials file)</li></ul></li><li>AWS Region ID<ul><li>us-west-1</li></ul></li><li>VPC Name<ul><li>Just hit enter to choose the default public</li></ul></li><li>Key Name<ul><li>Choose your Key Name from the list</li></ul></li><li>VPC ID<ul><li>Choose any of the available options</li></ul></li><li>Master Subnet ID<ul><li>Choose any of the available options</li></ul></li><li>IAM User Name<ul><li>Choose your IAM User Name from the list</li></ul></li></ul><h2 id=3-setup-complete>3. Setup complete</h2><p>Now that your config file is setup correctly. You can begin to create and interact with your own cluster (described in the Cluster Control and Operation section <a href=manuals_hpcc-aws-cluster_operation.html>Link</a>)</p><h2 id=setup-walk-through>Setup Walk Through</h2><script id=asciicast-ewZjGbJkX0ZpE2sla5BoZ9aRq src=https://asciinema.org/a/ewZjGbJkX0ZpE2sla5BoZ9aRq.js async data-autoplay=false data-size=small data-speed=3></script></div><div class=td-content style=page-break-before:always><h1 id=pg-389571a10573d130fd51b9bc08293672>3.6 - Introduction</h1><h2 id=introduction>Introduction</h2><p>Getting started using HPCC and Amazon Web Service (AWS) to quickly create an on-demand cluster private to you.</p><h2 id=hpcc-aws-cluster-benefits>HPCC AWS Cluster benefits.</h2><ul><li>Build a private cluster in 10 min.<ul><li>Any number of nodes, auto scaling (up and down), limit 20 to start</li><li>Any type of compute nodes<ul><li>High memory</li><li>High CPU single/multi node</li><li>GPUs</li><li>Choose HPCC default configuration</li></ul></li></ul></li><li>For only as long as you need it - delete when done</li><li>Familiar interface and job scheduler</li><li>Easy ability to have the software you need installed by HPCC, if it’s not there already</li><li>Build as many of these clusters as you need (even at the same time)</li><li>Pay for only the time you use it - per/min billing</li></ul><h2 id=how-to-get-started>How to get started</h2><p>The manual menu on the left will walk you through the process while the simple steps are outlined below.</p><ol><li>Create a Master AWS Account (if you do not have one yet) and one or more AWS IAM account(s).</li><li>Associate your AWS Master account with Amazon as a UCR educational member to take advantage of a data egress waiver.</li><li>Set up your HPCC account to access and use your HPCC AWS Cluster.</li><li>Create your cluster and begin computing</li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-0a7cfdbbbcf4186e92cdbbda5db3dc9d>4 - Linux Basics</h1><div class=lead>What does your user need to know to try your project?</div><div class="pageinfo pageinfo-primary"><p>This is a placeholder page that shows you how to use this template site.</p></div><p>Information in this section helps your user try your project themselves.</p><ul><li><p>What do your users need to do to start using your project? This could include downloading/installation instructions, including any prerequisites or system requirements.</p></li><li><p>Introductory “Hello World” example, if appropriate. More complex tutorials should live in the Tutorials section.</p></li></ul><p>Consider using the headings below for your getting started page. You can delete any that are not applicable to your project.</p><h2 id=prerequisites>Prerequisites</h2><p>Are there any system requirements for using your project? What languages are supported (if any)? Do users need to already have any software or tools installed?</p><h2 id=installation>Installation</h2><p>Where can your user find your project code? How can they install it (binaries, installable package, build from source)? Are there multiple options/versions they can install and how should they choose the right one for them?</p><h2 id=setup>Setup</h2><p>Is there any initial setup users need to do after installation to try your project?</p><h2 id=try-it-out>Try it out!</h2><p>Can your users test their installation, for example by running a command or deploying a Hello World example?</p></div><div class=td-content style=page-break-before:always><h1 id=pg-9291f41bc052c8146c2f2d2bc1f05148>4.1 - Access</h1><h2 id=how-to-get-access>How to Get Access?</h2><p>Many of the commands referenced here may work in any local <code>bash</code> shell, however we will focus on running these on the Linux HPC cluster.
In order to gain access to the cluster, you will need to request an account and also download an SSH client.</p><ul><li>Users at UC Riverside can apply for an account on our Linux clusters by sending an account request to Support (<a href=mailto:support@hpcc.ucr.edu>support@hpcc.ucr.edu</a>).</li><li>Install your preferred ssh client on your local machine (we can help you with this).</li></ul><h3 id=windows>Windows</h3><ol><li>Open MobaXTerm <a href=https://mobaxterm.mobatek.net/download-home-edition.html>Download MobaXTerm</a></li><li>Click on &ldquo;Start local terminal&rdquo; in the center of the window.</li></ol><h3 id=mac>Mac</h3><ol><li>Download and install <a href=https://www.xquartz.org/>XQuartz</a>, this is optional and only needed if you want X11 Forwarding.</li><li>Open Terminal or <a href=https://www.iterm2.com/downloads.html>iterm2</a></li></ol><h3 id=logging-in>Logging in</h3><ul><li><p>Now that you have a terminal open, execute the following on the command line:
<code>ssh -X myusername@cluster.hpcc.ucr.edu</code></p><p><code>myusername</code> is your username on the cluster.
You will be asked to enter your password. Simply type it (even if you cannot see anything) and press enter.</p></li></ul><h2 id=change-password>Change Password</h2><ol><li>Log-in to the cluster via SSH</li><li>Once you have logged in, type the following command:
<code>passwd</code></li><li>Enter your current password (the random characters that you were given as your initial password)</li><li>Enter your new password (you will be asked to type it twice for verification)</li></ol><h3 id=minimum-password-requirements>Minimum password requirements</h3><ul><li>Total length at least 8 characters long</li><li>Must have at least 3 of the following:<ul><li>Lowercase character</li><li>Uppercase character</li><li>Number</li><li>Punctuation character</li></ul></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-ec9dd3a11b1821f51d2bd89f64cd57aa>4.2 - Command Line Basics</h1><h2 id=basics>Basics</h2><h3 id=syntax-and-notes>Syntax and Notes</h3><ul><li><p>Remember the UNIX/Linux command line is case sensitive!</p></li><li><p>The hash (pound) sign <code>#</code> indicates end of a command and the start of a comment.</p></li><li><p>The notation <code>&lt;...></code> refers to variables and file names that need to be specified by the user. The symbols <code>&lt;</code> and <code>></code> need to be excluded.</p></li><li><p>No need to memorize all of these commands, by using these commands you will naturally memorize the most frequently used.</p></li><li><p>When specifying file names:</p><ul><li>The <code>.</code> (dot) refers to the present working directory</li><li>The <code>~</code> (tilde) refers to user&rsquo;s home directory</li></ul></li></ul><h3 id=commands>Commands</h3><h4 id=navigation-and-exploration>Navigation and Exploration</h4><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#204a87>pwd</span>               <span style=color:#8f5902;font-style:italic># &#34;Print working directory&#34;; show your current path</span>

ls                <span style=color:#8f5902;font-style:italic># &#34;List&#34; contents of current directory</span>
ls -l             <span style=color:#8f5902;font-style:italic># Similar to ls, but provides additional info on files and directories</span>
ls -a             <span style=color:#8f5902;font-style:italic># List all files, including hidden files (.name) as well</span>
ls -R             <span style=color:#8f5902;font-style:italic># Lists subdirectories recursively</span>
ls -t             <span style=color:#8f5902;font-style:italic># Lists files in chronological order</span>

<span style=color:#204a87>cd</span> &lt;dir_name&gt;     <span style=color:#8f5902;font-style:italic># &#34;Change directory&#34; to specified path</span>
<span style=color:#204a87>cd</span>                <span style=color:#8f5902;font-style:italic># Brings you to your home directory</span>
<span style=color:#204a87>cd</span> ~              <span style=color:#8f5902;font-style:italic># Also bring you to your home directory</span>
<span style=color:#204a87>cd</span> ..             <span style=color:#8f5902;font-style:italic># Moves one directory up</span>
<span style=color:#204a87>cd</span> ../../         <span style=color:#8f5902;font-style:italic># Moves two directories up (and so on)</span>
<span style=color:#204a87>cd</span> -              <span style=color:#8f5902;font-style:italic># Go back to you were previously (before the last directory change)</span>
</code></pre></div><h4 id=informative>Informative</h4><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>file &lt;file-name&gt;  <span style=color:#8f5902;font-style:italic># Show type of file (text, binary, compressed, etc...)</span>
id                <span style=color:#8f5902;font-style:italic># Shows your user name and associated groups</span>
hostname          <span style=color:#8f5902;font-style:italic># Shows the name of the machine your shell is currently on</span>
</code></pre></div><h4 id=files-and-directories>Files and Directories</h4><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>mkdir &lt;dir_name&gt;   <span style=color:#8f5902;font-style:italic># Creates specified directory</span>
rmdir &lt;dir_name&gt;   <span style=color:#8f5902;font-style:italic># Removes empty directory</span>
rm &lt;file_name&gt;     <span style=color:#8f5902;font-style:italic># Removes file_name</span>
rm -r &lt;dir_name&gt;   <span style=color:#8f5902;font-style:italic># Removes directory including its contents, but asks for confirmation</span>
rm -rf &lt;dir_name&gt;  <span style=color:#8f5902;font-style:italic># Same as above, but turns confirmation off. Use with caution</span>
cp &lt;name&gt; &lt;path&gt;   <span style=color:#8f5902;font-style:italic># Copy file/directory as specified in path (-r to include content in directories)</span>
mv &lt;name1&gt; &lt;name2&gt; <span style=color:#8f5902;font-style:italic># Renames directories or files</span>
mv &lt;name&gt; &lt;path&gt;   <span style=color:#8f5902;font-style:italic># Moves file/directory as specified in path</span>
</code></pre></div><h3 id=copy-and-paste>Copy and paste</h3><p>The methods to copy and paste on the command line differ depending on your operating systems (ie. Mac OSX, MS Windows, Linux) and your SSH application (ie. Terminal, MobaXTerm).</p><ul><li>Linux (xterm)</li></ul><pre><code># Copy
CTRL+SHIFT+C

# Paste
CTRL+SHIFT+V
</code></pre><ul><li>MS Windows (MobaXTerm)</li></ul><pre><code># Copy by highlighting with mouse

# Paste
SHIFT+INSERT
</code></pre><ul><li>Mac OSX (Terminal)</li></ul><pre><code># Copy
COMMAND+c

# Paste
COMMAND+v
</code></pre><h3 id=shortcuts>Shortcuts</h3><h4 id=command-history>Command History</h4><ul><li>↑<code> # Up arrow key scrolls backwards through command history</code></li><li>↓<code> # Down arrow key scrolls forwards through command history</code></li><li><code>history # Shows all commands you have used recently</code></li></ul><h4 id=auto-completion>Auto-completion</h4><p>The tab (⇥) key auto completes commands or file names if there is only one option.
Hitting the tab (⇥) key twice will list multiple options.
Keep in mind that there are no spaces between the tab (⇥) keys and the partial names of commands or files.</p><p>Show all directories under my home that I can <code>cd</code> into:</p><p><code>cd ~/</code>⇥⇥</p><p>Show all files that I can <code>ls</code> with names that start with &ldquo;myfile&rdquo;:</p><p><code>ls myfile</code>⇥⇥</p><p>Show all commands that I can run with names that start with &ldquo;sp&rdquo;:</p><p><code>sp</code>⇥⇥</p><h4 id=cursor>Cursor</h4><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>Ctrl+a    <span style=color:#8f5902;font-style:italic># Cursor to beginning of command line</span>
Ctrl+e    <span style=color:#8f5902;font-style:italic># Cursor to end of command line</span>
Ctrl+w    <span style=color:#8f5902;font-style:italic># Cut last word</span>
Ctrl+k    <span style=color:#8f5902;font-style:italic># Cut to the end of the line</span>
Ctrl+y    <span style=color:#8f5902;font-style:italic># Paste (&#34;yank&#34;) content that was cut earlier (by Ctrl-w or Ctrl-k)</span>
</code></pre></div><h3 id=other-useful-unix-commands>Other Useful Unix Commands</h3><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>df -h /scratch          <span style=color:#8f5902;font-style:italic># Show local disk space for /scratch, do not use for /rhome or /bigdata</span>
free -h                 <span style=color:#8f5902;font-style:italic># Show memory of current machine</span>
bc                      <span style=color:#8f5902;font-style:italic># Command-line calculator (to exit type &#39;quit&#39;)</span>
wget &lt;URL&gt;              <span style=color:#8f5902;font-style:italic># Download a file or directory from the web</span>
ln -s &lt;FILENAME1&gt; &lt;FILENAME2&gt; <span style=color:#8f5902;font-style:italic># Creates symbolic link (shortcut, or alias) for file or directory</span>
du -sh .                <span style=color:#8f5902;font-style:italic># Shows size of current directory</span>
du -sh &lt;FILENAME&gt;       <span style=color:#8f5902;font-style:italic># Shows size of individual file</span>
du -s * <span style=color:#000;font-weight:700>|</span> sort -nr      <span style=color:#8f5902;font-style:italic># Shows size of each file within current directory, sorted by size</span>
</code></pre></div><h2 id=help>Help</h2><p>Not all command have help documentation available, however one of these methods will likely work:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#204a87>help</span> &lt;COMMAND&gt;    <span style=color:#8f5902;font-style:italic># Show help for a Bash command</span>
man &lt;COMMAND&gt;     <span style=color:#8f5902;font-style:italic># Show the manual page for a program (press the &#39;q&#39; key to exit)</span>
&lt;COMMAND&gt; --help  <span style=color:#8f5902;font-style:italic># Show help documentation for command</span>
&lt;COMMAND&gt; -h      <span style=color:#8f5902;font-style:italic># Show help documentation for command</span>
</code></pre></div><p>Online help: <a href=https://www.google.com/>Google</a> is your friend.</p><p>Universally available Linux commands, with detailed examples and explanations: <a href=https://www.linuxconfig.org/linux-commands>https://www.linuxconfig.org/linux-commands</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-7eb831e5c7bb1c75993d9c2d1660258a>4.3 - File Systems and Transfers</h1><h2 id=file-systems>File Systems</h2><p>The file system in Linux is where you can save data, files, scripts, etc.
There are different storage pools based on the path.
In Linux you can provide any storage pool from any directory, not like MS Windows systems, where a drive letter is assigned to each storage pool (ie. &ldquo;C:&rdquo;,&ldquo;D:").
This means that by navigating through nested directories, you may find different capacity limits, depending on where you are.</p><h2 id=locations>Locations</h2><p>Most unix system, including Linux, have a common directory hierarchy. The following is called the <code>root</code> level, since it is at the &ldquo;top&rdquo; like roots of a inverted tree:</p><pre><code>/
|-- bigdata
|-- bin
|-- boot
|-- dev
|-- etc
|-- home
|-- lib
|-- lib64
|-- media
|-- mnt
|-- opt
|-- proc
|-- rhome
|-- root
|-- run
|-- sbin
|-- srv
|-- sys
|-- tmp
|-- usr
`-- var
</code></pre><p>The two most important directories are <code>/rhome</code> and <code>/bigdata</code>, since this is where your code and data will be stored.
These two directories are IBM Spectrum Scale (GPFS) pools, so storage quotas apply.
Your home directory lives directly under <code>/rhome</code> and your groups shared storage lives under <code>/bigdata</code> (if extra storage was purchased).
These two &ldquo;bigdata&rdquo; directories <code>/bigdata/groupname/username</code> and <code>/bigdata/groupname/shared</code> are symlinked (alias/shortcut) to your home directory for convenience, as seen here:</p><pre><code>/
|-- bigdata
    |-- groupname (Quota based on purchase)
        |-- username &lt;-------------|
        |-- shared &lt;----------|    |
|-- bin                       |    |
|-- boot                      |    |
|-- dev                       |    |
|-- etc                       |    |
|-- home                      |    |
|-- lib                       |    |
|-- lib64                     |    |
|-- media                     |    |
|-- mnt                       |    |
|-- opt                       |    |
|-- proc                      |    |
|-- rhome                     |    |
    |-- username (20GB Quota) |    |
        |-- shared ----------&gt;|    |
        |-- bigdata --------------&gt;|
|-- root
|-- run
|-- sbin
|-- srv
|-- sys
|-- tmp
|-- usr
`-- var
</code></pre><p>For more information regarding these locations, and others, visit <a href=manuals_linux-cluster_storage>HPCC Cluster: Data Storage</a>.</p><h3 id=case-sensitive>Case sensitive</h3><p>All paths and commands are case sensitive, an uppercase letter is not the same as a lowercase letter.</p><h3 id=path-types>Path Types</h3><p>An absolute path is a full path from top to bottom, from the <code>root</code> to the <code>leaf</code>:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>/rhome/username/example_dir/example_file
</code></pre></div><p>A relative path is a partial path with the current working directory is the starting point:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>example_dir/example_file
</code></pre></div><h2 id=commands>Commands</h2><p>Here are many common commands related to files and file systems (run <code>man &lt;command></code> for more information):</p><pre><code>pwd           # Print working directory
ls            # List files in directory
touch         # Make an empty file
mkdir         # Make a directory
cd            # Change to directory
cp            # Copy file[s] from a directory to a directory
mv            # Move file[s] from a directory to a directory
rm            # Remove a file
rmdir         # Remove an empty directory
df            # Check size of storage pool
du            # Check size of file or directory
check_quota   # Check quota for home and bigdata
</code></pre><blockquote><p>Note: <code>CTRL+c</code> will cancel a running command</p></blockquote><h2 id=file-transfers>File Transfers</h2><p>If you would rather use a graphical interface, instead of the command line, try FileZilla <a href=https://filezilla-project.org/>FileZilla</a> for file exchanges.</p><ul><li><p>To copy files To the server run the following on your workstation or laptop:</p><p><code>scp -r &lt;path_to_directory> &lt;your_username>@&lt;host_name>:</code></p></li><li><p>To copy files From the server run the following on your workstation or laptop:</p><p><code>scp -r &lt;your_username>@&lt;host_name>:&lt;path_to_directory> .</code></p></li></ul><p>For more advanced methods of file transfers to the cluster refer to <a href=manuals_linux-cluster_sharing>Cluster - Sharing Data</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-ea36b6adbbc1635f99e1da1659fbe7ab>4.4 - Finding Things</h1><h2 id=find-files>Find Files</h2><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>find ~ -name <span style=color:#4e9a06>&#34;*pattern*&#34;</span>          <span style=color:#8f5902;font-style:italic># Searches for *pattern* in and below your home directory</span>
find ~ -iname <span style=color:#4e9a06>&#34;*pattern*&#34;</span>         <span style=color:#8f5902;font-style:italic># Same as above, but case insensitive</span>
find ~ -type f -mtime -2          <span style=color:#8f5902;font-style:italic># Searches for files you have modified in the last two days</span>
</code></pre></div><p>Useful <code>find</code> arguments:</p><ul><li><code>-user &lt;userName></code></li><li><code>-group &lt;groupName></code></li><li><code>-ctime &lt;number of days ago changed></code></li><li><code>-exec &lt;command to run on each file> {} \;</code></li></ul><h2 id=find-text>Find Text</h2><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>grep <span style=color:#4e9a06>&#34;pattern&#34;</span> &lt;FILENAME&gt;                              <span style=color:#8f5902;font-style:italic># Provides lines in a file where &#34;pattern&#34; appears</span>
grep -H <span style=color:#4e9a06>&#34;pattern&#34;</span>                                      <span style=color:#8f5902;font-style:italic># -H prints out file name in front of pattern</span>
find ~ -name <span style=color:#4e9a06>&#34;*.txt&#34;</span> -exec grep -H <span style=color:#4e9a06>&#34;pattern&#34;</span> <span style=color:#ce5c00;font-weight:700>{}</span> <span style=color:#4e9a06>\;</span>     <span style=color:#8f5902;font-style:italic># Search lines where &#34;pattern&#34; appears in files with names that end with &#34;.txt&#34;</span>
</code></pre></div><h2 id=find-applications>Find Applications</h2><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>which &lt;APPLICATION_NAME&gt;                <span style=color:#8f5902;font-style:italic># Location of application</span>
whereis &lt;APPLICATION_NAME&gt;              <span style=color:#8f5902;font-style:italic># Searches for executables in set of directories</span>
rpm -qa <span style=color:#000;font-weight:700>|</span> grep <span style=color:#4e9a06>&#34;pattern&#34;</span>                <span style=color:#8f5902;font-style:italic># List all RPM packages and filter based on &#34;pattern&#34;</span>
</code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-d64f50f5d5ae8ccbd34759787e1d5175>4.5 - Permissions and Ownership</h1><h2 id=overview>Overview</h2><p>In Linux (and Unix systems in general), access to files and directories is
controlled by a system of owners, groups, and permission bits. Changing these
settings is necessary to control access by other users.
The permission system also affects what files can be executed.</p><h2 id=ownership-levels>Ownership Levels</h2><ul><li><strong>user (u)</strong> - User ownership of a file/directory. This user has the special
right to change the permission bits and group ownership.</li><li><strong>group (g)</strong> - Group ownership of a file/directory. Members of this group may
be assigned greater access rights than non-members.</li><li><strong>other (o)</strong> - Everyone else that isn&rsquo;t the owning user or from the owning
group.</li></ul><h2 id=permission-bits>Permission Bits</h2><p>The elemental permissions in Linux/Unix are read, write, and execute. Users and
groups can have one many, or none of these rights. Their meanings are as follows:</p><table><thead><tr><th></th><th>Letter</th><th>Number</th><th>File</th><th>Directory</th></tr></thead><tbody><tr><td>Read</td><td>r</td><td>4</td><td>View the contents</td><td>View the listings</td></tr><tr><td>Write</td><td>w</td><td>2</td><td>Modify the contents</td><td>Create a new file, or rename or delete existing files</td></tr><tr><td>Execute</td><td>x</td><td>1</td><td>Execute a program/script</td><td>Traversal rights</td></tr></tbody></table><h2 id=checking-permissions>Checking Permissions</h2><p>Annotated output for <code>ls -la</code>:</p><pre><code>---------- File type (d = directory, - = regular file, l = symlink)
|--------- User permission triplet
||  ------ Group permission triplet
||  |  --- Other permission triplet
||  |  |
||  |  |       [user] [group]
drwx-----x  61 username groupname   4096 Feb 24 16:39 ./
drwxr-xr-x 688 root   root       262144 Feb 24 11:05 ../
drwx------   2 username groupname   4096 Feb  2 22:45 .ssh/
drwxr-xr-x   5 username groupname   4096 Dec 12 15:57 Downloads/
drwxr-xr-x   2 username groupname   4096 Jan  9 16:29 bin/
-rw-------   1 username groupname   7960 Feb 23 18:37 .bash_history
-rw-r--r--   1 username groupname    306 Nov  3 15:08 .bashrc
-rw-r--r--   1 username groupname    677 Apr  8  2013 .profile
-rw-r--r--   1 username groupname    128 Nov 30 12:38 .tmux.conf
-rw-r--r--   1 username groupname  12126 Nov  2 13:14 .vimrc
lrwxrwxrwx   1 username groupname     23 Sep 12 10:49 bigdata -&gt; /bigdata/groupname/username/
-rw-r--r--   1 username groupname   5657 Sep 19 11:31 bookmarks.html
lrwxrwxrwx   1 username groupname     23 Sep 12 10:49 shared -&gt; /bigdata/groupname/shared/
</code></pre><p>Assign write and execute permissions to user and group</p><p><code>chmod ug+rx my_file</code></p><p>To remove all permissions from all three user groups</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>chmod ugo-rwx my_file
            <span style=color:#8f5902;font-style:italic># &#39;+&#39; causes the permissions selected to be added</span>
            <span style=color:#8f5902;font-style:italic># &#39;-&#39; causes them to be removed</span>
            <span style=color:#8f5902;font-style:italic># &#39;=&#39; causes them to be the only permissions that the file has.</span>

chmod +rx public_html/ or $ chmod <span style=color:#0000cf;font-weight:700>755</span> public_html/ <span style=color:#8f5902;font-style:italic># Example for number system:</span>
</code></pre></div><h2 id=change-ownership>Change ownership</h2><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>chown &lt;user&gt; &lt;file or dir&gt;         <span style=color:#8f5902;font-style:italic># changes user ownership</span>
chgrp &lt;group&gt; &lt;file or dir&gt;        <span style=color:#8f5902;font-style:italic># changes group ownership</span>
chown &lt;user&gt;:&lt;group&gt; &lt;file or dir&gt; <span style=color:#8f5902;font-style:italic># changes user &amp; group ownership</span>
</code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-dbf76568729e6f45436864bb508b3ed3>4.6 - Piping</h1><h2 id=piping>Piping</h2><p>One of the the most powerful things you can do in Linux is piping.
This allows chaining of commands so that the output (<code>STDOUT</code>) of one command is the input (<code>STDIN</code>) for another.
This is done by placing a <code>|</code> (pipe) character between the commands.
Please note that not all commands support this, for example if your command is not taking input from <code>STDIN</code>.</p><p>As an example, let&rsquo;s collect all the lines where <code>pattern</code> is found in a file, then count how many lines were found:</p><pre><code>grep 'pattern' filename | wc -l
</code></pre><p>You can pipe as many commands together as you like, not just two.
For example, you can combined two CSV files and extract the first column, then filter for only unique values:</p><pre><code>cat filename1.csv filename2.csv | cut -f 1 | sort | uniq
</code></pre><p>For a few more simple examples, please visit here <a href=https://www.guru99.com/linux-pipe-grep.html>Pipe, Grep and Sort Command in Linux/Unix with Examples</a>.
Or you can try searching Google for even more complex examples, the possibilities are endless.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-c2544b888e150bbe542cef6b8043ac41>4.7 - Process Management</h1><h2 id=process-management>Process Management</h2><p>Basic Linux process management commands only apply to processes that are running on the current machine you are logged into.
This means that you cannot use these commands to manage jobs.
Jobs on the cluster are managed through <code>Slurm</code>, see <a href=manuals_linux-cluster_jobs>Cluster Jobs</a> for more details.
However, these commands are still useful for pausing, backgrounding, killing processes on a login node directly.
This commands could also be useful when running an interactive session on a compute node.</p><h3 id=user-management>User Management</h3><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>top               <span style=color:#8f5902;font-style:italic># view top consumers of memory and CPU (press 1 to see per-CPU statistics)</span>
who               <span style=color:#8f5902;font-style:italic># Shows who is logged into system</span>
w                 <span style=color:#8f5902;font-style:italic># Shows which users are logged into system and what they are doing</span>
</code></pre></div><h3 id=process-management-1>Process Management</h3><h4 id=processes>Processes</h4><pre><code>ps                         # Shows processes running by user
ps -e                      # Shows all processes on system; try also '-a' and '-x' arguments
ps ux -u &lt;USERNAME&gt;        # Shows all processes owned by user
ps axjf                    # Shows the child-parent hierarchy of all processes
ps -o %t -p &lt;PID&gt;          # Shows how long a particular process was running.
                           # (E.g. 6-04:30:50 means 6 days 4 hours ...)
</code></pre><p>Here are two common utilities for displaying processes, sorting, and even killing them:</p><pre><code>top            # Basic text based interface for exploring and managing processes
htop           # Text based interface for exploring and managing processes
</code></pre><blockquote><p>Note <code>q</code> to quit and <code>?</code> to see help</p></blockquote><h4 id=background-resume-cancel>Background Resume Cancel</h4><pre><code>CTRL+z ENTER         # Suspend a process in the background
fg                   # Resume a suspended process and brings it into foreground
bg                   # Resume a suspended process but keeps it running in the background

CTRL+c               # Cancel the process that is currently running in the foreground
</code></pre><h4 id=pid>PID</h4><pre><code>echo $!              # Get PID of last executed command
</code></pre><h4 id=killing>Killing</h4><pre><code>kill -l              # List all of the signals that can be sent to a process
kill &lt;PID&gt;           # Kill a specific process with process ID using SIGTERM
kill -9 &lt;PID&gt;        # Violently kill process with process ID using SIGKILL, may corrupt files
</code></pre><h3 id=more-on-terminating-processes>More on Terminating Processes</h3><p><a href=https://www.digitalocean.com/community/tutorials/how-to-use-ps-kill-and-nice-to-manage-processes-in-linux>DigitalOcean - How To Use ps, kill, and nice to Manage Processes in Linux</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-1c4417cb6a57ee480443dcdfa3f74862>4.8 - Shell Bootcamp</h1><h2 id=the-unix-shell>The Unix Shell</h2><p>When you log into UNIX/LINUX system, then is starts a program called the Shell. It provides you with a working environment and interface to the operating system. Usually there are several different shell programs installed. The shell program bash is one of the most common ones.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>finger &lt;user_name&gt; <span style=color:#8f5902;font-style:italic># shows which shell you are using</span>
chsh -l <span style=color:#8f5902;font-style:italic># gives list of shell programs available on your system (does not work on all UNIX variants)</span>
&lt;shell_name&gt; <span style=color:#8f5902;font-style:italic># switches to different shell</span>
</code></pre></div><h3 id=stdin-stdout-stderr-redirections-and-wildcards>STDIN, STDOUT, STDERR, Redirections, and Wildcards</h3><p>See <a href=http://www.tldp.org/HOWTO/Bash-Prog-Intro-HOWTO-3.html>LINUX HOWTOs</a></p><p>By default, UNIX commands read from standard input (STDIN) and send their output to standard out (STDOUT).</p><p>You can redirect them by using the following commands:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>&lt;beginning-of-filename&gt;*         <span style=color:#8f5902;font-style:italic># * is wildcard to specify many files</span>
ls &gt; file                        <span style=color:#8f5902;font-style:italic># prints ls output into specified file</span>
<span style=color:#204a87>command</span> &lt; my_file                <span style=color:#8f5902;font-style:italic># uses file after &#39;&lt;&#39; as STDIN</span>
<span style=color:#204a87>command</span> &gt;&gt; my_file               <span style=color:#8f5902;font-style:italic># appends output of one command to file</span>
<span style=color:#204a87>command</span> <span style=color:#000;font-weight:700>|</span> tee my_file            <span style=color:#8f5902;font-style:italic># writes STDOUT to file and prints it to screen</span>
<span style=color:#204a87>command</span> &gt; my_file<span style=color:#000;font-weight:700>;</span> cat my_file   <span style=color:#8f5902;font-style:italic># writes STDOUT to file and prints it to screen</span>
<span style=color:#204a87>command</span> &gt; /dev/null              <span style=color:#8f5902;font-style:italic># turns off progress info of applications by redirecting</span>
                                 <span style=color:#8f5902;font-style:italic># their output to /dev/null</span>
grep my_pattern my_file <span style=color:#000;font-weight:700>|</span> wc     <span style=color:#8f5902;font-style:italic># Pipes (|) output of &#39;grep&#39; into &#39;wc&#39;</span>
grep my_pattern my_non_existing_file <span style=color:#0000cf;font-weight:700>2</span> &gt; my_stderr <span style=color:#8f5902;font-style:italic># prints STDERR to file</span>
</code></pre></div><h3 id=useful-shell-commands>Useful shell commands</h3><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>cat &lt;file1&gt; &lt;file2&gt; &gt; &lt;cat.out&gt;      <span style=color:#8f5902;font-style:italic># concatenate files in output file &#39;cat.out&#39;</span>
paste &lt;file1&gt; &lt;file2&gt; &gt; &lt;paste.out&gt;  <span style=color:#8f5902;font-style:italic># merges lines of files and separates them by tabs (useful for tables)</span>
cmp &lt;file1&gt; &lt;file2&gt;                  <span style=color:#8f5902;font-style:italic># tells you whether two files are identical</span>
diff &lt;fileA&gt; &lt;fileB&gt;                 <span style=color:#8f5902;font-style:italic># finds differences between two files</span>
head -&lt;number&gt; &lt;file&gt;                <span style=color:#8f5902;font-style:italic># prints first lines of a file</span>
tail -&lt;number&gt; &lt;file&gt;                <span style=color:#8f5902;font-style:italic># prints last lines of a file</span>
split -l &lt;number&gt; &lt;file&gt;             <span style=color:#8f5902;font-style:italic># splits lines of file into many smaller ones</span>
csplit -f out fasta_batch <span style=color:#4e9a06>&#34;%^&gt;%&#34;</span> <span style=color:#4e9a06>&#34;/^&gt;/&#34;</span> <span style=color:#4e9a06>&#34;{*}&#34;</span> <span style=color:#8f5902;font-style:italic># splits fasta batch file into many files</span>
                                     <span style=color:#8f5902;font-style:italic># at &#39;&gt;&#39;</span>
sort &lt;file&gt;                          <span style=color:#8f5902;font-style:italic># sorts single file, many files and can merge (-m)</span>
                                     <span style=color:#8f5902;font-style:italic># them, -b ignores leading white space, ...</span>
sort -k 2,2 -k 3,3n input_file &gt; output_file <span style=color:#8f5902;font-style:italic># sorts in table column 2 alphabetically and</span>
                                     <span style=color:#8f5902;font-style:italic># column 3 numerically, &#39;-k&#39; for column, &#39;-n&#39; for</span>
                                     <span style=color:#8f5902;font-style:italic># numeric</span>
sort input_file <span style=color:#000;font-weight:700>|</span> uniq &gt; output_file <span style=color:#8f5902;font-style:italic># uniq command removes duplicates and creates file/table</span>
                                     <span style=color:#8f5902;font-style:italic># with unique lines/fields</span>
join -1 <span style=color:#0000cf;font-weight:700>1</span> -2 <span style=color:#0000cf;font-weight:700>1</span> &lt;table1&gt; &lt;table2&gt;     <span style=color:#8f5902;font-style:italic># joins two tables based on specified column numbers</span>
                                     <span style=color:#8f5902;font-style:italic># (-1 file1, 1: col1; -2: file2, col2). It assumes</span>
                                     <span style=color:#8f5902;font-style:italic># that join fields are sorted. If that is not the case,</span>
                                     <span style=color:#8f5902;font-style:italic># use the next command:</span>
sort table1 &gt; table1a<span style=color:#000;font-weight:700>;</span> sort table2 &gt; table2a<span style=color:#000;font-weight:700>;</span> join -a <span style=color:#0000cf;font-weight:700>1</span> -t <span style=color:#4e9a06>&#34;</span><span style=color:#204a87;font-weight:700>$(</span><span style=color:#204a87>echo</span> -e <span style=color:#4e9a06>&#39;\t&#39;</span><span style=color:#204a87;font-weight:700>)</span><span style=color:#4e9a06>&#34;</span> table1a table2a &gt; table3                               <span style=color:#8f5902;font-style:italic># &#39;-a &lt;table&gt;&#39; prints all lines of specified table!</span>
                                     <span style=color:#8f5902;font-style:italic># Default prints only all lines the two tables have in</span>
                                     <span style=color:#8f5902;font-style:italic># common. &#39;-t &#34;$(echo -e &#39;\t&#39;)&#34; -&gt;&#39; forces join to</span>
                                     <span style=color:#8f5902;font-style:italic># use tabs as field separator in its output. Default is</span>
                                     <span style=color:#8f5902;font-style:italic># space(s)!!!</span>
cat my_table <span style=color:#000;font-weight:700>|</span> cut -d , -f1-3        <span style=color:#8f5902;font-style:italic># cut command prints only specified sections of a table,</span>
                                     <span style=color:#8f5902;font-style:italic># -d specifies here comma as column separator (tab is</span>
                                     <span style=color:#8f5902;font-style:italic># default), -f specifies column numbers.</span>
grep                                 <span style=color:#8f5902;font-style:italic># see chapter 4</span>
egrep                                <span style=color:#8f5902;font-style:italic># see chapter 4</span>
</code></pre></div><h2 id=screen>Screen</h2><p>Screen references</p><ol><li><a href=http://fosswire.com/post/2008/08/video-tutorial-getting-started-with-gnu-screen/>Screen Turorial</a></li><li><a href=http://aperiodic.net/screen/quick_reference>Screen Cheat Sheet</a></li></ol><h3 id=starting-a-new-screen-session>Starting a New Screen Session</h3><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>screen                 <span style=color:#8f5902;font-style:italic># Start a new session</span>
screen -S &lt;some-name&gt;  <span style=color:#8f5902;font-style:italic># Start a new session and gives it a name</span>
</code></pre></div><p>Commands to Control Screen</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>Ctrl-a d <span style=color:#8f5902;font-style:italic>#  Detach from the screen session</span>
Ctrl-a c <span style=color:#8f5902;font-style:italic># Create a new window inside the screen session</span>
Ctrl-a Space <span style=color:#8f5902;font-style:italic># Switch to the next window</span>
Ctrl-a a <span style=color:#8f5902;font-style:italic># Switch to the window that you were previously on</span>
Ctrl-a <span style=color:#4e9a06>&#34; # List all open windows. Double-quotes &#34;</span> are typed with the Shift key
Ctrl-d or <span style=color:#204a87>type</span> <span style=color:#204a87>exit</span> <span style=color:#8f5902;font-style:italic># Exit out of the current window. Exiting form the last window will end the screen session</span>
Ctrl-a <span style=color:#ce5c00;font-weight:700>[</span> <span style=color:#8f5902;font-style:italic># Enters the scrolling mode. Use Page Up and Page Down keys to scroll through the window. Hit the Enter key twice to return to normal mode.</span>
</code></pre></div><h3 id=attaching-to-screen-sessions>Attaching to Screen Sessions</h3><p>From any computer, you can attach to a screen session after SSH-ing into a server.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>screen -r              <span style=color:#8f5902;font-style:italic># Attaches to an existing session, if there is only one</span>
screen -r              <span style=color:#8f5902;font-style:italic># Lists available sessions and their names, if there are more then one session running</span>
screen -r &lt;some-name&gt;  <span style=color:#8f5902;font-style:italic># Attaches to a specific session</span>
screen -r &lt;first-few-letters-of-name&gt; <span style=color:#8f5902;font-style:italic># Type just the first few letters of the name</span>
                       <span style=color:#8f5902;font-style:italic># and you will be attached to the session you need</span>
</code></pre></div><h3 id=destroying-screen-sessions>Destroying Screen Sessions</h3><ol><li>Terminate all programs that are running in the screen session. The standard way to do that is: <code>Ctrl-c</code></li><li>Exit out of your shell: <code>exit</code></li><li>Repeat steps 1 and 2 until you see the message: <code>[screen is terminating]</code></li></ol><p>There may be programs running in different windows of the same screen session. That&rsquo;s why you may need to terminate programs and exit shells multiple time.</p><h3 id=tabs-and-a-reasonably-large-history-buffer>Tabs and a Reasonably Large History Buffer</h3><p>For a better experience with screen, run</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>cp ~/.screenrc ~/.screenrc.backup 2&gt; /dev/null
<span style=color:#204a87>echo</span> <span style=color:#4e9a06>&#39;startup_message off
</span><span style=color:#4e9a06>defscrollback 10240
</span><span style=color:#4e9a06>caption always &#34;%{=b dy}{ %{= dm}%H %{=b dy}}%={ %?%{= dc}%-Lw%?%{+b dy}(%{-b r}%n:%t%{+b dy})%?(%u)%?%{-dc}%?%{= dc}%+Lw%? %{=b dy}}&#34;
</span><span style=color:#4e9a06>&#39;</span> &gt; ~/.screenrc
</code></pre></div><h2 id=simple-one-liner-shell-scripts>Simple One-Liner Shell Scripts</h2><p>Web page for <a href=http://linuxcommand.org/script_library.php>script download</a>.</p><p>Renames many files *.old to *.new. To test things first, replace &lsquo;do mv&rsquo; with &lsquo;do echo mv&rsquo;:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#204a87;font-weight:700>for</span> i in *.input<span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>do</span> mv <span style=color:#000>$i</span> <span style=color:#4e9a06>${</span><span style=color:#000>i</span><span style=color:#000;font-weight:700>/</span><span style=color:#4e9a06>\.</span><span style=color:#000>old</span><span style=color:#000;font-weight:700>/</span><span style=color:#4e9a06>\.</span><span style=color:#000>new</span><span style=color:#4e9a06>}</span><span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>done</span>
<span style=color:#204a87;font-weight:700>for</span> i in *<span style=color:#4e9a06>\ </span>*<span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>do</span> mv <span style=color:#4e9a06>&#34;</span><span style=color:#000>$i</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>i</span><span style=color:#000;font-weight:700>// /_</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span><span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>done</span> <span style=color:#8f5902;font-style:italic># Replaces spaces in files by underscores</span>
</code></pre></div><p>Run an application in loops on many input files:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#204a87;font-weight:700>for</span> i in *.input<span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>do</span> ./application <span style=color:#000>$i</span><span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>done</span>
</code></pre></div><p>Run fastacmd from BLAST program in loops on many *.input files and create corresponding *.out files:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#204a87;font-weight:700>for</span> i in *.input<span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>do</span> fastacmd -d /data/../database_name -i <span style=color:#000>$i</span> &gt; <span style=color:#000>$i</span>.out<span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>done</span>
</code></pre></div><p>Run SAM&rsquo;s target99 on many input files:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#204a87;font-weight:700>for</span> i in *.pep<span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>do</span> target99 -db /usr/../database_name -seed <span style=color:#000>$i</span> -out <span style=color:#000>$i</span><span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>done</span>
Search in many files <span style=color:#204a87;font-weight:700>for</span> a pattern and print occurrences together with file names.
<span style=color:#204a87;font-weight:700>for</span> j in <span style=color:#0000cf;font-weight:700>0</span> <span style=color:#0000cf;font-weight:700>1</span> <span style=color:#0000cf;font-weight:700>2</span> <span style=color:#0000cf;font-weight:700>3</span> <span style=color:#0000cf;font-weight:700>4</span> <span style=color:#0000cf;font-weight:700>5</span> <span style=color:#0000cf;font-weight:700>6</span> <span style=color:#0000cf;font-weight:700>7</span> <span style=color:#0000cf;font-weight:700>8</span> 9<span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>do</span> grep -iH &lt;my_pattern&gt; *<span style=color:#000>$j</span>.seq<span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>done</span>
</code></pre></div><p>Example of how to run an interactive application (tmpred) that asks for file name input/output:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#204a87;font-weight:700>for</span> i in *.pep<span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>do</span> <span style=color:#204a87>echo</span> -e <span style=color:#4e9a06>&#34;</span><span style=color:#000>$i</span><span style=color:#4e9a06>\n\n17\n33\n\n\n&#34;</span> <span style=color:#000;font-weight:700>|</span> ./tmpred <span style=color:#000>$i</span> &gt; <span style=color:#000>$i</span>.out<span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>done</span>
</code></pre></div><p>Run BLAST2 for all <em>.fasa1/</em>.fasta2 file pairs in the order specified by file names and write results into one file:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#204a87;font-weight:700>for</span> i in *.fasta1<span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>do</span> blast2 -p blastp -i <span style=color:#000>$i</span> -j <span style=color:#4e9a06>${</span><span style=color:#000>i</span><span style=color:#000;font-weight:700>/_*fasta1/_*fasta2</span><span style=color:#4e9a06>}</span> &gt;&gt; my_out_file<span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>done</span>
</code></pre></div><pre><code>This example uses two variables in a for loop. The content of the second variable gets specified in each loop by a replace function.
</code></pre><p>Runs BLAST2 in all-against-all mode and writes results into one file ('-F F' turns low-complexity filter off):</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#204a87;font-weight:700>for</span> i in *.fasta<span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>do</span> <span style=color:#204a87;font-weight:700>for</span> j in *.fasta<span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>do</span> blast2 -p blastp -F F -i <span style=color:#000>$i</span> -j <span style=color:#000>$j</span> &gt;&gt; my_out_file<span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>done</span><span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>done</span><span style=color:#000;font-weight:700>;</span>
</code></pre></div><h3 id=how-to-write-a-real-shell-script>How to write a real shell script</h3><ol><li><p>Create file which contains an interpreter as the first line:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#8f5902;font-style:italic>#!/bin/bash
</span></code></pre></div></li><li><p>Place shell commands in file below the interpreter line using a text editor.</p></li><li><p>Make file executable:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>chmod +x my_shell_script
</code></pre></div></li><li><p>Run shell script like this:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>./my_shell_script
</code></pre></div></li><li><p>Place it into your /rhome/<username>/bin directory</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>mkdir -p ~/bin
mv my_shell_script ~/bin/
</code></pre></div></li><li><p>Add the bin path to your shell permanently:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#204a87>echo</span> <span style=color:#4e9a06>&#39;export PATH=~/bin:$PATH&#39;</span> &gt;&gt; ~/.bashrc
<span style=color:#204a87>source</span> ~/.bashrc
</code></pre></div></li></ol><h2 id=simple-one-liner-perl-scripts>Simple One-Liner Perl Scripts</h2><p><em>Small collection of useful one-liners:</em></p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-perl data-lang=perl><span style=color:#000>perl</span> <span style=color:#ce5c00;font-weight:700>-</span><span style=color:#000>p</span> <span style=color:#ce5c00;font-weight:700>-</span><span style=color:#000>i</span> <span style=color:#ce5c00;font-weight:700>-</span><span style=color:#000>w</span> <span style=color:#ce5c00;font-weight:700>-</span><span style=color:#000>e</span> <span style=color:#4e9a06>&#39;s/pattern1/pattern2/g&#39;</span> <span style=color:#000>my_input_file</span>
            <span style=color:#8f5902;font-style:italic># Replaces a pattern in a file by a another pattern using regular expressions.</span>
            <span style=color:#8f5902;font-style:italic># $1 or \1: back-references to pattern placed in parentheses</span>
            <span style=color:#8f5902;font-style:italic># -p: lets perl know to write program</span>
            <span style=color:#8f5902;font-style:italic># -i.bak: creates backup file *.bak, only -i doesn&#39;t</span>
            <span style=color:#8f5902;font-style:italic># -w: turns on warnings</span>
            <span style=color:#8f5902;font-style:italic># -e: executable code follows</span>
</code></pre></div><p><em>Parse lines based on patterns:</em></p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-perl data-lang=perl><span style=color:#000>perl</span> <span style=color:#ce5c00;font-weight:700>-</span><span style=color:#204a87;font-weight:700>ne</span> <span style=color:#4e9a06>&#39;print if (/my_pattern1/ ? ($c=1) : (--$c &gt; 0)); print if (/my_pattern2/ ? ($d = 1) : (--$d &gt; 0))&#39;</span> <span style=color:#000>my_infile</span> <span style=color:#ce5c00;font-weight:700>&gt;</span> <span style=color:#000>my_outfile</span>
            <span style=color:#8f5902;font-style:italic># Parses lines that contain pattern1 and pattern2.</span>
            <span style=color:#8f5902;font-style:italic># The following lines after the pattern can be specified in &#39;$c=1&#39; and &#39;$d=1&#39;.</span>
            <span style=color:#8f5902;font-style:italic># For logical OR use this syntax: &#39;/(pattern1|pattern2)/&#39;.</span>
</code></pre></div><h2 id=remote-copy-wget-scp-ncftp>Remote Copy: wget, scp, ncftp</h2><h3 id=wget>Wget</h3><p>Use wget to download a file from the web:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>wget ftp://ftp.ncbi.nih.... <span style=color:#8f5902;font-style:italic># file download from www; add option &#39;-r&#39; to download entire directories</span>
</code></pre></div><h3 id=scp>SCP</h3><p>Use scp to copy files between machines (ie. laptop to server):</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>scp <span style=color:#204a87>source</span> target <span style=color:#8f5902;font-style:italic># Use form &#39;userid@machine_name&#39; if your local and remote user ids are different.</span>
                  <span style=color:#8f5902;font-style:italic># If they are the same you can use only &#39;machine_name&#39;.</span>
</code></pre></div><p>Here are more scp examples:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>scp user@remote_host:file.name . <span style=color:#8f5902;font-style:italic># Copies file from server to local machine (type from local</span>
                                 <span style=color:#8f5902;font-style:italic># machine prompt). The &#39;.&#39; copies to pwd, you can specify                                              # here any directory, use wildcards to copy many files.</span>

scp file.name user@remote_host:~/dir/newfile.name
                                                                       <span style=color:#8f5902;font-style:italic># Copies file from local machine to server.</span>

scp -r user@remote_host:directory/ ~/dir
                                 <span style=color:#8f5902;font-style:italic># Copies entire directory from server to local machine.</span>
</code></pre></div><h3 id=nice-ftp>Nice FTP</h3><p>From the linux command line run ncftp and use it to get files:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ncftp
ncftp&gt; open ftp.ncbi.nih.gov
ncftp&gt; <span style=color:#204a87>cd</span> /blast/executables
ncftp&gt; get blast.linux.tar.Z <span style=color:#ce5c00;font-weight:700>(</span>skip extension: @<span style=color:#ce5c00;font-weight:700>)</span>
ncftp&gt; bye
</code></pre></div><h2 id=archiving-and-compressing>Archiving and Compressing</h2><h3 id=creating-archives>Creating Archives</h3><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>tar -cvf my_file.tar mydir/    <span style=color:#8f5902;font-style:italic># Builds tar archive of files or directories. For directories, execute command in parent directory. Don&#39;t use absolute path.    </span>
tar -czvf my_file.tgz mydir/   <span style=color:#8f5902;font-style:italic># Builds tar archive with compression of files or directories. For</span>
                               <span style=color:#8f5902;font-style:italic># directories, execute command in parent directory. Don&#39;t use absolute path.</span>
zip -r mydir.zip mydir/        <span style=color:#8f5902;font-style:italic># Command to archive a directory (here mydir) with zip.</span>
tar -jcvf mydir.tar.bz2 mydir/ <span style=color:#8f5902;font-style:italic># Creates *.tar.bz2 archive</span>
</code></pre></div><h3 id=viewing-archives>Viewing Archives</h3><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>tar -tvf my_file.tar
tar -tzvf my_file.tgz
</code></pre></div><h3 id=extracting-archives>Extracting Archives</h3><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>tar -xvf my_file.tar
tar -xzvf my_file.tgz
gunzip my_file.tar.gz <span style=color:#8f5902;font-style:italic># or unzip my_file.zip, uncompress my_file.Z,</span>
                      <span style=color:#8f5902;font-style:italic># or bunzip2 for file.tar.bz2</span>
find -name <span style=color:#4e9a06>&#39;*.zip&#39;</span> <span style=color:#000;font-weight:700>|</span> xargs -n <span style=color:#0000cf;font-weight:700>1</span> unzip <span style=color:#8f5902;font-style:italic># this command usually works for unzipping</span>
                      <span style=color:#8f5902;font-style:italic># many files that were compressed under Windows</span>
tar -jxvf mydir.tar.bz2 <span style=color:#8f5902;font-style:italic># Extracts *.tar.bz2 archive</span>
</code></pre></div><p>Try also:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>tar zxf blast.linux.tar.Z
tar xvzf file.tgz
</code></pre></div><p>Important options:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>f: use archive file
p: preserve permissions
v: list files processed
x: exclude files listed in FILE
z: filter the archive through gzip
</code></pre></div><h2 id=simple-installs>Simple Installs</h2><h3 id=systems-wide-installations>Systems-wide installations</h3><h3 id=applications-in-user-accounts>Applications in user accounts</h3><h3 id=installation-of-rpms>Installation of RPMs</h3><h2 id=environment-variables>Environment Variables</h2><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>xhost user@host                <span style=color:#8f5902;font-style:italic># adds X permissions for user on server.</span>
<span style=color:#204a87>echo</span> <span style=color:#000>$DISPLAY</span>                  <span style=color:#8f5902;font-style:italic># shows current display settings</span>
<span style=color:#204a87>export</span> <span style=color:#000>DISPLAY</span><span style=color:#ce5c00;font-weight:700>=</span>&lt;local_IP&gt;:0    <span style=color:#8f5902;font-style:italic># change environment variable</span>
unsetenv DISPLAY               <span style=color:#8f5902;font-style:italic># removes display variable</span>
env                            <span style=color:#8f5902;font-style:italic># prints all environment variables</span>
</code></pre></div><p>List of directories that the shell will search when you type a command:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#204a87>echo</span> <span style=color:#000>$PATH</span>
</code></pre></div><p>You can edit your default DISPLAY setting for your account by adding it to file .bash_profile</p><h2 id=exercises>Exercises</h2><h3 id=exercise-1>Exercise 1</h3><ol><li><p>Download proteome of Halobacterium spec. with wget and look at it:</p><pre><code>module load ncbi-blast/2.2.26 # Loads legacy blastall
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/genbank/archaea/Halobacterium_salinarum/representative/GCA_000069025.1_ASM6902v1/GCA_000069025.1_ASM6902v1_protein.faa.gz
gunzip GCA_000069025.1_ASM6902v1_protein.faa.gz
mv GCA_000069025.1_ASM6902v1_protein.faa AE004437.faa
less AE004437.faa  # press q to quit
</code></pre></li><li><p>Simple Analysis:</p><p>a. How many predicted proteins are there?</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>grep <span style=color:#4e9a06>&#39;^&gt;&#39;</span> AE004437.faa --count
</code></pre></div><p>b. How many proteins contain the pattern &ldquo;WxHxxH&rdquo; or &ldquo;WxHxxHH&rdquo;?</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>egrep <span style=color:#4e9a06>&#39;W.H..H{1,2}&#39;</span> AE004437.faa --count
</code></pre></div><p>c. Use the find function (/) in &lsquo;less&rsquo; to fish out the protein IDs containing the pattern or more elegantly do it with awk:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>awk --posix -v <span style=color:#000>RS</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#39;&gt;&#39;</span> <span style=color:#4e9a06>&#39;/W.H..(H){1,2}/ { print &#34;&gt;&#34; $0;}&#39;</span> AE004437.faa <span style=color:#000;font-weight:700>|</span> less <span style=color:#8f5902;font-style:italic># press q to quit</span>
</code></pre></div></li><li><p>Create a BLASTable database with formatdb:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ls <span style=color:#8f5902;font-style:italic># before</span>
formatdb -i AE004437.faa -p T -o T
ls <span style=color:#8f5902;font-style:italic># after</span>
<span style=color:#4e9a06>&#39;-p F&#39;</span> <span style=color:#204a87;font-weight:700>for</span> nucleotide and <span style=color:#4e9a06>&#39;-p T&#39;</span> <span style=color:#204a87;font-weight:700>for</span> protein database<span style=color:#000;font-weight:700>;</span> <span style=color:#4e9a06>&#39;-o T&#39;</span> parse SeqId and create indexes
</code></pre></div></li><li><p>Generate myseq.fasta</p><p>a. Generate list of sequence IDs for the above pattern match result (i.e. retrieve my_IDs from step 2c). Alternatively, download the pre-generated file with wget.</p><p>b. Retrieve the corresponding sequences for these IDs with the fastacmd command from the blastable database:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>wget https://cluster.hpcc.ucr.edu/~tgirke/Documents/UNIX/my_IDs
fastacmd -d AE004437.faa -i my_IDs &gt; myseq.fasta
less myseq.fasta <span style=color:#8f5902;font-style:italic># press q to quit</span>
</code></pre></div></li><li><p>(Optional) Looking at several different patterns:</p><p>a. Generate several lists of sequence IDs from various pattern match results (i.e. retrieve a.my_ids, b.my_ids, and c.my_ids from step 2c).</p><p>b. Retrieve the sequences in one step using the fastacmd in a for-loop:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#204a87;font-weight:700>for</span> i in *.my_ids<span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>do</span> fastacmd -d AE004437.faa -i <span style=color:#000>$i</span> &gt; <span style=color:#000>$i</span>.fasta<span style=color:#000;font-weight:700>;</span> <span style=color:#204a87;font-weight:700>done</span>
</code></pre></div></li><li><p>Run blastall with a few proteins in myseq.fasta against your newly created Halobacterium proteome database.</p><p>Create first a complete blast output file including alignments. In a second step use the &rsquo;m -8' option to obtain a tabular output (i.e. tab separated values):</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>blastall -p blastp -i myseq.fasta -d AE004437.faa -o blastp.out -e 1e-6 -v <span style=color:#0000cf;font-weight:700>10</span> -b <span style=color:#0000cf;font-weight:700>10</span>
blastall -p blastp -i myseq.fasta -d AE004437.faa -m <span style=color:#0000cf;font-weight:700>8</span> -e 1e-6 &gt; blastp.tab
less blastp.out <span style=color:#8f5902;font-style:italic># press q to quit</span>
less -S blastp.tab <span style=color:#8f5902;font-style:italic># -S disables line wrapping, press q to quit</span>
</code></pre></div><p>The filed descriptions of the Blast tabular output (from the &ldquo;-m 8&rdquo; option) are available here:</p><pre><code>1  Query (The query sequence id)
2  Subject (The matching subject sequence id)
3  % id
4  alignment length
5  mismatches
6  gap openings
7  q.start
8  q.end
9  s.start
10 s.end
11 e-value
12 bit score
</code></pre></li></ol><p>Is your blastp.out file equivalent to this one?</p><ol><li><p>Parse blastall output into Excel spread sheet</p><p>a. Using biocore parser</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>blastParse -i blastp.out -o blast.xls -c <span style=color:#0000cf;font-weight:700>5</span>
</code></pre></div><p>b. Using BioPerl parser</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>bioblastParse.pl blastp.out &gt; blastparse.txt     
</code></pre></div></li></ol><h3 id=exercise-2>Exercise 2</h3><p>Split sample fasta batch file with csplit (use sequence file myseq.fasta from Exercise 1).</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>csplit -z myseq.fasta <span style=color:#4e9a06>&#39;/&gt;/&#39;</span> <span style=color:#4e9a06>&#39;{*}&#39;</span>
</code></pre></div><p>Delete some of the files generated by csplit
Concatenate single fasta files from (step 1) into to one file with cat (e.g. <code>cat file1 file2 file3 > bigfile</code>).
BLAST two related sequences, retrieve the result in tabular format and use <code>comm</code> to identify common hit IDs in the two tables.</p><h3 id=exercise-3>Exercise 3</h3><p>Run HMMPFAM search with proteins from Exercise 1 against Pfam database (will take ~3 minutes)</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>hmmscan -E 0.1 --acc /srv/projects/db/pfam/2011-12-09-Pfam26.0/Pfam-A.hmm myseq.fasta &gt; output.pfam
</code></pre></div><p>Easier to parse/process tabular output</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>hmmscan -E 0.1 --acc --tblout output.pfam /srv/projects/db/pfam/2011-12-09-Pfam26.0/Pfam-A.hmm myseq.fasta <span style=color:#8f5902;font-style:italic># also try --domtblout</span>
</code></pre></div><p>Which query got the most hits? How many hits were found that query?</p><h3 id=exercise-4>Exercise 4</h3><p>Create multiple alignment with ClustalW (e.g. use sequences with &lsquo;W.H..HH&rsquo; pattern)</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>clustalw myseq.fasta
mv myseq.aln myalign.aln
</code></pre></div><h3 id=exercise-5>Exercise 5</h3><p>Reformat alignment into PHYILIP format using &lsquo;seqret&rsquo; from EMBOSS</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>seqret clustal::myalign.aln phylip::myalign.phylip
</code></pre></div><h3 id=exercise-6>Exercise 6</h3><p>Create neighbor-joining tree with PHYLIP</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>cp myalign.phylip infile
protdist     <span style=color:#8f5902;font-style:italic># creates distance matrix (you may need to press &#39;R&#39; and then &#39;Y&#39;)</span>
cp outfile infile
neighbor     <span style=color:#8f5902;font-style:italic># use default settings (press &#39;Y&#39;)</span>
cp outtree intree
</code></pre></div><p>retree # displays tree and can use midpoint method for defining root of tree, my typical command sequence is: &lsquo;N&rsquo; (until you see PHYLIP) &lsquo;Y&rsquo; &lsquo;M&rsquo; &lsquo;W&rsquo; &lsquo;R&rsquo; &lsquo;R&rsquo; &lsquo;X&rsquo;</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>cp outtree tree.dnd
</code></pre></div><p>View your tree in TreeBrowse or open it in TreeView</p></div><div class=td-content style=page-break-before:always><h1 id=pg-2fd30c11f419f2288892e85df4de180b>4.9 - Streams</h1><h2 id=streams>Streams</h2><p>On the command line, or terminal, there are three very important lanes where information can be sent, we call these <code>streams</code>.
A single command can take information in from <code>STDIN</code> and then send information out on both <code>STDOUT</code> and <code>STDERR</code> simultaneously.</p><h3 id=stdin>STDIN</h3><p>For example, we can send the contents of a file as a <code>STDIN</code> steam to the <code>wc</code> command in order to count the lines:</p><pre><code>wc -l &lt; file.txt
</code></pre><h3 id=stdout>STDOUT</h3><p>The <code>STDOUT</code> steam is probably the most often used, since this is how commands send information to the screen.
However, if we do not want the information printed to the screen, we can send it into a file for later review:</p><pre><code>ls &gt; output.txt    # Overwrite contents in output file with `ls` results
</code></pre><p>You can also append to the same file, if more information is to be saved:</p><pre><code>ls &gt;&gt; output.txt     # Append results from `ls` to the bottom of the file
</code></pre><h3 id=stderr>STDERR</h3><p>The error stream is very useful to separate error messages (or warnings) from real output (your results).
Since there is no <code>-e</code> flag for the <code>ls</code> command this will generate an error. We can then store this error in a by redirecting the error stream with <code>2></code>.</p><pre><code>ls -e 2&gt; errors.txt
</code></pre><h3 id=tips>Tips</h3><h4 id=combined-streams>Combined streams</h4><p>If you want to combined your <code>STDOUT</code> with your <code>STDERR</code> stream and store it into a file, you can do this with <code>&></code>, like so:</p><pre><code>command &amp;&gt; output_and_errors.txt
</code></pre><h4 id=trash-streams>Trash Streams</h4><p>If you want to ignore all information from <code>STDOUT</code> and <code>STDERR</code> you can send both of these streams to the trash (<code>/dev/null</code>):</p><pre><code>command &amp;&gt; /dev/null
</code></pre><p>This can be useful when you are only interested in the resulting file that your command will create.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-c8656daa5ea9b4db1c7a307969154d39>4.10 - Text Editors</h1><h2 id=text-viewing>Text Viewing</h2><p>Here are a few commands that are used to just display the text within a file:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>more &lt;FILENAME&gt;     <span style=color:#8f5902;font-style:italic># Views text, use space bar to browse, &#39;q&#39; to quit</span>
less &lt;FILENAME&gt;     <span style=color:#8f5902;font-style:italic># Also views text, uses arrow keys to browse, &#39;q&#39; to quit</span>
cat  &lt;FILENAME&gt;     <span style=color:#8f5902;font-style:italic># Concatenates files and prints content to screen</span>
</code></pre></div><h2 id=text-editors>Text Editors</h2><ul><li><strong>Nano</strong><ul><li>A simple terminal-based editor.</li></ul></li><li><strong>Neovim</strong><ul><li>Non-graphical (terminal-based) editor. Neovim is an improved version of vim.</li></ul></li><li><strong>Vim</strong> <strong>Gvim</strong><ul><li>Non-graphical (<code>vim</code>) or window-based editor (<code>gvim</code>). Vim is the improved version of vi.</li></ul></li><li><strong>Emacs</strong><ul><li>Non-graphical or window-based editor.</li></ul></li><li><strong>Atom</strong><ul><li>Window-based editor that runs on your local machine.</li></ul></li></ul><h2 id=nano>Nano</h2><p>The <code>nano</code> editor is the simplest to use and can be good for beginners:</p><pre><code>nano &lt;FILENAME&gt;     # Open file if it exists, or create it
</code></pre><p>Navigation in <code>nano</code> uses the arrow keys, and all other commands are noted at the bottom of the screen.
The <code>CTRL</code> key is used in combination with other keys to execute commands in <code>nano</code>.</p><p>For example, at the bottom of the <code>nano</code> screen it is noted that <code>^X</code> is used to exit.
This means you will need to hold the <code>CTRL</code> key and then press <code>x</code> in order to quit.
After that, just follow the on screen prompts at the bottom.</p><p>For more <code>nano</code> commands, please visit <a href=https://www.nano-editor.org/dist/latest/cheatsheet.html>Overview of nano shortcuts</a>.</p><h2 id=neovim--vim--gvim--vi>Neovim / Vim / GVim / VI</h2><p>All of these editors follow the same principals.</p><pre><code>nvim &lt;FILENAME&gt;     # Open file if it exists, or create it
vim &lt;FILENAME&gt;      # Open file if it exists, or create it
gvim &lt;FILENAME&gt;     # Open file if it exists, or create it (must have XForwarding or VNC)
vi &lt;FILENAME&gt;       # Open file if it exists, or create it
</code></pre><p>For more information please visit <a href=manuals_linux-basics_vim>Vim Manual</a>.</p><h2 id=emacs>Emacs</h2><p>Navigation in <code>emacs</code> also uses the arrow keys. It is similar to <code>nano</code>, in that, <code>CTRL</code> is combined with other keys to execute commands.</p><p>For example, to open a file, simply run the command with a file name:</p><pre><code>emacs &lt;FILENAME&gt;     # Open file if it exists, or create it
</code></pre><p>Then, after you have made some changes, exit by holding the <code>CTRL</code> key and then pressing <code>c</code>, releasing and then holding the <code>CTRL</code> key once more and pressing <code>c</code> again.
After that, just follow the on screen prompts at the bottom.</p><p>For more commands in <code>emacs</code> please visit <a href=https://www.gnu.org/software/emacs/refcards/pdf/refcard.pdf>GNU Emacs Reference Card</a></p><h2 id=atom>Atom</h2><h3 id=install>Install</h3><p>This editor should be installed on your local machine (ie. workstation, laptop).
Please visit <a href=https://atom.io/>Atom</a> for software download.</p><h3 id=remote-atom>Remote Atom</h3><p>After you have <code>atom</code> installed, you need to install the <code>Remote Atom</code> plugin.
Click on <code>edit</code>, then <code>preferences</code>, then look for the <code>install</code> item on the left side menu.
You should then be able to type <code>remote-atom</code> in the search field, find it and install it.
After installation, <code>atom</code> should restart.</p><h3 id=start-server>Start Server</h3><p>Once you have <code>remote-atom</code> installed, click <code>Packages</code> in the top menu, then <code>Remote Atom</code>, and then click <code>Start Server</code>.
<code>Atom</code> may need to be restarted in order for you to see these new menu items.</p><h3 id=cluster>Cluster</h3><p>SSH into cluster using a socket (replace <code>&lt;USERNAME></code> with your real username on the cluster):</p><pre><code>ssh -R /rhome/&lt;USERNAME&gt;/.rmate.socket:localhost:52698 cluster.hpcc.ucr.edu
</code></pre><blockquote><p>Note: Do not use a remote PORT, you must use a SOCKET FILE as shown above. There are security issues otherwise.</p></blockquote><p>After you have logged into the cluster load <code>rmate</code> (alias is optional):</p><pre><code>module load rmate
alias ratom=rmate
</code></pre><p>You can add this into your <code>~/.bashrc</code> for convenience.</p><p>Then you should be able to open a file on the cluster and have it appear on your local machine:</p><pre><code>rmate &lt;FILENAME&gt;
</code></pre><p>Once you have finished all your editing and close <code>atom</code>, be sure to delete the socket file from the cluster:</p><pre><code>rm -f /rhome/&lt;USERNAME&gt;/.rmate.socket'
</code></pre><p>For more information regarding <code>remote-atom</code>, please visit <a href=https://atom.io/packages/remote-atom>Remote-Atom</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-5214e2825df5a868ca3a6d2886c4ad5f>4.11 - Variables</h1><h2 id=variables>Variables</h2><p>The HPCC cluster uses bash as the default shell environment. Within this environment, variables can be set and reused.</p><p>For example:</p><pre><code>MYVAR=’Something’
export MYVAR=’Something’
echo $MYVAR
</code></pre><h3 id=default-variables>Default Variables</h3><p>Some softwares utilize this feature and require that specific environment variables be set.
For example, every time you login, the following variables are set by default:</p><pre><code>echo $HOME               #Contains your home path
echo $USER               #Contains your username
echo $PATH               #Contains paths of executables
echo $LD_LIBRARY_PATH    #Contains paths of library dependencies
</code></pre><h3 id=finding-variables>Finding Variables</h3><p>To see a list of all variables currently set in your shell, use the <code>env</code> command.
You can also <code>grep</code> through this list to find variables, like so:</p><pre><code>env | grep -i home
</code></pre><p>Or if you are in a <code>Slurm</code> job, you can find all related <code>Slurm</code> variables:</p><pre><code>env | grep -i slurm
</code></pre><h3 id=setting-variables>Setting variables</h3><p>Try to choose unique names when setting variables.
It is best to not overwrite a variable that is already set, unless on purpose.</p><p>To set a variable in your current shell, you can do so like this:</p><pre><code>MYVAR='Something Important'
</code></pre><blockquote><p>Notice that there is no spaces around the <code>=</code> sign.</p></blockquote><p>If you would like to set a variable that is carried over to all other commands or sub-shells, then it must be <code>exported</code>:</p><pre><code>export MYVAR='Something Important'
</code></pre></div><div class=td-content style=page-break-before:always><h1 id=pg-6c33cd51ee4d79b09958bb3cbefd007d>5 - Reference</h1><div class=lead>Low level reference docs for your project.</div><div class="pageinfo pageinfo-primary"><p>This is a placeholder page that shows you how to use this template site.</p></div><p>If your project has an API, configuration, or other reference - anything that users need to look up that’s at an even lower level than a single task - put (or link to it) here. You can serve and link to generated reference docs created using Doxygen,
Javadoc, or other doc generation tools by putting them in your <code>static/</code> directory. Find out more in <a href=https://docsy.dev/docs/adding-content/content/#adding-static-content>Adding static content</a>. For OpenAPI reference, Docsy also provides a <a href=https://www.docsy.dev/docs/adding-content/shortcodes/#swaggerui>Swagger UI layout and shortcode</a> that renders <a href=https://swagger.io/tools/swagger-ui/>Swagger UI</a> using any OpenAPI YAML or JSON file as source.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-0ced68162fb683117a1934936d54c1ac>5.1 - Parameter Reference</h1><div class=lead>A short lead description about this content page. It can be <strong>bold</strong> or <em>italic</em> and can be split over multiple paragraphs.</div><div class="pageinfo pageinfo-primary"><p>This is a placeholder page. Replace it with your own content.</p></div><p>Text can be <strong>bold</strong>, <em>italic</em>, or <del>strikethrough</del>. <a href=https://gohugo.io>Links</a> should be blue with no underlines (unless hovered over).</p><p>There should be whitespace between paragraphs. Vape migas chillwave sriracha poutine try-hard distillery. Tattooed shabby chic small batch, pabst art party heirloom letterpress air plant pop-up. Sustainable chia skateboard art party banjo cardigan normcore affogato vexillologist quinoa meggings man bun master cleanse shoreditch readymade. Yuccie prism four dollar toast tbh cardigan iPhone, tumblr listicle live-edge VHS. Pug lyft normcore hot chicken biodiesel, actually keffiyeh thundercats photo booth pour-over twee fam food truck microdosing banh mi. Vice activated charcoal raclette unicorn live-edge post-ironic. Heirloom vexillologist coloring book, beard deep v letterpress echo park humblebrag tilde.</p><p>90&rsquo;s four loko seitan photo booth gochujang freegan tumeric listicle fam ugh humblebrag. Bespoke leggings gastropub, biodiesel brunch pug fashion axe meh swag art party neutra deep v chia. Enamel pin fanny pack knausgaard tofu, artisan cronut hammock meditation occupy master cleanse chartreuse lumbersexual. Kombucha kogi viral truffaut synth distillery single-origin coffee ugh slow-carb marfa selfies. Pitchfork schlitz semiotics fanny pack, ugh artisan vegan vaporware hexagon. Polaroid fixie post-ironic venmo wolf ramps <strong>kale chips</strong>.</p><blockquote><p>There should be no margin above this first sentence.</p><p>Blockquotes should be a lighter gray with a border along the left side in the secondary color.</p><p>There should be no margin below this final sentence.</p></blockquote><h2 id=first-header-2>First Header 2</h2><p>This is a normal paragraph following a header. Knausgaard kale chips snackwave microdosing cronut copper mug swag synth bitters letterpress glossier <strong>craft beer</strong>. Mumblecore bushwick authentic gochujang vegan chambray meditation jean shorts irony. Viral farm-to-table kale chips, pork belly palo santo distillery activated charcoal aesthetic jianbing air plant woke lomo VHS organic. Tattooed locavore succulents heirloom, small batch sriracha echo park DIY af. Shaman you probably haven&rsquo;t heard of them copper mug, crucifix green juice vape <em>single-origin coffee</em> brunch actually. Mustache etsy vexillologist raclette authentic fam. Tousled beard humblebrag asymmetrical. I love turkey, I love my job, I love my friends, I love Chardonnay!</p><p>Deae legum paulatimque terra, non vos mutata tacet: dic. Vocant docuique me plumas fila quin afuerunt copia haec o neque.</p><p>On big screens, paragraphs and headings should not take up the full container width, but we want tables, code blocks and similar to take the full width.</p><p>Scenester tumeric pickled, authentic crucifix post-ironic fam freegan VHS pork belly 8-bit yuccie PBR&B. <strong>I love this life we live in</strong>.</p><h2 id=second-header-2>Second Header 2</h2><blockquote><p>This is a blockquote following a header. Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.</p></blockquote><h3 id=header-3>Header 3</h3><pre><code>This is a code block following a header.
</code></pre><p>Next level leggings before they sold out, PBR&B church-key shaman echo park. Kale chips occupy godard whatever pop-up freegan pork belly selfies. Gastropub Belinda subway tile woke post-ironic seitan. Shabby chic man bun semiotics vape, chia messenger bag plaid cardigan.</p><h4 id=header-4>Header 4</h4><ul><li>This is an unordered list following a header.</li><li>This is an unordered list following a header.</li><li>This is an unordered list following a header.</li></ul><h5 id=header-5>Header 5</h5><ol><li>This is an ordered list following a header.</li><li>This is an ordered list following a header.</li><li>This is an ordered list following a header.</li></ol><h6 id=header-6>Header 6</h6><table><thead><tr><th>What</th><th>Follows</th></tr></thead><tbody><tr><td>A table</td><td>A header</td></tr><tr><td>A table</td><td>A header</td></tr><tr><td>A table</td><td>A header</td></tr></tbody></table><hr><p>There&rsquo;s a horizontal rule above and below this.</p><hr><p>Here is an unordered list:</p><ul><li>Liverpool F.C.</li><li>Chelsea F.C.</li><li>Manchester United F.C.</li></ul><p>And an ordered list:</p><ol><li>Michael Brecker</li><li>Seamus Blake</li><li>Branford Marsalis</li></ol><p>And an unordered task list:</p><ul><li><input checked disabled type=checkbox> Create a Hugo theme</li><li><input checked disabled type=checkbox> Add task lists to it</li><li><input disabled type=checkbox> Take a vacation</li></ul><p>And a &ldquo;mixed&rdquo; task list:</p><ul><li><input disabled type=checkbox> Pack bags</li><li>?</li><li><input disabled type=checkbox> Travel!</li></ul><p>And a nested list:</p><ul><li>Jackson 5<ul><li>Michael</li><li>Tito</li><li>Jackie</li><li>Marlon</li><li>Jermaine</li></ul></li><li>TMNT<ul><li>Leonardo</li><li>Michelangelo</li><li>Donatello</li><li>Raphael</li></ul></li></ul><p>Definition lists can be used with Markdown syntax. Definition headers are bold.</p><dl><dt>Name</dt><dd>Godzilla</dd><dt>Born</dt><dd>1952</dd><dt>Birthplace</dt><dd>Japan</dd><dt>Color</dt><dd>Green</dd></dl><hr><p>Tables should have bold headings and alternating shaded rows.</p><table><thead><tr><th>Artist</th><th>Album</th><th>Year</th></tr></thead><tbody><tr><td>Michael Jackson</td><td>Thriller</td><td>1982</td></tr><tr><td>Prince</td><td>Purple Rain</td><td>1984</td></tr><tr><td>Beastie Boys</td><td>License to Ill</td><td>1986</td></tr></tbody></table><p>If a table is too wide, it should scroll horizontally.</p><table><thead><tr><th>Artist</th><th>Album</th><th>Year</th><th>Label</th><th>Awards</th><th>Songs</th></tr></thead><tbody><tr><td>Michael Jackson</td><td>Thriller</td><td>1982</td><td>Epic Records</td><td>Grammy Award for Album of the Year, American Music Award for Favorite Pop/Rock Album, American Music Award for Favorite Soul/R&B Album, Brit Award for Best Selling Album, Grammy Award for Best Engineered Album, Non-Classical</td><td>Wanna Be Startin' Somethin', Baby Be Mine, The Girl Is Mine, Thriller, Beat It, Billie Jean, Human Nature, P.Y.T. (Pretty Young Thing), The Lady in My Life</td></tr><tr><td>Prince</td><td>Purple Rain</td><td>1984</td><td>Warner Brothers Records</td><td>Grammy Award for Best Score Soundtrack for Visual Media, American Music Award for Favorite Pop/Rock Album, American Music Award for Favorite Soul/R&B Album, Brit Award for Best Soundtrack/Cast Recording, Grammy Award for Best Rock Performance by a Duo or Group with Vocal</td><td>Let&rsquo;s Go Crazy, Take Me With U, The Beautiful Ones, Computer Blue, Darling Nikki, When Doves Cry, I Would Die 4 U, Baby I&rsquo;m a Star, Purple Rain</td></tr><tr><td>Beastie Boys</td><td>License to Ill</td><td>1986</td><td>Mercury Records</td><td>noawardsbutthistablecelliswide</td><td>Rhymin & Stealin, The New Style, She&rsquo;s Crafty, Posse in Effect, Slow Ride, Girls, (You Gotta) Fight for Your Right, No Sleep Till Brooklyn, Paul Revere, Hold It Now, Hit It, Brass Monkey, Slow and Low, Time to Get Ill</td></tr></tbody></table><hr><p>Code snippets like <code>var foo = "bar";</code> can be shown inline.</p><p>Also, <code>this should vertically align</code> <del><code>with this</code></del> <del>and this</del>.</p><p>Code can also be shown in a block element.</p><pre><code>foo := &quot;bar&quot;;
bar := &quot;foo&quot;;
</code></pre><p>Code can also use syntax highlighting.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#204a87;font-weight:700>func</span> <span style=color:#000>main</span><span style=color:#000;font-weight:700>()</span> <span style=color:#000;font-weight:700>{</span>
  <span style=color:#000>input</span> <span style=color:#ce5c00;font-weight:700>:=</span> <span style=color:#4e9a06>`var foo = &#34;bar&#34;;`</span>

  <span style=color:#000>lexer</span> <span style=color:#ce5c00;font-weight:700>:=</span> <span style=color:#000>lexers</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>Get</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#34;javascript&#34;</span><span style=color:#000;font-weight:700>)</span>
  <span style=color:#000>iterator</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>_</span> <span style=color:#ce5c00;font-weight:700>:=</span> <span style=color:#000>lexer</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>Tokenise</span><span style=color:#000;font-weight:700>(</span><span style=color:#204a87;font-weight:700>nil</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>input</span><span style=color:#000;font-weight:700>)</span>
  <span style=color:#000>style</span> <span style=color:#ce5c00;font-weight:700>:=</span> <span style=color:#000>styles</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>Get</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#34;github&#34;</span><span style=color:#000;font-weight:700>)</span>
  <span style=color:#000>formatter</span> <span style=color:#ce5c00;font-weight:700>:=</span> <span style=color:#000>html</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>New</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>html</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>WithLineNumbers</span><span style=color:#000;font-weight:700>())</span>

  <span style=color:#204a87;font-weight:700>var</span> <span style=color:#000>buff</span> <span style=color:#000>bytes</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>Buffer</span>
  <span style=color:#000>formatter</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>Format</span><span style=color:#000;font-weight:700>(</span><span style=color:#ce5c00;font-weight:700>&amp;</span><span style=color:#000>buff</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>style</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>iterator</span><span style=color:#000;font-weight:700>)</span>

  <span style=color:#000>fmt</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>Println</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>buff</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>String</span><span style=color:#000;font-weight:700>())</span>
<span style=color:#000;font-weight:700>}</span>
</code></pre></div><pre><code>Long, single-line code blocks should not wrap. They should horizontally scroll if they are too long. This line should be long enough to demonstrate this.
</code></pre><p>Inline code inside table cells should still be distinguishable.</p><table><thead><tr><th>Language</th><th>Code</th></tr></thead><tbody><tr><td>Javascript</td><td><code>var foo = "bar";</code></td></tr><tr><td>Ruby</td><td><code>foo = "bar"{</code></td></tr></tbody></table><hr><p>Small images should be shown at their actual size.</p><p><img src=https://upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Picea_abies_shoot_with_buds%2C_Sogndal%2C_Norway.jpg/240px-Picea_abies_shoot_with_buds%2C_Sogndal%2C_Norway.jpg alt></p><p>Large images should always scale down and fit in the content container.</p><p><img src=https://upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Picea_abies_shoot_with_buds%2C_Sogndal%2C_Norway.jpg/1024px-Picea_abies_shoot_with_buds%2C_Sogndal%2C_Norway.jpg alt></p><p><em>The photo above of the Spruce Picea abies shoot with foliage buds: Bjørn Erik Pedersen, CC-BY-SA.</em></p><h2 id=components>Components</h2><h3 id=alerts>Alerts</h3><p><div class="alert alert-primary" role=alert>This is an alert.</div><div class="alert alert-primary" role=alert><h4 class=alert-heading>Note</h4>This is an alert with a title.</div><div class="alert alert-primary" role=alert><h4 class=alert-heading>Note</h4>This is an alert with a title and <strong>Markdown</strong>.</div><div class="alert alert-success" role=alert>This is a successful alert.</div><div class="alert alert-warning" role=alert>This is a warning.</div><div class="alert alert-warning" role=alert><h4 class=alert-heading>Warning</h4>This is a warning with a title.</div></p><h2 id=another-heading>Another Heading</h2></div></main></div></div><footer class="bg-dark py-5 row d-print-none"><div class="container-fluid mx-sm-5"><div class=row><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Immediate Email Support" aria-label="Immediate Email Support"><a class=text-white target=_blank rel="noopener noreferrer" href=support@hpcc.ucr.edu><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank rel="noopener noreferrer" href=https://twitter.com/UCR_HPCC><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank rel="noopener noreferrer" href=https://ucr-hpcc.slack.com/><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-6 col-sm-4 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title aria-label><a class=text-white target=_blank rel="noopener noreferrer" href><i></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title aria-label><a class=text-white target=_blank rel="noopener noreferrer" href><i></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title aria-label><a class=text-white target=_blank rel="noopener noreferrer" href><i></i></a></li></ul></div><div class="col-12 col-sm-4 text-center py-2 order-sm-2"><small class=text-white>&copy; 2021 The Docsy Authors All Rights Reserved</small>
<small class=ml-1><a href=https://policies.google.com/privacy target=_blank>Privacy Policy</a></small><p class=mt-2><a href=/about/>Abouts</a></p></div></div></div></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js integrity=sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49 crossorigin=anonymous></script><script src=https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js integrity=sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy crossorigin=anonymous></script><script src=/js/main.min.63db3e552bd0543be17ce4a79a18b744e9cb72256bec42b540e3ab0cd43722d0.js integrity="sha256-Y9s+VSvQVDvhfOSnmhi3ROnLciVr7EK1QOOrDNQ3ItA=" crossorigin=anonymous></script></body></html>