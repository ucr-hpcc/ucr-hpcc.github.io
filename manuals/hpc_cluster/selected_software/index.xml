<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>HPCC â€“ Selected Research Software Usage</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/selected_software/</link><description>Recent content in Selected Research Software Usage on HPCC</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://hpcc.ucr.edu/manuals/hpc_cluster/selected_software/index.xml" rel="self" type="application/rss+xml"/><item><title>Manuals: AlphaFold Usage on HPCC</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/selected_software/alphafold/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/selected_software/alphafold/</guid><description>
&lt;h2 id="alphafold3">AlphaFold3&lt;/h2>
&lt;h3 id="loading-the-module">Loading the module&lt;/h3>
&lt;p>You can load AlphaFold3 using the following commands:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load alphafold/3
singularity shell $ALPHAFOLD_SING
&lt;/code>&lt;/pre>
&lt;p>You can also run AlphaFold3 with a gpu. If you wish to use a GPU, &lt;a href="https://hpcc.ucr.edu/manuals/hpc_cluster/jobs/#gpu-jobs">log into an A100 gpu node&lt;/a> and then use the following commands:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load alphafold/3
singularity shell --nv $ALPHAFOLD_SING
&lt;/code>&lt;/pre>
&lt;h3 id="using-alphafold-databases">Using AlphaFold databases&lt;/h3>
&lt;p>A handful of databases are available at &lt;code>$ALPHAFOLD_DB&lt;/code> (available after loading the &lt;code>alphafold/3&lt;/code> module).&lt;/p>
&lt;p>An example command is as follows:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load alphafold/3
singularity shell --nv $ALPHAFOLD_SING
# Commands from here on are run inside of the Alphafold container
python3 /app/alphafold/run_alphafold.py \
--model_dir=$ALPHAFOLD_DB/model \
--db_dir=$ALPHAFOLD_DB \
--json_path=fold_input.json \
--output_dir=my_output_folder/
&lt;/code>&lt;/pre>
&lt;p>More information on using Alphafold3 can be found in the &lt;a href="https://github.com/google-deepmind/alphafold3">Alphafold3 GitHub repo&lt;/a>, including &lt;a href="https://github.com/google-deepmind/alphafold3/blob/main/docs/input.md">input documentation&lt;/a> and &lt;a href="https://github.com/google-deepmind/alphafold3/blob/main/docs/output.md">output documentation&lt;/a>.&lt;/p>
&lt;h3 id="processing-large-datasets">Processing Large Datasets&lt;/h3>
&lt;p>Sometimes the dataset cannot fit within the memory of a single GPU. In this case you&amp;rsquo;ll need to use Unified Memory (&amp;ldquo;Combined&amp;rdquo; GPU and System memory). This does come with a drop in performance, but might be the only way to get large datasets processed.&lt;/p>
&lt;p>To use Unified Memory, you can add these additional flags to the alphafold command:&lt;/p>
&lt;pre>&lt;code class="language-bash">--env XLA_PYTHON_CLIENT_PREALLOCATE=false \
--env TF_FORCE_UNIFIED_MEMORY=true \
--env XLA_CLIENT_MEM_FRACTION=3.2
&lt;/code>&lt;/pre>
&lt;p>For example:&lt;/p>
&lt;pre>&lt;code class="language-bash">python3 /app/alphafold/run_alphafold.py \
--model_dir=$ALPHAFOLD_DB/model \
--db_dir=$ALPHAFOLD_DB \
--json_path=fold_input.json \
--env XLA_PYTHON_CLIENT_PREALLOCATE=false \
--env TF_FORCE_UNIFIED_MEMORY=true \
--env XLA_CLIENT_MEM_FRACTION=3.2 \
--output_dir=my_output_folder/
&lt;/code>&lt;/pre>
&lt;h2 id="alphafold2">AlphaFold2&lt;/h2>
&lt;p>Description of AlphaFold2&lt;/p>
&lt;h3 id="loading-the-module-1">Loading the module&lt;/h3>
&lt;p>You can load AlphaFold2 using the following commands:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load alphafold/2
singularity shell $ALPHAFOLD_SING
&lt;/code>&lt;/pre>
&lt;p>You can also run AlphaFold2 with a gpu. If you wish to use a GPU, &lt;a href="https://hpcc.ucr.edu/manuals/hpc_cluster/jobs/#gpu-jobs">log into a P100 gpu node&lt;/a> and then use the following commands:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load alphafold/2
singularity shell --nv $ALPHAFOLD_SING
&lt;/code>&lt;/pre>
&lt;h3 id="using-alphafold-databases-1">Using Alphafold Databases&lt;/h3>
&lt;p>When running the alphafold command, you will be asked for certain databases. These databases can be found under the path $DATABASE_DIR/alphafold/&lt;version>. They can also be accessed using the &lt;code>$$ALPHAFOLD_DB&lt;/code> environment variable that is automatically set after loading the alphafold module.&lt;/p>
&lt;p>Here is an example of how to write your alphafold command using the monomer preset:&lt;/p>
&lt;pre>&lt;code class="language-bash">python3 /app/alphafold/run_alphafold.py \
--model_preset=monomer \
--db_preset=reduced_dbs \
--use_gpu_relax=True \
--data_dir=$ALPHAFOLD_DB \
--uniref90_database_path=$ALPHAFOLD_DB/uniref90/uniref90.fasta \
--mgnify_database_path=$ALPHAFOLD_DB/mgnify/mgy_clusters_2018_12.fa \
--template_mmcif_dir=$ALPHAFOLD_DB/pdb_mmcif/mmcif_files \
--max_template_date=2020-05-14 \
--obsolete_pdbs_path=$ALPHAFOLD_DB/pdb_mmcif/obsolete.dat \
--pdb_seqres_database_path=$ALPHAFOLD_DB/pdb_seqres/pdb_seqres \
--uniprot_database_path=$ALPHAFOLD_DB/uniprot/uniprot.fasta \
--small_bfd_database_path=$ALPHAFOLD_DB/small_bfd/bfd-first_non_consensus_sequences.fasta \
--pdb70_database_path=$ALPHAFOLD_DB/pdb70/pdb70 \
--fasta_paths=&amp;lt;path to fasta file here&amp;gt; \
--output_dir=&amp;lt;path to output directory&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>and an example using the multimer preset:&lt;/p>
&lt;pre>&lt;code class="language-bash">python3 /app/alphafold/run_alphafold.py \
--model_preset=multimer \
--db_preset=reduced_dbs \
--use_gpu_relax=True \
--data_dir=$ALPHAFOLD_DB \
--uniref90_database_path=$ALPHAFOLD_DB/uniref90/uniref90.fasta \
--mgnify_database_path=$ALPHAFOLD_DB/mgnify/mgy_clusters_2018_12.fa \
--template_mmcif_dir=$ALPHAFOLD_DB/pdb_mmcif/mmcif_files \
--max_template_date=2020-05-14 \
--obsolete_pdbs_path=$ALPHAFOLD_DB/pdb_mmcif/obsolete.dat \
--small_bfd_database_path=$ALPHAFOLD_DB/small_bfd/bfd-first_non_consensus_sequences.fasta \
--uniprot_database_path=$ALPHAFOLD_DB/uniprot/uniprot.fasta \
--pdb_seqres_database_path=$ALPHAFOLD_DB/pdb_seqres \
--fasta_paths=&amp;lt;path to fasta file&amp;gt; \
--output_dir=&amp;lt;path to output directory&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>Remember to fill in your fasta path and output dir if you wish to use these templates.&lt;/p>
&lt;p>Additionally, these are not the only two methods of running AlphaFold, and different modes might require different sets of arguments to be passed to &lt;code>alphafold.py&lt;/code>. For more details regarding what parameters are available, as well as more examples, please refer to the &lt;a href="https://github.com/deepmind/alphafold">Alphafold Github Repo&lt;/a>.&lt;/p></description></item><item><title>Manuals: Open OnDemand Usage</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/selected_software/ondemand/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/selected_software/ondemand/</guid><description>
&lt;h2 id="what-is-ondemand">What is OnDemand?&lt;/h2>
&lt;p>&lt;a href="https://openondemand.org/">Open OnDemand&lt;/a> allows users to access our cluster resources purely through a web browser. No additional client software is required. OnDemand gives users the ability to launch &amp;ldquo;Interactive Apps&amp;rdquo; such as Jupyter, RStudio, Matlab, Mathematica, and VSCode and connect to them through your browser.&lt;/p>
&lt;p>User&amp;rsquo;s also have the ability to upload/download files to/from the cluster, connect to the cluster via SSH, and create batch job templates.&lt;/p>
&lt;p>The sections below go over using OnDemand, as well as a couple pieces of popular software.&lt;/p>
&lt;h2 id="accessing-ondemand">Accessing OnDemand&lt;/h2>
&lt;p>Our OnDemand instance is located here: &lt;a href="https://ondemand.hpcc.ucr.edu/">https://ondemand.hpcc.ucr.edu/&lt;/a>. Log in with your &lt;strong>cluster&lt;/strong> login details and verify your login with Duo&amp;rsquo;s two-factor authentication.&lt;/p>
&lt;h2 id="jupyter-on-ondemand">Jupyter on OnDemand&lt;/h2>
&lt;p>After logging in, select &amp;ldquo;Jupyter Notebook&amp;rdquo; from the &amp;ldquo;Interactive Apps&amp;rdquo; tab from the menu bar.&lt;/p>
&lt;p>&lt;img src="../../../img/ondemand_jupyter1.png" alt="jupytermenu">&lt;/p>
&lt;p>From there, select the resources you need, time you want, partition to run the job on, and click &amp;ldquo;Launch&amp;rdquo;.&lt;/p>
&lt;p>&lt;img src="../../../img/ondemand_jupyter2.png" alt="jupyterparams">&lt;/p>
&lt;p>Your job will then be queued and eventually start running.&lt;/p>
&lt;p>&lt;img src="../../../img/ondemand_jupyter3.png" alt="jupyterqueue1">&lt;/p>
&lt;p>&lt;img src="../../../img/ondemand_jupyter4.png" alt="jupyterqueue2">&lt;/p>
&lt;p>Click &amp;ldquo;Connect to Jupyter&amp;rdquo; to open a new window containing Jupyter and start working!&lt;/p>
&lt;h3 id="using-remote-kernels-in-vscode">Using Remote Kernels in VSCode&lt;/h3>
&lt;p>VSCode allows you to run your code using a remote kernel. They provide some instructions &lt;a href="https://code.visualstudio.com/docs/datascience/jupyter-notebooks#_connect-to-a-remote-jupyter-server">here&lt;/a>. Using the OnDemand Jupyter requires a couple of additional extra steps.&lt;/p>
&lt;p>When you start a new Jupyter session on OnDemand, it should provide you with a command to set up an &lt;a href="https://hpcc.ucr.edu/manuals/hpc_cluster/jobs/#tunneling">SSH Tunnel&lt;/a>. This command should be run &lt;strong>on your local machine&lt;/strong> and &lt;em>not&lt;/em> on the cluster. Note that numbers and node name will likely be different!&lt;/p>
&lt;p>&lt;img src="../../../img/ondemand_jupyter5.png" alt="jupyterqueue2">&lt;/p>
&lt;p>At this point, you should be able to navigate to the provided URL along with the provided password to access your Jupyter session.&lt;/p>
&lt;p>To connect within VSCode you&amp;rsquo;ll need the &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter">Jupyter&lt;/a> extension installed. Within a &lt;code>.ipynb&lt;/code> file, find the &amp;ldquo;Select Kernel&amp;rdquo; option in the top right of your screen, select &amp;ldquo;Existing Jupyter Server&amp;rdquo;, and paste the URL provided by OnDemand. When asked for a password, use the one provided by OnDemand.&lt;/p>
&lt;p>From there you should be able to select the kernel that you would like to run.&lt;/p>
&lt;h2 id="rstudio-on-ondemand">RStudio on OnDemand&lt;/h2>
&lt;p>The process of launching RStudio is almost identical to that of starting Jupyter, but selecting &amp;ldquo;RStudio Server&amp;rdquo; instead of &amp;ldquo;Jupyter Notebook&amp;rdquo; from the menu.&lt;/p>
&lt;p>&lt;img src="../../../img/ondemand_rstudio1.png" alt="rstudiomenu">&lt;/p>
&lt;p>Please see the Jupyter section for selecting resources and opening the RStudio window.&lt;/p>
&lt;h2 id="desktop-session-on-ondemand">Desktop Session on OnDemand&lt;/h2>
&lt;p>A Desktop session is a Virtual Desktop that is running on the cluster. It will allow you to run programs that require GUIs without going through the steps of forwarding X11 sessions.&lt;/p>
&lt;p>&lt;img src="../../../img/ondemand_desktop2.png" alt="rstudiomenu">&lt;/p>
&lt;p>Similar to Jupyter and RStudio, a Desktop Session can be started by selecting &amp;ldquo;HPCC Desktop&amp;rdquo; from the menu dropdown.&lt;/p>
&lt;p>&lt;img src="../../../img/ondemand_desktop1.png" alt="rstudiomenu">&lt;/p>
&lt;p>Please see the Jupyter section for selecting resources and opening the Desktop Window.&lt;/p>
&lt;h2 id="using-gpus-on-ondemand">Using GPUs on OnDemand&lt;/h2>
&lt;p>In many of the interactive session launch pages, the &amp;ldquo;Additional Slurm Arguments&amp;rdquo; option is available.&lt;/p>
&lt;p>&lt;img src="../../../img/ondemand_use_gpu.png" alt="GPU Menu1">&lt;/p>
&lt;p>To select a GPU, you can use the same &lt;code>--gres&lt;/code> argument as you would with the &lt;code>srun&lt;/code> command or in &lt;code>sbatch&lt;/code> scripts.&lt;/p>
&lt;p>For example, to get 1x A100 GPU for a job, be sure to select the &lt;code>gpu&lt;/code> partition and enter &lt;code>--gres=gpu:a100:1&lt;/code> in the Additional SLurm Arguments box.&lt;/p>
&lt;h2 id="troubleshooting-jobs">Troubleshooting Jobs&lt;/h2>
&lt;h3 id="rstudio-crashes">RStudio Crashes&lt;/h3>
&lt;p>&lt;img src="../../../img/ondemand_r_crash.png" alt="jupyterqueue2">&lt;/p>
&lt;p>If your RStudio session crashes with an error similar to the following, first try increasing the memory allocated to your job. If your R program attempts to allocate too much memory it will be killed by Slurm, causing an error similar to the one pictured.&lt;/p>
&lt;p>To confirm whether or not this is the problem you are encountering:&lt;/p>
&lt;ol>
&lt;li>Copy the Job ID from OnDemand&lt;/li>
&lt;li>Delete the job (This will remove the dialog, so make sure you copy the JobID first)&lt;/li>
&lt;li>Using a terminal, run &lt;code>sacct -j ####&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>If one of the job steps existed with the reason &amp;ldquo;OUT_OF_MEM&amp;rdquo;, then you need to allocate more memory to RStudio.&lt;/p>
&lt;p>&lt;img src="../../../img/ondemand_r_crash2.png" alt="jupyterqueue2">&lt;/p></description></item><item><title>Manuals: PyTorch In Jupyter</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/selected_software/pytorch_in_jupyter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/selected_software/pytorch_in_jupyter/</guid><description>
&lt;h2 id="pytorch-in-a-jupyter-notebook">PyTorch in a Jupyter Notebook&lt;/h2>
&lt;p>There are many ways to run PyTorch within Jupyter, though some methods are needlessly complicated or are more prone to errors. If you intend to use PyTorch within Jupyter, the following steps should get you up and running.&lt;/p>
&lt;h2 id="setting-up-the-environment">Setting Up The Environment&lt;/h2>
&lt;p>Creating a new Conda environment is necessary as we do not provide PyTorch through our global Python installation.&lt;/p>
&lt;pre>&lt;code class="language-bash">conda create -n pytorch_env
conda activate pytorch_env
&lt;/code>&lt;/pre>
&lt;p>After activating the conda environment, install python and ipykernel.&lt;/p>
&lt;blockquote>
&lt;p>Warning: The &lt;a href="https://pytorch.org/get-started/locally/">PyTorch instructions&lt;/a> provide a method of installing through Conda. &lt;strong>Do not use this method&lt;/strong> as the CUDA packages installed through Conda can conflict with the system installation.&lt;/p>
&lt;/blockquote>
&lt;pre>&lt;code class="language-bash">conda install python=3 ipykernel
&lt;/code>&lt;/pre>
&lt;blockquote>
&lt;p>At this point run &lt;code>which pip&lt;/code>, it should return a path ending in something similar to &lt;code>...../.conda/envs/pytorch_env/bin/pip&lt;/code>. If the output path begins with &lt;code>/opt/linux/...&lt;/code> then the environment has not been set up correctly.&lt;/p>
&lt;/blockquote>
&lt;p>With &lt;code>ipykernel&lt;/code> installed, add the environment as a Jupyter Kernel.&lt;/p>
&lt;pre>&lt;code class="language-bash">python -m ipykernel install --user --name pytorch_env --display-name &amp;quot;PyTorch Env&amp;quot;
&lt;/code>&lt;/pre>
&lt;blockquote>
&lt;p>For more info on Jupyter Kernels, see the &lt;a href="https://hpcc.ucr.edu/manuals/hpc_cluster/package_manage/#virtual-environment">Package Management&lt;/a> page.&lt;/p>
&lt;/blockquote>
&lt;p>PyTorch can now be installed in the Conda environment using Pip&lt;/p>
&lt;pre>&lt;code class="language-bash">pip3 install torch torchvision torchaudio
&lt;/code>&lt;/pre>
&lt;p>From this point, the PyTorch kernel should be ready to use within Jupyter. Because of it&amp;rsquo;s requirement for a GPU, it will need to be run using OnDemand or through an interactive session.&lt;/p>
&lt;h2 id="running-on-jupyter">Running on Jupyter&lt;/h2>
&lt;p>The below steps will focus on running it through OnDemand.&lt;/p>
&lt;p>From within OnDemand, start a new Jupyter Notebook using the highlighted options below.&lt;/p>
&lt;p>&lt;img src="../../../img/pytorch_jupyter.png" alt="pytorch jupyter">&lt;/p>
&lt;p>Once the session has started, be sure to use the &amp;ldquo;PyTorch Env&amp;rdquo; kernel that we created earlier when creating a new notebook or within existing notebooks.&lt;/p>
&lt;p>The following code can be used to verify that the GPU is properly working.&lt;/p>
&lt;pre>&lt;code class="language-Python">import torch
dev = torch.device(&amp;quot;cuda&amp;quot;) if torch.cuda.is_available() else torch.device(&amp;quot;cpu&amp;quot;)
print(dev)
&lt;/code>&lt;/pre>
&lt;p>If the output prints &amp;ldquo;cuda&amp;rdquo;, then you&amp;rsquo;re good to go. If it prints &amp;ldquo;cpu&amp;rdquo;, then please double check that all of the above steps are correct.&lt;/p>
&lt;p>&lt;img src="../../../img/pytorch_jupyter2.png" alt="pytorch jupyter">&lt;/p></description></item><item><title>Manuals: VSCode Usage on HPCC</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/selected_software/vscode/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/selected_software/vscode/</guid><description>
&lt;h2 id="using-vscode-on-the-cluster">Using VSCode on the Cluster&lt;/h2>
&lt;p>VSCode is a code editor that can run locally on your computer, or while connected to the cluster.&lt;/p>
&lt;p>When using VSCode on the cluster, please do not use Remote SSH as it will launch the code server on a head node, causing unneeded load.&lt;/p>
&lt;p>Instead, we can use a feature of VSCode: &lt;a href="https://code.visualstudio.com/docs/remote/tunnels">Remote Tunnels&lt;/a>.&lt;/p>
&lt;h2 id="setting-up-vscode-tunnels">Setting up VSCode Tunnels&lt;/h2>
&lt;p>Using a tunnel allows us to work on a compute node, rather than on a head node. This allows us to use more resources than we would normally be allowed to on a head node.&lt;/p>
&lt;h3 id="installing-the-remote-tunnels-extension">Installing the Remote Tunnels extension&lt;/h3>
&lt;p>On your local machine, install the &amp;ldquo;Remote - Tunnels&amp;rdquo; extension.&lt;/p>
&lt;p>&lt;img src="../../../img/vscode-ext-install.png" alt="vscodeinstall">&lt;/p>
&lt;h3 id="starting-vscode-tunnel-on-the-cluster">Starting VSCode Tunnel on the Cluster&lt;/h3>
&lt;p>Create an interactive session using srun&lt;/p>
&lt;pre>&lt;code class="language-sh">srun -p epyc -t 5:00:00 --pty -c 4 --mem=4g bash -l # Customize as needed
&lt;/code>&lt;/pre>
&lt;p>Load the VSCode module and start the tunnel&lt;/p>
&lt;pre>&lt;code class="language-sh">module load vscode
code tunnel
&lt;/code>&lt;/pre>
&lt;p>The program will provide you with a code and ask you to verify on GitHub.com. Follow the steps for authorization.
Once you get to the &amp;ldquo;Congratulations, you&amp;rsquo;re all set!&amp;rdquo; page, the terminal will update with a new line asking you to open another link.
At this point you have 2 ways to access: via a web browser, or using the extension that we previously installed. Make sure that you keep
the server running in the background, as it is what allows the connection to occur.&lt;/p>
&lt;h3 id="using-a-web-browser">Using A Web Browser&lt;/h3>
&lt;p>After authorizing VSCode, you can use the link given to access your session. The URL should be similar to &lt;code>https://vscode.dev/tunnel/...&lt;/code>.
The environment is very similar to the desktop program, though some features might be missing.&lt;/p>
&lt;h3 id="using-the-vscode-extension">Using the VSCode Extension&lt;/h3>
&lt;p>After install the &amp;ldquo;Remote - Tunnels&amp;rdquo; extension on your local machine, connect to the Tunnel session that was previously created using the green &amp;ldquo;&amp;gt;&amp;lt;&amp;rdquo;
icon in the bottom left of VSCode. Select the &amp;ldquo;Connect to Tunnel&amp;hellip;&amp;rdquo; option, then select the tunnel we created earlier.&lt;/p>
&lt;p>&lt;img src="../../../img/vscode-tunnel1.png" alt="vscodeinstall">&lt;/p>
&lt;p>&lt;img src="../../../img/vscode-tunnel2.png" alt="vscodeinstall">&lt;/p>
&lt;p>After VSCode connects, you should be able to open Files and Folders on the cluster as if it were your local machine.&lt;/p>
&lt;h3 id="using-the-built-in-terminal">Using the Built-In Terminal&lt;/h3>
&lt;p>One feature that VSCode integrates is an in-editor terminal. To activate it, you can use the keyboard shortcut &lt;code>Ctrl+`&lt;/code>, or via &lt;code>View &amp;gt; Terminal&lt;/code> from the status bar.&lt;/p>
&lt;p>By default, you might be dropped into a basic shell without some of the features that you are used to (eg. with the prompt &lt;code>bash-4.4$&lt;/code> instead of &lt;code>username@node&lt;/code>). To fix this, you can type &lt;code>bash -l&lt;/code> that should bring you to the terminal environment that you are used to, and from here you can navigate and use the cluster as if it was any other terminal program.&lt;/p>
&lt;h3 id="cleaning-up">Cleaning Up&lt;/h3>
&lt;p>Once you have finished, make sure to close VSCode (locally or using your web browser). Then stop the Tunnel from running on the cluster using &lt;code>Ctrl+C&lt;/code>.
Once the program had been stopped, you can exit out of the interactive srun session and close your terminal.&lt;/p></description></item></channel></rss>